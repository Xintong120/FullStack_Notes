## 必须掌握（核心基础）
### 1. `os` - 文件系统操作

`os` 是 Python 的**标准库**（无需安装），提供了与**操作系统交互**的功能。

```python
import os  # 直接导入，不需要 pip install
```

**主要功能：**

- 📁 文件和目录操作
- 🔑 环境变量管理
- 📂 路径操作
- 🖥️ 进程管理
- 🔧 系统信息

---

📚 **核心功能分类**

**1. 环境变量（最常用）**

```python
import os

# 1. 读取环境变量
api_key = os.getenv("OPENAI_API_KEY")                    # 推荐，返回 None 如果不存在
api_key = os.getenv("OPENAI_API_KEY", "default_value")  # 带默认值
api_key = os.environ["OPENAI_API_KEY"]                  # 不存在会报错

# 2. 设置环境变量
os.environ["DEBUG"] = "1"

# 3. 获取所有环境变量
all_vars = os.environ  # 字典形式
```

**在 AutoGPT Platform 中的实际使用：**

```python
# backend/data/redis_client.py
HOST = os.getenv("REDIS_HOST", "localhost")      # 读取 Redis 主机，默认 localhost
PORT = int(os.getenv("REDIS_PORT", "6379"))      # 读取端口，默认 6379
PASSWORD = os.getenv("REDIS_PASSWORD", None)     # 读取密码，可选

# backend/data/db.py
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://localhost:5432")
PRISMA_SCHEMA = os.getenv("PRISMA_SCHEMA", "schema.prisma")
os.environ["PRISMA_SCHEMA_PATH"] = PRISMA_SCHEMA  # 设置环境变量
```

---

**2. 路径操作**

```python
import os

# 获取当前工作目录
current_dir = os.getcwd()
print(current_dir)  # /path/to/current/directory

# 改变工作目录
os.chdir("/path/to/another/directory")

# 拼接路径（自动处理 / 和 \）
path = os.path.join("folder", "subfolder", "file.txt")
# Windows: folder\subfolder\file.txt
# Linux:   folder/subfolder/file.txt

# 获取绝对路径
abs_path = os.path.abspath("file.txt")
# /full/path/to/file.txt

# 获取文件所在目录
dir_name = os.path.dirname("/path/to/file.txt")
# /path/to

# 获取文件名
file_name = os.path.basename("/path/to/file.txt")
# file.txt

# 分割路径和文件名
path, filename = os.path.split("/path/to/file.txt")
# path: /path/to
# filename: file.txt

# 分割文件名和扩展名
name, ext = os.path.splitext("document.txt")
# name: document
# ext: .txt

# 检查路径是否存在
exists = os.path.exists("/path/to/file")

# 检查是否是文件
is_file = os.path.isfile("/path/to/file.txt")

# 检查是否是目录
is_dir = os.path.isdir("/path/to/folder")
```

**在 AutoGPT Platform 中的实际使用：**

```python
# backend/blocks/block.py
block_dir = os.path.dirname(__file__)  # 获取当前文件所在目录
file_path = f"{block_dir}/{file_name}.py"

# backend/server/v2/store/media.py
file_ext = os.path.splitext(filename)[1].lower()  # 获取文件扩展名
# 如果 filename = "image.jpg"，返回 ".jpg"

# backend/blocks/__init__.py
module_path = str(relative_path)[:-3].replace(os.path.sep, ".")
# os.path.sep 是路径分隔符：Windows 是 \，Linux 是 /

# backend/util/data.py
filedir = os.path.dirname(__file__)  # 获取当前文件目录
```

---

**3. 文件和目录操作**

```python
import os

# 创建单层目录
os.mkdir("new_folder")

# 创建多层目录（递归创建）
os.makedirs("parent/child/grandchild", exist_ok=True)
# exist_ok=True 表示如果目录存在不报错

# 删除文件
os.remove("file.txt")

# 删除空目录
os.rmdir("empty_folder")

# 删除非空目录（需要用 shutil）
import shutil
shutil.rmtree("folder_with_files")

# 重命名文件或目录
os.rename("old_name.txt", "new_name.txt")

# 列出目录内容
files = os.listdir("/path/to/directory")
# 返回：['file1.txt', 'file2.txt', 'subfolder']

# 遍历目录树
for root, dirs, files in os.walk("/path/to/directory"):
    print(f"当前目录: {root}")
    print(f"子目录: {dirs}")
    print(f"文件: {files}")
```

**在 AutoGPT Platform 中的实际使用：**

```python
# backend/cli.py
os.makedirs(file_path.parent, exist_ok=True)  # 创建目录
os.remove(get_pid_path())                     # 删除文件

# backend/blocks/media.py
abs_temp_dir = os.path.join(tempfile.gettempdir(), "exec_file", graph_exec_id)
output_abspath = os.path.join(abs_temp_dir, output_filename)
```

---

**4. 系统信息**

```python
import os

# 获取操作系统名称
os_name = os.name
# 'posix' (Linux/Mac), 'nt' (Windows)

# 路径分隔符
sep = os.path.sep
# '\\' (Windows), '/' (Linux/Mac)

# 换行符
linesep = os.linesep
# '\\r\\n' (Windows), '\\n' (Linux/Mac)

# 获取用户主目录
home = os.path.expanduser("~")
# /home/username (Linux)
# C:\\Users\\username (Windows)
```

---

**5. 进程管理**

```python
import os

# 获取当前进程 ID
pid = os.getpid()

# 执行系统命令
os.system("ls -la")  # Linux
os.system("dir")     # Windows

# 更强大的方式（推荐）
import subprocess
result = subprocess.run(["ls", "-la"], capture_output=True, text=True)
print(result.stdout)
```

---

> ## **AutoGPT Platform 中的实际案例**
>
> ### **案例 1：读取配置（环境变量）**
>
> ```python
> # backend/data/redis_client.py
> import os
> from dotenv import load_dotenv
> 
> load_dotenv()  # 加载 .env 文件
> 
> HOST = os.getenv("REDIS_HOST", "localhost")
> PORT = int(os.getenv("REDIS_PORT", "6379"))
> PASSWORD = os.getenv("REDIS_PASSWORD", None)
> 
> # 使用场景：从环境变量读取敏感配置
> # .env 文件内容：
> # REDIS_HOST=192.168.1.100
> # REDIS_PORT=6379
> # REDIS_PASSWORD=secret123
> ```
>
> ---
>
> ### **案例 2：动态模块加载**
>
> ```python
> # backend/blocks/__init__.py
> import os
> from pathlib import Path
> 
> current_dir = Path(__file__).parent
> for f in current_dir.rglob("*.py"):
>     if not f.is_file() or f.name == "__init__.py":
>         continue
>     
>     relative_path = f.relative_to(current_dir)
>     # 将路径转换为模块名：folder/file.py → folder.file
>     module_path = str(relative_path)[:-3].replace(os.path.sep, ".")
>     #                                              ^^^^^^^^^^^ 跨平台路径分隔符
> ```
>
> ---
>
> ### **案例 3：文件路径处理**
>
> ```python
> # backend/server/v2/store/media.py
> import os
> 
> filename = "user_upload.jpeg"
> file_ext = os.path.splitext(filename)[1].lower()  # .jpeg
> # os.path.splitext() 返回 ('user_upload', '.jpeg')
> 
> if file_ext in [".jpg", ".jpeg", ".png"]:
>     print("这是图片文件")
> ```
>
> ---
>
> ### **案例 4：创建临时目录**
>
> ```python
> # backend/blocks/media.py
> import os
> import tempfile
> 
> graph_exec_id = "abc-123"
> abs_temp_dir = os.path.join(
>     tempfile.gettempdir(),  # 系统临时目录
>     "exec_file",
>     graph_exec_id
> )
> # Windows: C:\Users\username\AppData\Local\Temp\exec_file\abc-123
> # Linux:   /tmp/exec_file/abc-123
> 
> os.makedirs(abs_temp_dir, exist_ok=True)  # 创建目录
> ```
>
> ---
>
> ### **案例 5：文件删除和清理**
>
> ```python
> # backend/blocks/block.py
> import os
> 
> file_path = "/path/to/block_code.py"
> 
> try:
>     # 执行某些操作
>     result = execute_code(file_path)
> except Exception as e:
>     # 失败时删除文件
>     os.remove(file_path)
>     raise RuntimeError(f"Error: {e}")
> ```
>

#### **总结：os 模块核心要点**

**最常用功能（必须掌握）**

| 功能       | 方法                 | 用途               |
| ---------- | -------------------- | ------------------ |
| 环境变量   | `os.getenv()`        | 读取配置           |
| 路径拼接   | `os.path.join()`     | 跨平台路径         |
| 创建目录   | `os.makedirs()`      | 递归创建           |
| 检查存在   | `os.path.exists()`   | 文件是否存在       |
| 获取扩展名 | `os.path.splitext()` | 分离文件名和扩展名 |
| 获取目录   | `os.path.dirname()`  | 获取父目录         |
| 删除文件   | `os.remove()`        | 删除单个文件       |

**常用但不紧急**

| 功能     | 方法                |
| -------- | ------------------- |
| 列出文件 | `os.listdir()`      |
| 遍历目录 | `os.walk()`         |
| 重命名   | `os.rename()`       |
| 当前目录 | `os.getcwd()`       |
| 绝对路径 | `os.path.abspath()` |

---

**常见陷阱**

**陷阱 1：路径分隔符**

```python
# ❌ 错误：硬编码路径分隔符
path = "data\\users\\config.json"  # Windows 专用

# ✅ 正确：使用 os.path.join
path = os.path.join("data", "users", "config.json")
```

**陷阱 2：环境变量不存在**

```python
# ❌ 错误：不存在会报 KeyError
api_key = os.environ["API_KEY"]

# ✅ 正确：使用 getenv 并提供默认值
api_key = os.getenv("API_KEY", "default_value")
```

**陷阱 3：创建目录时目录已存在**

```python
# ❌ 错误：如果目录存在会报错
os.makedirs("output")

# ✅ 正确：添加 exist_ok=True
os.makedirs("output", exist_ok=True)
```

---

💡 **os vs pathlib**

**现代 Python 推荐使用 `pathlib`（但 `os` 仍然很常用）**

```python
# 传统方式（os）
import os
path = os.path.join("data", "file.txt")
exists = os.path.exists(path)

# 现代方式（pathlib）
from pathlib import Path
path = Path("data") / "file.txt"  # 更直观
exists = path.exists()
```

**同时使用两者：**

- `os` 用于环境变量、简单路径操作
- `pathlib` 用于复杂路径操作

### 2. `pathlib` - 路径操作

**什么是 pathlib？**

- Python 3.4+ 引入的**面向对象**的路径操作库
- 比 `os.path` 更直观、更易用
- 标准库，无需安装

**为什么用 pathlib？**

```python
# os.path 方式（旧式，繁琐）
import os
path = os.path.join(os.path.dirname(__file__), "data", "file.txt")
if os.path.exists(path):
    with open(path) as f:
        content = f.read()

# pathlib 方式（现代，简洁）
from pathlib import Path
path = Path(__file__).parent / "data" / "file.txt"
if path.exists():
    content = path.read_text()
```

---

**核心功能速查表**

**创建路径对象**

| 功能         | 代码                      | 说明              |
| ------------ | ------------------------- | ----------------- |
| 当前文件路径 | `Path(__file__)`          | 获取当前 .py 文件 |
| 当前目录     | `Path.cwd()`              | 当前工作目录      |
| 主目录       | `Path.home()`             | 用户主目录        |
| 任意路径     | `Path("folder/file.txt")` | 创建路径对象      |

**路径拼接**

| 功能          | 代码                                |
| ------------- | ----------------------------------- |
| 使用 `/` 拼接 | `Path("data") / "file.txt"`         |
| 使用 joinpath | `Path("data").joinpath("file.txt")` |

**路径属性**

| 属性                                                         | 作用                 | 示例                               |
| ------------------------------------------------------------ | -------------------- | ---------------------------------- |
| [.name](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:476:4-478:38) | 文件名（含扩展名）   | `"file.txt"`                       |
| `.stem`                                                      | 文件名（不含扩展名） | `"file"`                           |
| `.suffix`                                                    | 扩展名               | `".txt"`                           |
| `.parent`                                                    | 父目录               | `Path("a/b/c.txt").parent` → `a/b` |
| `.parents`                                                   | 所有父目录           | 返回父目录序列                     |
| `.parts`                                                     | 路径各部分           | `('a', 'b', 'file.txt')`           |

**路径判断**

| 方法             | 作用           |
| ---------------- | -------------- |
| `.exists()`      | 是否存在       |
| `.is_file()`     | 是否是文件     |
| `.is_dir()`      | 是否是目录     |
| `.is_absolute()` | 是否是绝对路径 |

**路径转换**

| 方法                  | 作用                   |
| --------------------- | ---------------------- |
| `.resolve()`          | 转为绝对路径           |
| `.absolute()`         | 转为绝对路径（简单版） |
| `.relative_to(other)` | 相对于某路径           |
| `str(path)`           | 转为字符串             |

**文件操作**

| 方法                 | 作用           |
| -------------------- | -------------- |
| `.read_text()`       | 读取文本文件   |
| `.read_bytes()`      | 读取二进制文件 |
| `.write_text(data)`  | 写入文本       |
| `.write_bytes(data)` | 写入二进制     |
| `.open()`            | 打开文件       |

**目录操作**

| 方法              | 作用       |
| ----------------- | ---------- |
| `.mkdir()`        | 创建目录   |
| `.rmdir()`        | 删除空目录 |
| `.iterdir()`      | 遍历目录   |
| `.glob(pattern)`  | 模式匹配   |
| `.rglob(pattern)` | 递归匹配   |

**文件系统操作**

| 方法               | 作用       |
| ------------------ | ---------- |
| `.rename(target)`  | 重命名     |
| `.replace(target)` | 替换       |
| `.unlink()`        | 删除文件   |
| `.touch()`         | 创建空文件 |

---

> ## **pathlib vs os.path 对比**
>
> | 操作       | os.path                     | pathlib                                                      |
> | ---------- | --------------------------- | ------------------------------------------------------------ |
> | 路径拼接   | `os.path.join(a, b)`        | `Path(a) / b`                                                |
> | 获取文件名 | `os.path.basename(path)`    | [path.name](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:476:4-478:38) |
> | 获取扩展名 | `os.path.splitext(path)[1]` | `path.suffix`                                                |
> | 获取目录   | `os.path.dirname(path)`     | `path.parent`                                                |
> | 检查存在   | `os.path.exists(path)`      | `path.exists()`                                              |
> | 绝对路径   | `os.path.abspath(path)`     | `path.resolve()`                                             |
> | 读取文件   | `open(path).read()`         | `path.read_text()`                                           |
>

---

**最常用的 10 个操作**

```python
from pathlib import Path

# 1. 获取当前文件所在目录
current_dir = Path(__file__).parent

# 2. 拼接路径
file_path = Path("data") / "users" / "config.json"

# 3. 检查文件是否存在
if file_path.exists():
    pass

# 4. 读取文件
content = file_path.read_text()

# 5. 写入文件
file_path.write_text("content")

# 6. 创建目录
Path("output/reports").mkdir(parents=True, exist_ok=True)

# 7. 获取文件名和扩展名
name = file_path.stem      # "config"
ext = file_path.suffix     # ".json"

# 8. 遍历目录
for file in Path("data").iterdir():
    print(file)

# 9. 查找文件（递归）
for py_file in Path(".").rglob("*.py"):
    print(py_file)

# 10. 转为绝对路径
abs_path = file_path.resolve()
```

---

> ## **AutoGPT Platform 中的实际使用**
>
> ### **案例分析**
>
> #### **案例 1：获取当前文件目录**
>
> ```python
> # backend/usecases/block_autogen.py
> from pathlib import Path
> 
> current_dir = Path(__file__).parent
> #             ^^^^^^^^^^^^^^^ 当前文件的 Path 对象
> #                      ^^^^^^ 获取父目录
> 
> file_path = current_dir.parent / "blocks" / f"{module}.py"
> #           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> #           使用 / 运算符拼接路径，清晰直观
> ```
>
> **等价的 os.path 写法（更繁琐）：**
> ```python
> import os
> current_dir = os.path.dirname(__file__)
> file_path = os.path.join(os.path.dirname(current_dir), "blocks", f"{module}.py")
> ```
>
> ---
>
> #### **案例 2：路径拼接和转换**
>
> ```python
> # backend/util/data.py
> import pathlib
> 
> def get_frontend_path() -> pathlib.Path:
>     filedir = os.path.dirname(__file__)
>     datadir = pathlib.Path(filedir).parent.parent.parent / "example_files"
>     #         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>     #         Path(...).parent.parent.parent 优雅地向上三级
>     return pathlib.Path(datadir)
> ```
>
> ---
>
> #### **案例 3：文件操作**
>
> ```python
> # backend/util/file.py
> from pathlib import Path
> 
> TEMP_DIR = Path(tempfile.gettempdir()).resolve()
> #          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 转为绝对路径
> 
> base_path = Path(get_exec_file_path(graph_exec_id, ""))
> base_path.mkdir(parents=True, exist_ok=True)
> #         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> #         创建多级目录，exist_ok=True 避免已存在报错
> 
> # 检查路径是否存在且是目录
> exec_path = Path(get_exec_file_path(graph_exec_id, file))
> if exec_path.exists() and exec_path.is_dir():
>     shutil.rmtree(exec_path)
> ```
>
> ---
>
> #### **案例 4：提取文件名**
>
> ```python
> # backend/util/file.py
> from pathlib import Path
> 
> # 从 URL 提取文件名
> filename = Path(parsed_url.path).name or f"{uuid.uuid4()}"
> #          ^^^^^^^^^^^^^^^^^^^^^^^^^^ 优雅地获取 URL 路径的文件名
> #          如果 path = "/files/image.jpg"，返回 "image.jpg"
> 
> # 从云存储路径提取文件名
> filename = Path(path_part).name or f"{uuid.uuid4()}.bin"
> ```
>
> ---
>
> #### **案例 5：递归查找文件**
>
> ```python
> # backend/blocks/__init__.py
> from pathlib import Path
> 
> current_dir = Path(__file__).parent
> for f in current_dir.rglob("*.py"):
>     #                ^^^^^^^^^^^^^ 递归查找所有 .py 文件
>     if not f.is_file() or f.name == "__init__.py":
>         continue
>     
>     relative_path = f.relative_to(current_dir)
>     #                 ^^^^^^^^^^^^^^^^^^^^^^^ 获取相对路径
> ```
>

### 

> | 路径类型            | 何时使用                                        | 为什么？                                                     | AutoGPT 例子                                                 |
> | ------------------- | ----------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | **相对路径**        | **项目内部**的文件引用 (代码、配置、资源)       | **可移植性**：项目可以移动到任何地方而代码不受影响。         | 动态加载 Blocks, `import` 语句, 前端组件。                   |
> | **绝对路径**        | **项目外部**的文件引用 (系统目录、用户指定路径) | **位置固定**：这些路径由操作系统或用户定义，与项目位置无关。 | 使用 `tempfile` 创建临时目录，读取用户配置的日志路径。       |
> | **`__file__` 技巧** | 需要一个指向**项目内部**文件的**绝对路径**时    | **健壮性**：结合了相对路径的灵活性和绝对路径的明确性，避免了“当前工作目录”陷阱。 | 从任何子模块安全地定位到项目根目录下的 `schema.prisma` 或 `.env` 文件。 |

**详细功能讲解**

**1. 创建  Path 对象**

```python
from pathlib import Path

# 相对路径
p1 = Path("data/file.txt")

# 绝对路径
p2 = Path("/usr/local/bin")

# 当前文件路径
p3 = Path(__file__)
# 输出：/path/to/current/script.py

# 当前工作目录
p4 = Path.cwd()
# 输出：/path/to/working/directory

# 用户主目录
p5 = Path.home()
# 输出：/home/username 或 C:\Users\username
```

---

**2. 路径拼接（/ 运算符）**

```python
from pathlib import Path

# 使用 / 拼接路径（最推荐）
path = Path("data") / "users" / "config.json"
# data/users/config.json

# 可以混用字符串
base = Path("output")
path = base / "reports" / "2024" / "report.pdf"

# 链式操作
path = Path.home() / "Documents" / "projects" / "myapp"
```

---

**3. 路径属性**

```python
from pathlib import Path

p = Path("/home/user/documents/report.pdf")

p.name      # "report.pdf"          - 完整文件名
p.stem      # "report"              - 文件名（不含扩展名）
p.suffix    # ".pdf"                - 扩展名
p.suffixes  # ['.pdf']              - 所有扩展名（如 .tar.gz）
p.parent    # Path("/home/user/documents")  - 父目录
p.parents   # [documents, user, home, /]    - 所有父目录
p.parts     # ('/', 'home', 'user', 'documents', 'report.pdf')
```

**实际应用：**
```python
# 获取文件扩展名
file_path = Path("image.jpg")
if file_path.suffix == ".jpg":
    print("这是 JPEG 图片")

# 改变扩展名
new_path = file_path.with_suffix(".png")
# image.png

# 改变文件名
new_path = file_path.with_name("photo.jpg")
# photo.jpg

# 改变文件名但保留扩展名
new_path = file_path.with_stem("photo")
# photo.jpg
```

---

**4. 路径判断**

```python
from pathlib import Path

p = Path("data/file.txt")

p.exists()       # 路径是否存在
p.is_file()      # 是否是文件
p.is_dir()       # 是否是目录
p.is_symlink()   # 是否是符号链接
p.is_absolute()  # 是否是绝对路径

# 实际应用
if p.exists():
    if p.is_file():
        content = p.read_text()
    elif p.is_dir():
        for item in p.iterdir():
            print(item)
```

---

**5. 文件读写**

```python
from pathlib import Path

# 读取文本文件

path = Path("config.txt")
content = path.read_text()           # 读取整个文件为字符串
content = path.read_text(encoding="utf-8")  # 指定编码

# 读取二进制文件

data = path.read_bytes()

# 写入文本

path.write_text("Hello, World!")
path.write_text("你好", encoding="utf-8")

# 写入二进制

path.write_bytes(b"\x00\x01\x02")

# 传统方式（更灵活）

with path.open("r") as f:
    for line in f:
        print(line)
```

>  什么时候必须指定 `encoding="utf-8"`？
>
> 1. **文件中包含任何非英文字符时**
>      这是最直接的场景。只要你的文本可能包含中文、日文、俄文、特殊符号（`©`）、或者 Emoji ( `😂` )，就必须用 `UTF-8`。
> 2. **为了编写可移植、健壮的代码时 (最重要的原因)**
>      即使你现在处理的文件只包含英文字母，也应该指定编码。这能确保你的代码在任何人的、任何语言的操作系统上都能按预期工作，不会因为环境变化而出错。这是专业开发的标准做法。
> 3. **读取来自网络或第三方系统的文件时**
>      API 返回的 JSON、从网站下载的配置文件、Git 仓库中的代码文件等，现代互联网世界的事实标准就是 `UTF-8`。当你接收这些文件时，必须假设它们是 `UTF-8` 并以此编码来读取。
>
> **结论：** 养成习惯，在所有 `read_text()` 和 `write_text()` 操作中都加上 `encoding="utf-8"`。

> **什么时候需要用二进制模式写入**？
>
> 1. **文本文档 (`.txt`, `.md`, `.py`, `.json`)**: 你可以用记事本打开并直接阅读里面的文字。它们由字符组成。
> 2. **数据文件 (`.jpg`, `.png`, `.mp4`, `.zip`, `.exe`)**: 你用记事本打开会看到一堆无法理解的乱码。它们由原始的字节（bytes）组成，需要特定的程序（如图片查看器、视频播放器）才能正确解析。
>
> **写入二进制 (`write_bytes`) 就是在处理第二种类型的文件。**

---

**6. 目录操作**

```python
from pathlib import Path

# 创建目录

Path("output").mkdir()
Path("output/reports/2024").mkdir(parents=True, exist_ok=True)

#                                  ^^^^^^^^^^^^^^^^^^^^^^

#                                  parents=True: 创建父目录

#                                  exist_ok=True: 已存在不报错

# 遍历目录

for item in Path("data").iterdir():
    print(item)

    # Path('data/file1.txt')

    # Path('data/file2.txt')

    # Path('data/subfolder')

# 只遍历文件

for file in Path("data").iterdir():
    if file.is_file():
        print(file)

# 查找匹配的文件

for txt_file in Path("data").glob("*.txt"):
    print(txt_file)

    # data/file1.txt

    # data/file2.txt

# 递归查找

for py_file in Path(".").rglob("*.py"):
    print(py_file)

    # ./app.py

    # ./utils/helper.py

    # ./tests/test_app.py
```

| 方法            | 搜索深度                  | 是否过滤                | 典型用例                                       |
| --------------- | ------------------------- | ----------------------- | ---------------------------------------------- |
| `iterdir()`     | **浅层** (仅当前目录)     | 否 (返回所有文件和目录) | 查看一个文件夹里直接包含哪些东西。             |
| `glob("*.txt")` | **浅层** (仅当前目录)     | 是 (按模式匹配)         | 在一个文件夹里查找特定类型的文件。             |
| `rglob("*.py")` | **深层** (递归所有子目录) | 是 (按模式匹配)         | 在整个项目或某个目录下查找所有特定类型的文件。 |



---

**7. 路径转换**

```python
from pathlib import Path

p = Path("data/file.txt")

# 转为绝对路径
abs_path = p.resolve()
# /home/user/project/data/file.txt

# 简单的绝对路径（不解析符号链接）
abs_path = p.absolute()

# 相对路径
base = Path("/home/user/project")
file = Path("/home/user/project/data/file.txt")
rel = file.relative_to(base)
# data/file.txt

# 转为字符串
path_str = str(p)
# "data/file.txt"

# 转为 URI
uri = p.as_uri()
# "file:///home/user/project/data/file.txt"
```

**什么时候转为字符串？**

> | 场景               | 动作                               | 为什么？                            |
> | ------------------ | ---------------------------------- | ----------------------------------- |
> | **与旧代码交互**   | `str(path)`                        | 旧函数只懂字符串。                  |
> | **设置环境变量**   | `os.environ["KEY"] = str(path)`    | 环境变量的值必须是字符串。          |
> | **构建 URL/URI**   | `f"protocol://{str(path)}"`        | URL 是一个复合字符串。              |
> | **调用子进程**     | `subprocess.run([..., str(path)])` | 命令行参数是字符串。                |
> | **打开/读/写文件** | `path.read_text()` 或 `open(path)` | 现代 I/O 操作原生支持 `Path` 对象。 |

**什么时候转为 URI？**

> | 场景                               | 是否需要 `as_uri()` | 为什么？                                                 |
> | ---------------------------------- | ------------------- | -------------------------------------------------------- |
> | 在 Python 中读写文件               | **否**              | `Path` 对象和 `open()` 函数直接处理操作系统路径。        |
> | 在 HTML/XML 文件中引用本地图片/CSS | **是**              | 浏览器和 XML 解析器遵循 URI 标准来定位资源。             |
> | 用 `webbrowser` 库打开本地文件     | **是**              | 这是最跨平台、最可靠的方式。                             |
> | 将路径作为参数传给大多数 Python 库 | **否**              | 绝大多数库都期望接收字符串或 `Path` 对象形式的系统路径。 |
>
> **核心法则：** 当你的 Python 代码需要**生成给“浏览器”或“网络解析器”看的内容**时，就要把本地路径转换成 URI。在纯粹的 Python 后端或脚本环境中，你几乎用不到它。

---

**8. 文件系统操作**

```python
from pathlib import Path

# 重命名
p = Path("old_name.txt")
p.rename("new_name.txt")

# 删除文件
p = Path("file.txt")
p.unlink()                    # 删除文件
p.unlink(missing_ok=True)     # 不存在不报错

# 删除空目录
p = Path("empty_folder")
p.rmdir()

# 删除非空目录（需要 shutil）
import shutil
shutil.rmtree(Path("folder_with_files"))

# 创建空文件
Path("new_file.txt").touch()

# 复制文件（需要 shutil）
import shutil
shutil.copy(Path("source.txt"), Path("dest.txt"))
```



---

⚠️ **常见陷阱和注意事项**

**陷阱 1：Path 对象不是字符串**

```python
# ❌ 错误
path = Path("file.txt")
os.system(f"cat {path}")  # 可能有问题

# ✅ 正确：转为字符串
os.system(f"cat {str(path)}")
```

**陷阱 2：/ 运算符必须至少一个是 Path**

```python
# ❌ 错误
path = "data" / "file.txt"  # TypeError

# ✅ 正确
path = Path("data") / "file.txt"
```

**陷阱 3：resolve() vs absolute()**

```python
# resolve() - 解析符号链接，返回真实路径
real_path = Path("link.txt").resolve()

# absolute() - 只是转为绝对路径，不解析链接
abs_path = Path("link.txt").absolute()
```

> | 特性            | `p.absolute()`                 | `p.resolve()`                      | 结论                  |
> | --------------- | ------------------------------ | ---------------------------------- | --------------------- |
> | **基本功能**    | 将相对路径变为绝对路径         | 将相对路径变为绝对路径             | 相同                  |
> | **符号链接**    | **不解析**，路径会包含链接本身 | **解析**，路径会指向链接的真实目标 | **核心区别**          |
> | **`..` 和 `.`** | 不保证完全清除                 | **保证清除**，给出最简洁的路径     | `resolve()` 更干净    |
> | **文件存在性**  | 不需要文件存在                 | 默认需要 (Python < 3.10)           | `absolute()` 更灵活   |
> | **性能**        | 非常快                         | 稍慢（需要查询文件系统）           | `absolute()` 性能更好 |

------

> | 使用场景                 | 推荐方法     | 为什么？                                                     |
> | ------------------------ | ------------ | ------------------------------------------------------------ |
> | **日志记录、错误信息**   | `absolute()` | 足够清晰，速度快，不关心文件是否存在。                       |
> | **传递路径给外部程序**   | `resolve()`  | 确保提供一个无歧义、干净的真实路径。                         |
> | **安全检查、路径验证**   | `resolve()`  | 防止路径遍历，确保你操作的是预期的物理文件。                 |
> | **获取文件的唯一标识符** | `resolve()`  | 两个不同的路径（一个通过符号链接）如果指向同一个文件，`resolve()` 会给出相同的结果。 |



### 3. `sys` - 系统信息

**什么是 sys？**

- Python 标准库，提供**与 Python 解释器交互**的功能
- 访问系统特定的参数和函数
- 管理运行时环境
- 标准库，无需安装

**为什么用 sys？**

```python
import sys

# 获取命令行参数
script_name = sys.argv[0]
arguments = sys.argv[1:]

# 退出程序
sys.exit(0)

# 获取 Python 版本
version = sys.version

# 修改模块搜索路径
sys.path.append("/custom/modules")
```

---

**核心功能速查表**

**命令行参数**

| 属性           | 作用           | 示例                            |
| -------------- | -------------- | ------------------------------- |
| `sys.argv`     | 命令行参数列表 | `['script.py', 'arg1', 'arg2']` |
| `sys.argv[0]`  | 脚本名称       | `'script.py'`                   |
| `sys.argv[1:]` | 所有参数       | `['arg1', 'arg2']`              |

**程序退出**

| 函数                   | 作用                 |
| ---------------------- | -------------------- |
| `sys.exit()`           | 正常退出（退出码 0） |
| `sys.exit(1)`          | 错误退出（退出码 1） |
| `sys.exit("错误消息")` | 打印消息并退出       |

**标准输入输出**

| 对象         | 作用       |
| ------------ | ---------- |
| `sys.stdin`  | 标准输入流 |
| `sys.stdout` | 标准输出流 |
| `sys.stderr` | 标准错误流 |

**Python 信息**

| 属性               | 作用              | 示例                             |
| ------------------ | ----------------- | -------------------------------- |
| `sys.version`      | Python 版本字符串 | `'3.10.0 ...'`                   |
| `sys.version_info` | 版本信息元组      | `(3, 10, 0, 'final', 0)`         |
| `sys.platform`     | 平台标识          | `'linux'`, `'win32'`, `'darwin'` |
| `sys.executable`   | Python 解释器路径 | `'/usr/bin/python3'`             |

**模块和导入**

| 属性/函数               | 作用             |
| ----------------------- | ---------------- |
| `sys.path`              | 模块搜索路径列表 |
| `sys.modules`           | 已导入模块字典   |
| `sys.path.append(path)` | 添加搜索路径     |

**内存和对象**

| 函数                   | 作用                     |
| ---------------------- | ------------------------ |
| `sys.getsizeof(obj)`   | 获取对象内存大小（字节） |
| `sys.getrefcount(obj)` | 获取对象引用计数         |

**递归和限制**

| 函数                       | 作用             |
| -------------------------- | ---------------- |
| `sys.getrecursionlimit()`  | 获取最大递归深度 |
| `sys.setrecursionlimit(n)` | 设置最大递归深度 |

**其他**

| 属性/函数                  | 作用                           |
| -------------------------- | ------------------------------ |
| `sys.maxsize`              | 最大整数值                     |
| `sys.byteorder`            | 字节序 (`'little'` 或 `'big'`) |
| `sys.getdefaultencoding()` | 默认编码                       |

---

**最常用的 10 个操作**

```python
import sys

# 1. 获取命令行参数
# 运行: python script.py arg1 arg2
args = sys.argv[1:]  # ['arg1', 'arg2']

# 2. 退出程序
if error:
    sys.exit(1)  # 退出码 1（错误）

# 3. 获取 Python 版本
if sys.version_info < (3, 8):
    print("需要 Python 3.8+")
    sys.exit(1)

# 4. 添加模块搜索路径
sys.path.insert(0, "/custom/lib")

# 5. 检查平台
if sys.platform == "win32":
    print("Windows 系统")

# 6. 重定向输出
original_stdout = sys.stdout
sys.stdout = open("output.log", "w")
print("这会写入文件")
sys.stdout = original_stdout

# 7. 获取对象大小
size = sys.getsizeof([1, 2, 3])  # 字节数

# 8. 检查是否在打包环境
is_frozen = getattr(sys, "frozen", False)

# 9. 获取解释器路径
python_path = sys.executable

# 10. 刷新输出缓冲
print("立即显示", flush=True)  # 或 sys.stdout.flush()
```

---

> ##  **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：检查是否在打包环境中**
>
> ```python
> # backend/util/data.py
> import sys
> import pathlib
> 
> def get_frontend_path() -> pathlib.Path:
>     if getattr(sys, "frozen", False):
>         # 应用被打包（如使用 PyInstaller）
>         datadir = pathlib.Path(os.path.dirname(sys.executable)) / "example_files"
>         #                                      ^^^^^^^^^^^^^^^ 获取可执行文件路径
>     else:
>         # 应用未打包（开发环境）
>         filedir = os.path.dirname(__file__)
>         datadir = pathlib.Path(filedir).parent.parent.parent / "example_files"
>     return pathlib.Path(datadir)
> ```
>
> **解释：**
> - `sys.frozen` - 只在打包后的应用中存在
> - `getattr(sys, "frozen", False)` - 安全检查属性是否存在
> - `sys.executable` - Python 解释器或打包后的可执行文件路径
>
> ---
>
> #### **案例 2：重定向标准输出（静默模式）**
>
> ```python
> # backend/util/process.py
> import sys
> import os
> 
> if silent:
>     sys.stdout = open(os.devnull, "w")
>     #            ^^^^^^^^^^^^^^^^^^^^^ 将输出重定向到 /dev/null（Linux）或 NUL（Windows）
>     sys.stderr = open(os.devnull, "w")
>     # 现在所有 print() 和错误输出都被屏蔽
> ```
>
> **解释：**
> - `sys.stdout` - 标准输出流（print 默认使用）
> - `sys.stderr` - 标准错误流（错误信息默认使用）
> - `os.devnull` - 空设备，丢弃所有写入
>
> ---
>
> #### **案例 3：程序退出**
>
> ```python
> # backend/util/process.py
> import sys
> import signal
> 
> def _self_terminate(self, signum: int, frame):
>     if not self.cleaned_up:
>         self.cleaned_up = True
>         sys.exit(0)  # 正常退出
>         #        ^^^ 退出码 0 表示成功
>     else:
>         # 已经在清理中...
>         pass
> ```
>
> **解释：**
> - `sys.exit(0)` - 正常退出（成功）
> - `sys.exit(1)` - 错误退出
> - `sys.exit("错误消息")` - 打印消息并退出
>
> ---
>
> #### **案例 4：获取对象大小**
>
> ```python
> # backend/util/truncate.py
> import sys
> 
> def get_size(val):
>     try:
>         return len(str(val))
>     except Exception:
>         return sys.getsizeof(val)
>         #      ^^^^^^^^^^^^^^^^^^^ 获取对象占用的内存字节数
> ```
>
> **解释：**
> - `sys.getsizeof(obj)` - 返回对象的内存大小（字节）
> - 用于性能分析和内存优化
>
> ---
>
> #### **案例 5：访问已导入的模块**
>
> ```python
> # backend/sdk/registry.py
> import sys
> 
> # 检查模块是否已导入
> if "backend.integrations.webhooks" in sys.modules:
>     webhooks = sys.modules["backend.integrations.webhooks"]
>     #          ^^^^^^^^^^^ 已导入模块的字典
> else:
>     import backend.integrations.webhooks
> ```
>
> **解释：**
> - `sys.modules` - 所有已导入模块的字典
> - 用于检查模块是否已加载，避免重复导入
>
> ---
>
> #### **案例 6：低级输出（信号处理器中）**
>
> ```python
> # backend/util/process.py
> import sys
> import os
> 
> def llprint(self, message: str):
>     """
>     Low-level print - 在信号处理器中安全的输出方式
>     """
>     os.write(sys.stdout.fileno(), (message + "\n").encode())
>     #        ^^^^^^^^^^^^^^^^^^^^ 获取标准输出的文件描述符
> ```
>
> **解释：**
> - `sys.stdout.fileno()` - 获取文件描述符（整数）
> - 用于低级 I/O 操作，在信号处理器中安全
>

---

**详细功能讲解**

**1. 命令行参数（sys.argv）**

> 让你的脚本可以被灵活配置和自动化。例如，一个测试脚本可以接收参数来决定只运行某一个特定的测试。

```python
import sys

# 运行命令: python script.py arg1 arg2 --verbose
print(sys.argv)
# ['script.py', 'arg1', 'arg2', '--verbose']

# 获取脚本名
script_name = sys.argv[0]  # 'script.py'

# 获取所有参数
args = sys.argv[1:]  # ['arg1', 'arg2', '--verbose']

# 实际应用
if len(sys.argv) < 2:
    print("用法: python script.py <filename>")
    sys.exit(1)

filename = sys.argv[1]
```

**简单的命令行工具示例：**
```python
# calculator.py
import sys

if len(sys.argv) != 4:
    print("用法: python calculator.py <num1> <op> <num2>")
    sys.exit(1)

num1 = float(sys.argv[1])
op = sys.argv[2]
num2 = float(sys.argv[3])

if op == '+':
    result = num1 + num2
elif op == '-':
    result = num1 - num2
else:
    print("不支持的操作")
    sys.exit(1)

print(f"{num1} {op} {num2} = {result}")

# 运行: python calculator.py 10 + 5
# 输出: 10.0 + 5.0 = 15.0
```

---

**2. 程序退出（sys.exit）**

> 当发生严重错误（如数据库连接失败、配置文件缺失）时，程序应该立即停止并向调用者（如 Shell 或 GitHub Actions）报告失败状态。

```python
import sys

# 正常退出（退出码 0）
sys.exit()
sys.exit(0)

# 错误退出（退出码 1）
sys.exit(1)

# 带消息退出
sys.exit("发生错误，程序终止")

# 实际应用
def validate_input(value):
    if value < 0:
        sys.exit("错误：值不能为负数")
    return value

# 与 try-except 结合
try:
    result = risky_operation()
except Exception as e:
    print(f"错误: {e}")
    sys.exit(1)
```

**退出码约定：**
- `0` - 成功
- `1` - 一般错误
- `2` - 命令行参数错误
- `> 128` - 被信号终止

---

**3. 标准输入输出流**

> - `sys.stdout`: 标准输出流，`print()` 函数默认写入的地方。
> - `sys.stderr`: 标准错误流，用于输出错误和警告信息。
> - `sys.stdin`: 标准输入流，用于从命令行读取用户的输入。
> - 将程序的正常输出和错误信息分开。这在日志记录和调试中非常有用，你可以将错误信息重定向到一个单独的文件。

```python
import sys

# 标准输出
sys.stdout.write("Hello\n")  # 等同于 print("Hello")
sys.stdout.flush()           # 立即刷新缓冲区

# 标准错误
sys.stderr.write("Error!\n")

# 重定向输出到文件
original_stdout = sys.stdout
with open("output.log", "w") as f:
    sys.stdout = f
    print("这会写入文件")
    print("这也会")
sys.stdout = original_stdout  # 恢复

# 标准输入
print("请输入内容:")
line = sys.stdin.readline()
print(f"你输入了: {line}")

# 读取所有输入
all_input = sys.stdin.read()
```

**实际应用：日志重定向**
```python
import sys
from datetime import datetime

class Logger:
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, "a")
    
    def write(self, message):
        self.terminal.write(message)  # 输出到控制台
        self.log.write(message)       # 同时写入文件
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()

# 使用
sys.stdout = Logger("app.log")
print("这会同时显示在控制台和文件中")
```

---

**4. Python 版本和平台信息**

> - `sys.getrecursionlimit()` / `sys.setrecursionlimit()`: 获取或设置最大递归深度。
> - `sys.platform`: 获取操作系统平台（如 `'linux'`, `'win32'`）。
> - `sys.version`: 获取 Python 解释器的版本。
> - **平台信息**: 编写需要根据不同操作系统（Windows/macOS/Linux）执行不同逻辑的代码。

```python
import sys

# Python 版本字符串
print(sys.version)
# '3.10.0 (default, Oct  6 2021, 00:00:00) [GCC 9.3.0]'

# 版本信息元组
print(sys.version_info)
# sys.version_info(major=3, minor=10, micro=0, releaselevel='final', serial=0)

# 版本检查
if sys.version_info < (3, 8):
    print("需要 Python 3.8 或更高版本")
    sys.exit(1)

if sys.version_info >= (3, 10):
    print("支持 match-case 语法")

# 平台标识
print(sys.platform)
# 'linux'   - Linux
# 'darwin'  - macOS
# 'win32'   - Windows

# 根据平台执行不同操作
if sys.platform == "win32":
    import msvcrt
elif sys.platform in ("linux", "darwin"):
    import termios

# Python 解释器路径
print(sys.executable)
# '/usr/bin/python3'
# 'C:\\Python310\\python.exe'
```

---

**5. 模块搜索路径（sys.path）**

```python
import sys

# 查看模块搜索路径
print(sys.path)
# ['', '/usr/lib/python310.zip', '/usr/lib/python3.10', ...]

# 添加自定义路径（开头）
sys.path.insert(0, "/custom/modules")

# 添加自定义路径（末尾）
sys.path.append("/another/path")

# 实际应用：动态导入自定义模块
import sys
import os

# 添加项目根目录到路径
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, project_root)

# 现在可以导入项目模块
from mymodule import myfunction

# 查看已导入的模块
print(sys.modules.keys())
# dict_keys(['sys', 'builtins', 'os', ...])

# 检查模块是否已导入
if 'numpy' in sys.modules:
    print("numpy 已导入")
```

---

**6. 内存和对象信息**

```python
import sys

# 获取对象大小（字节）
size = sys.getsizeof(10)          # 28 字节
size = sys.getsizeof("hello")     # 54 字节
size = sys.getsizeof([1, 2, 3])   # 88 字节

# 比较不同数据结构的内存占用
import sys

data_list = [1, 2, 3, 4, 5]
data_tuple = (1, 2, 3, 4, 5)

print(f"列表: {sys.getsizeof(data_list)} 字节")
print(f"元组: {sys.getsizeof(data_tuple)} 字节")

# 获取引用计数
import sys

a = [1, 2, 3]
print(sys.getrefcount(a))  # 2（a 本身 + getrefcount 参数）

b = a
print(sys.getrefcount(a))  # 3（增加了一个引用）
```

---

**7. 递归限制**

> - `sys.getrecursionlimit()` / `sys.setrecursionlimit()`: 获取或设置最大递归深度。
> - **递归限制**: 当你处理树或图等具有天然递归结构的数据时，如果层级非常深，可能会超出默认的递归限制（通常是 1000）。例如，解析一个极其复杂的 JSON 对象或文件系统树。

```python
import sys

# 获取最大递归深度（默认 1000）
limit = sys.getrecursionlimit()
print(limit)  # 1000

# 设置更大的递归深度
sys.setrecursionlimit(2000)

# 实际应用：深度递归
def deep_recursion(n):
    if n == 0:
        return
    return deep_recursion(n - 1)

# 默认限制会失败
try:
    deep_recursion(1500)
except RecursionError:
    print("递归太深！")

# 增加限制后可以成功
sys.setrecursionlimit(2000)
deep_recursion(1500)  # 现在可以了
```

---

**8. 其他有用的属性**

```python
import sys

# 最大整数值
print(sys.maxsize)
# 9223372036854775807（64 位系统）

# 字节序
print(sys.byteorder)
# 'little' 或 'big'

# 默认编码
print(sys.getdefaultencoding())
# 'utf-8'

# 文件系统编码
print(sys.getfilesystemencoding())
# 'utf-8' 或 'mbcs'（Windows）

# 浮点数信息
print(sys.float_info)
# sys.float_info(max=1.7976931348623157e+308, ...)

# 整数信息
print(sys.int_info)
# sys.int_info(bits_per_digit=30, sizeof_digit=4)
```

---

**常见陷阱和注意事项**

**陷阱 1：sys.exit() 在 REPL 中**

```python
# ❌ 在交互式解释器中会退出整个会话
>>> sys.exit()
# 整个 Python 会话结束

# ✅ 在脚本中使用是正确的
if error:
    sys.exit(1)
```

---

**陷阱 2：修改 sys.stdout 后忘记恢复**

```python
# ❌ 危险：可能丢失原始输出
sys.stdout = open("log.txt", "w")
print("写入文件")
# 如果程序崩溃，stdout 未恢复

# ✅ 正确：使用上下文管理器
original = sys.stdout
try:
    sys.stdout = open("log.txt", "w")
    print("写入文件")
finally:
    sys.stdout = original
```

---

**陷阱 3：sys.argv 索引越界**

```python
# ❌ 危险：如果没有提供参数会报错
filename = sys.argv[1]  # IndexError

# ✅ 正确：先检查长度
if len(sys.argv) < 2:
    print("请提供文件名")
    sys.exit(1)

filename = sys.argv[1]
```

---

**陷阱 4：递归限制设置过大**

```python
# ❌ 危险：可能导致栈溢出
sys.setrecursionlimit(1000000)  # 太大了！

# ✅ 正确：适度增加
sys.setrecursionlimit(2000)  # 或考虑改用迭代
```

---

#### **总结：sys 模块核心要点**

**必须掌握**

| 功能       | 方法/属性          | 用途         |
| ---------- | ------------------ | ------------ |
| 命令行参数 | `sys.argv`         | 获取脚本参数 |
| 程序退出   | `sys.exit()`       | 终止程序     |
| 版本检查   | `sys.version_info` | Python 版本  |
| 平台检测   | `sys.platform`     | 操作系统     |

**常用功能**

| 功能     | 方法/属性         |
| -------- | ----------------- |
| 标准输出 | `sys.stdout`      |
| 标准错误 | `sys.stderr`      |
| 模块路径 | `sys.path`        |
| 对象大小 | `sys.getsizeof()` |

**高级功能**

| 功能       | 方法/属性                 |
| ---------- | ------------------------- |
| 已导入模块 | `sys.modules`             |
| 递归限制   | `sys.setrecursionlimit()` |
| 引用计数   | `sys.getrefcount()`       |

### 4.`json` - JSON 数据

**什么是 json？**

- Python 标准库，用于处理 **JSON（JavaScript Object Notation）** 格式数据
- JSON 是最常用的数据交换格式（Web API、配置文件等）
- 标准库，无需安装

---

**核心功能速查表**

**序列化（Python → JSON）**

| 函数                   | 作用               | 输出           |
| ---------------------- | ------------------ | -------------- |
| `json.dumps(obj)`      | 对象转 JSON 字符串 | 字符串         |
| `json.dump(obj, file)` | 对象写入 JSON 文件 | 无（写入文件） |

**反序列化（JSON →  Python）**

| 函数                 | 作用                 | 输入     |
| -------------------- | -------------------- | -------- |
| `json.loads(string)` | JSON 字符串转对象    | 字符串   |
| `json.load(file)`    | 读取 JSON 文件为对象 | 文件对象 |

> `json` 库是 Python 的标准库，它的核心作用是充当**翻译官**，在 **Python 的数据结构** (如字典、列表) 和 **JSON 格式的文本字符串**之间进行转换。
>
> 这至关重要，因为 JSON 是现代软件中**数据交换的通用语言**。
>
> ---
>
> ### 为什么必须使用 `json`？
>
> #### 1. API 通信 (最核心的用途)
>
> 这是 `json` 在 AutoGPT 项目中最关键的应用。
>
> *   **场景**: AutoGPT 的前端 (Next.js, 运行在浏览器中) 需要向后端 (Python, FastAPI) 请求数据，比如获取一个 Agent 的任务列表。
> *   **过程**:
>     1.  **后端 (Python)**: 从数据库查询到任务列表，这是一个 Python 的列表，里面包含多个字典。
>         `[{"id": 1, "task": "Research AI"}, {"id": 2, "task": "Write report"}]`
>     2.  **序列化 (Serialization)**: Python 不能直接通过网络发送一个列表对象。它必须使用 `json.dumps()` (dump string) 将这个 Python 列表**转换**成一个 JSON 格式的文本字符串。
>         `'[{"id": 1, "task": "Research AI"}, {"id": 2, "task": "Write report"}]'`
>     3.  **网络传输**: 这个字符串通过 HTTP 请求发送给前端。
>     4.  **前端 (JavaScript)**: 浏览器接收到这个字符串。JavaScript 可以原生理解 JSON，并使用 `JSON.parse()` 将其**转换**回 JavaScript 的对象数组。
>     5.  **显示**: 前端现在可以使用这个对象数组来在界面上渲染任务列表。
>
> 在 AutoGPT 中，FastAPI 框架会自动在后台为你完成这个 JSON 转换过程，但其底层原理就是在使用 `json` 库。
>
> #### 2. 配置文件
>
> 当需要存储结构化的配置信息时，JSON 是一个非常好的选择，因为它既人类可读，也易于程序解析。
>
> *   **场景**: 一个 Agent Block 可能需要一个复杂的配置，定义它的行为。
>     ````json
>     // filepath: backend/blocks/config/some_block_config.json
>     {
>       "name": "WebSearchBlock",
>       "version": "1.2.0",
>       "settings": {
>         "timeout": 30,
>         "allowed_domains": [
>           "wikipedia.org",
>           "github.com"
>         ]
>       }
>     }
>     ````
>     Python 代码可以轻松地读取并解析这个文件：
>     ````python
>     import json
>     from pathlib import Path
>         
>     config_path = Path("backend/blocks/config/some_block_config.json")
>     config_text = config_path.read_text(encoding="utf-8")
>         
>     # 反序列化 (Deserialization): 将 JSON 字符串转换回 Python 字典
>     config_dict = json.loads(config_text) # load string
>         
>     print(config_dict["settings"]["timeout"]) # 输出: 30
>     ````
>
> #### 3. 存储结构化数据 (Agent 状态或记忆)
>
> 当 Agent 需要保存其工作进度或“记忆”时，可以将其内部的状态（通常是一个复杂的字典）序列化为 JSON 字符串，然后存入数据库或文件中。
>
> *   **场景**: Agent 完成了一半任务，需要保存状态以便下次恢复。
>     ````python
>     import json
>         
>     agent_state = {
>         "current_task": "Write report",
>         "completed_steps": ["Step 1: Research AI"],
>         "memory": {
>             "key_findings": "AutoGPT is an agent platform."
>         }
>     }
>         
>     # 将状态序列化为 JSON 字符串，以便存入数据库
>     state_as_json_string = json.dumps(agent_state, indent=2)
>         
>     # state_as_json_string 现在可以被写入文件或数据库的文本字段中
>     print(state_as_json_string)
>     ````
>
> ---
>
> ### 总结
>
> | 你想做什么？                            | 使用的 `json` 函数 | 解释                                                     | AutoGPT 场景                           |
> | :-------------------------------------- | :----------------- | :------------------------------------------------------- | :------------------------------------- |
> | 将 Python 对象 (字典/列表) 转换为字符串 | `json.dumps()`     | **序列化**：为了通过网络发送、写入文件或数据库。         | FastAPI 后端返回 API 响应。            |
> | 将 JSON 格式的字符串转换回 Python 对象  | `json.loads()`     | **反序列化**：为了处理从 API、文件或数据库接收到的数据。 | Python 客户端或测试脚本解析 API 响应。 |
>
> 简而言之，`json` 是现代应用程序的**数据黏合剂**，它让用不同语言编写的不同部分（如 Python 后端和 JavaScript 前端）能够无缝地对话。 

**常用参数**

| 参数           | 作用                 | 示例                                   |
| -------------- | -------------------- | -------------------------------------- |
| `indent`       | 缩进美化             | `json.dumps(data, indent=2)`           |
| `ensure_ascii` | 是否转义非 ASCII     | `json.dumps(data, ensure_ascii=False)` |
| `sort_keys`    | 排序键               | `json.dumps(data, sort_keys=True)`     |
| `default`      | 处理无法序列化的对象 | `json.dumps(data, default=str)`        |

---

**Python ↔ JSON 类型对应**

| Python                                                       | JSON     |
| ------------------------------------------------------------ | -------- |
| [dict](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:89:4-90:65) | `object` |
| `list`, `tuple`                                              | `array`  |
| `str`                                                        | `string` |
| `int`, `float`                                               | `number` |
| `True`                                                       | `true`   |
| `False`                                                      | `false`  |
| `None`                                                       | `null`   |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：字符串转换（类型转换）**
>
> ```python
> # backend/util/type.py
> import json
> 
> def __convert_list(value: Any) -> list:
>     if isinstance(value, str):
>         value = value.strip()
>         if value.startswith("[") and value.endswith("]"):
>             try:
>                 return json.loads(value)
>                 #      ^^^^^^^^^^^^^^^^^ 将 JSON 字符串解析为列表
>             except json.JSONDecodeError:
>                 return [value]  # 解析失败，返回包含原字符串的列表
>         else:
>             return [value]
> 
> def __convert_dict(value: Any) -> dict:
>     if isinstance(value, str):
>         try:
>             result = json.loads(value)
>             #        ^^^^^^^^^^^^^^^^^ 尝试解析 JSON 字符串
>             if isinstance(result, dict):
>                 return result
>             else:
>                 return {"value": result}
>         except json.JSONDecodeError:
>             return {"value": value}  # 解析失败，包装为字典
> ```
>
> **解释：**
> - 用于 Block 之间数据类型的智能转换
> - 例如：`"[1,2,3]"` → `[1, 2, 3]`
> - 例如：`'{"name": "Alice"}'` → `{"name": "Alice"}`
>
> ---
>
> #### **案例 2：配置文件读写**
>
> ```python
> # backend/util/settings.py
> import json
> import os
> 
> # 保存配置到 JSON 文件
> config_path = os.path.join(get_data_path(), "config.json")
> 
> if os.path.exists(config_path):
>     # 读取现有配置
>     with open(config_path, "r+") as f:
>         existing_config = json.load(f)
>         #                 ^^^^^^^^^^^^^^ 从文件读取 JSON
>         existing_config.update(config_to_save)
>         f.seek(0)  # 回到文件开头
>         json.dump(existing_config, f, indent=2)
>         #         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 写入文件，带缩进
>         f.truncate()  # 截断文件（删除多余内容）
> else:
>     # 创建新配置文件
>     with open(config_path, "w") as f:
>         json.dump(config_to_save, f, indent=2)
> ```
>
> **解释：**
> - 典型的配置文件管理模式
> - `json.load()` 读取文件
> - `json.dump()` 写入文件，`indent=2` 美化输出
> - `f.seek(0)` + `f.truncate()` 用于更新文件内容
>
> ---
>
> #### **案例 3：加密和解密**
>
> ```python
> # backend/util/encryption.py
> import json
> from cryptography.fernet import Fernet
> 
> class DataEncryption:
>     def encrypt(self, data: dict) -> str:
>         """加密字典数据为字符串"""
>         json_str = json.dumps(data)
>         #          ^^^^^^^^^^^^^^^^ 先转为 JSON 字符串
>         encrypted = self.fernet.encrypt(json_str.encode())
>         return encrypted.decode()
>     
>     def decrypt(self, encrypted_str: str) -> dict:
>         """解密字符串为字典"""
>         try:
>             decrypted = self.fernet.decrypt(encrypted_str.encode())
>             return json.loads(decrypted.decode())
>             #      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 解密后解析 JSON
>         except Exception:
>             return {}
> ```
>
> **解释：**
> - 先用 `json.dumps()` 序列化为字符串，再加密
> - 解密后用 `json.loads()` 反序列化回对象
>
> ---
>
> #### **案例 4：HTTP 响应解析**
>
> ```python
> # backend/util/request.py
> import json
> 
> class Response:
>     def json(self, encoding=None, **kwargs):
>         """解析响应体为 JSON 并返回 Python 对象"""
>         return json.loads(
>             self.content.decode(encoding or "utf-8", errors="replace"),
>             #                                                           ^^^^^^
>             #                                                           额外参数传给 json.loads
>             **kwargs
>         )
> 
> # 使用示例
> response = requests.get("https://api.example.com/data")
> data = response.json()  # 自动解析 JSON 响应
> ```
>
> ---
>
> #### **案例 5：测试快照（美化输出）**
>
> ```python
> # backend/server/v2/store/routes_test.py
> import json
> 
> # 从 WebSocket 接收的消息
> sent_message = mock_websocket.send_text.call_args[0][0]
> parsed_message = json.loads(sent_message)
> #                ^^^^^^^^^^^^^^^^^^^^^^^^ 解析 JSON 字符串
> 
> # 美化输出用于快照测试
> snapshot.assert_match(
>     json.dumps(parsed_message, indent=2, sort_keys=True),
>     #          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>     #          美化输出：缩进 2 空格，键排序
>     "snapshot_name"
> )
> ```
>
> **解释：**
> - `indent=2` - 每层缩进 2 空格，便于阅读
> - `sort_keys=True` - 键排序，保证输出一致性
> - 用于测试时的快照比对
>
> ---
>
> #### **案例 6：token 计数（非字符串处理）**
>
> ```python
> # backend/util/prompt.py
> import json
> 
> def count_tokens(text, model="gpt-4"):
>     enc = encoding_for_model(model)
>     text = json.dumps(text) if not isinstance(text, str) else text
>     #      ^^^^^^^^^^^^^^^^ 如果不是字符串，先序列化
>     return _tok_len(text, enc)
> 
> # 使用示例
> tokens = count_tokens({"role": "user", "content": "Hello"})
> # 先转为 '{"role": "user", "content": "Hello"}' 再计算 token
> ```
>
> ---
>
> #### **案例 7：紧凑格式（节省空间）**
>
> ```python
> # backend/util/prompt.py
> import json
> 
> # 将消息内容压缩为紧凑格式
> content_str = json.dumps(m["content"], separators=(",", ":"))
> #                                      ^^^^^^^^^^^^^^^^^^^^
> #                                      无空格的紧凑格式
> ```
>
> **解释：**
> - `separators=(",", ":")` - 最紧凑的格式
> - 默认：`{"a": 1, "b": 2}` (有空格)
> - 紧凑：`{"a":1,"b":2}` (无空格)
>

---

**详细功能讲解**

**1. 基础序列化（dumps/dump）**

```python
import json

# dumps - 对象转字符串
data = {"name": "Alice", "age": 30, "active": True}
json_string = json.dumps(data)
print(json_string)
# '{"name": "Alice", "age": 30, "active": true}'

# dump - 对象写入文件
with open("data.json", "w") as f:
    json.dump(data, f)
```

---

**2. 基础反序列化（loads/load）**

```python
import json

# loads - 字符串转对象
json_string = '{"name": "Bob", "age": 25}'
data = json.loads(json_string)
print(data)
# {'name': 'Bob', 'age': 25}

# load - 从文件读取
with open("data.json", "r") as f:
    data = json.load(f)
```

---

**3. 美化输出（indent）**

```python
import json

data = {
    "name": "Alice",
    "address": {
        "city": "Beijing",
        "street": "Changan Ave"
    },
    "hobbies": ["reading", "coding"]
}

# 不带缩进（紧凑）
compact = json.dumps(data)
print(compact)
# {"name":"Alice","address":{"city":"Beijing","street":"Changan Ave"},"hobbies":["reading","coding"]}

# 带缩进（美化）
pretty = json.dumps(data, indent=2)
print(pretty)
# {
#   "name": "Alice",
#   "address": {
#     "city": "Beijing",
#     "street": "Changan Ave"
#   },
#   "hobbies": [
#     "reading",
#     "coding"
#   ]
# }

# 也可以用制表符缩进
pretty_tab = json.dumps(data, indent="\t")
```

---

**4. 处理中文（ensure_ascii）**

```python
import json

data = {"姓名": "张三", "城市": "北京"}

# 默认：转义非 ASCII 字符
escaped = json.dumps(data)
print(escaped)
# {"\u59d3\u540d": "\u5f20\u4e09", "\u57ce\u5e02": "\u5317\u4eac"}

# ensure_ascii=False：不转义中文
chinese = json.dumps(data, ensure_ascii=False)
print(chinese)
# {"姓名": "张三", "城市": "北京"}

# 保存中文到文件
with open("chinese.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
```

---

**5. 排序键（sort_keys）**

```python
import json

data = {"z": 1, "a": 2, "m": 3}

# 不排序（保持原顺序，Python 3.7+）
unordered = json.dumps(data)
print(unordered)
# {"z": 1, "a": 2, "m": 3}

# 排序键
sorted_json = json.dumps(data, sort_keys=True)
print(sorted_json)
# {"a": 2, "m": 3, "z": 1}

# 用途：确保输出一致性，便于比较
```

---

**6. 紧凑格式（separators）**

```python
import json

data = {"name": "Alice", "age": 30}

# 默认格式
default = json.dumps(data)
print(default)
# {"name": "Alice", "age": 30}

# 紧凑格式（无空格）
compact = json.dumps(data, separators=(',', ':'))
print(compact)
# {"name":"Alice","age":30}

# 疏松格式（多空格）
loose = json.dumps(data, separators=(', ', ' : '))
print(loose)
# {"name" : "Alice", "age" : 30}
```

---

**7. 处理无法序列化的对象（default）**

```python
import json
from datetime import datetime, date
from decimal import Decimal

# 问题：某些对象无法直接序列化
data = {
    "time": datetime.now(),
    "date": date.today(),
    "price": Decimal("19.99")
}

try:
    json.dumps(data)
except TypeError as e:
    print(e)
    # Object of type datetime is not JSON serializable

# 解决方案 1：转为字符串
json_str = json.dumps(data, default=str)
print(json_str)
# {"time": "2024-01-01 12:00:00.123456", "date": "2024-01-01", "price": "19.99"}

# 解决方案 2：自定义序列化函数
def custom_serializer(obj):
    if isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, date):
        return obj.isoformat()
    elif isinstance(obj, Decimal):
        return float(obj)
    raise TypeError(f"Type {type(obj)} not serializable")

json_str = json.dumps(data, default=custom_serializer)
print(json_str)
# {"time": "2024-01-01T12:00:00.123456", "date": "2024-01-01", "price": 19.99}

# 解决方案 3：自定义编码器
class CustomEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

json_str = json.dumps(data, cls=CustomEncoder)
```

---

**8. 错误处理（JSONDecodeError）**

```python
import json

# 错误的 JSON
invalid_json = '{"name": "Alice", "age": }'  # 缺少值

try:
    data = json.loads(invalid_json)
except json.JSONDecodeError as e:
    print(f"JSON 解析错误")
    print(f"错误信息: {e.msg}")
    print(f"错误位置: 行 {e.lineno}, 列 {e.colno}")
    print(f"错误附近: ...{e.doc[max(0, e.pos-20):e.pos+20]}...")

# 实际应用：安全解析
def safe_json_loads(json_str, default=None):
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        return default

data = safe_json_loads('invalid json', default={})
print(data)  # {}
```

---

**9. 流式处理（大文件）**

> | 场景                     | 使用的 `json` 函数                      | 为什么需要？                                                 |
> | ------------------------ | --------------------------------------- | ------------------------------------------------------------ |
> | **生成巨大的 JSON 文件** | `json.dumps()` (在循环中对单个对象使用) | **内存效率**：避免在内存中构建一个巨大的 Python 列表，防止程序因内存耗尽而崩溃。 |
> | **解析巨大的 JSON 文件** | `json.loads()` (在循环中对单行使用)     | **内存效率**：逐行或逐块处理文件，而不是一次性将整个文件加载到内存中。 |

```python
import json

# 写入大量数据（流式）
with open("large_data.json", "w") as f:
    f.write("[\n")
    for i in range(1000000):
        data = {"id": i, "value": i * 2}
        json_str = json.dumps(data)
        f.write(json_str)
        if i < 999999:
            f.write(",\n")
    f.write("\n]")

# 读取大文件（逐行）
def read_json_lines(filename):
    with open(filename, "r") as f:
        for line in f:
            line = line.strip().rstrip(',')  # 移除逗号
            if line and line not in ['[', ']']:
                yield json.loads(line)

for item in read_json_lines("large_data.json"):
    print(item)
```

---

**10. 类型注解**

```python
import json
from typing import Dict, Any, List

def load_config(filename: str) -> Dict[str, Any]:
    """加载 JSON 配置文件"""
    with open(filename, "r") as f:
        return json.load(f)

def save_config(filename: str, config: Dict[str, Any]) -> None:
    """保存配置到 JSON 文件"""
    with open(filename, "w") as f:
        json.dump(config, f, indent=2)

# 使用
config: Dict[str, Any] = load_config("config.json")
users: List[Dict[str, str]] = json.loads('  [{"name": "Alice"}]')
```

---

**常见陷阱和注意事项**

**陷阱 1：混淆 dump 和 dumps**

```python
import json

data = {"name": "Alice"}

# ❌ 错误：dump 需要文件对象
json.dump(data)  # TypeError: missing required positional argument: 'fp'

# ✅ 正确：dump 写入文件
with open("file.json", "w") as f:
    json.dump(data, f)

# ✅ 正确：dumps 返回字符串
json_str = json.dumps(data)
```

**记忆技巧：**
- `dump` = dump to file（写入文件）
- `dumps` = dump to string（返回字符串，s = string）

---

**陷阱 2：中文乱码**

```python
data = {"name": "张三"}

# ❌ 问题：默认转义中文
json_str = json.dumps(data)
print(json_str)  # {"\u5f20\u4e09"}

# ✅ 正确：不转义中文
json_str = json.dumps(data, ensure_ascii=False)
print(json_str)  # {"name": "张三"}

# 保存文件时也要注意编码
with open("data.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
```

---

**陷阱 3：无法序列化的对象**

```python
from datetime import datetime

data = {"time": datetime.now()}

# ❌ 错误：datetime 无法序列化
json.dumps(data)  # TypeError: Object of type datetime is not JSON serializable

# ✅ 正确：使用 default 参数
json.dumps(data, default=str)
# 或
json.dumps(data, default=lambda x: x.isoformat() if isinstance(x, datetime) else str(x))
```

---

**陷阱 4：JSON 和 Python 的差异**

```python
import json

# JSON 使用 true/false/null，不是 True/False/None
json_str = '{"active": true, "data": null}'
data = json.loads(json_str)
print(data)  # {'active': True, 'data': None}  - 自动转换

# 元组会变成列表
data = {"coords": (10, 20)}
json_str = json.dumps(data)
loaded = json.loads(json_str)
print(loaded)  # {'coords': [10, 20]}  - 元组变成列表！
print(type(loaded["coords"]))  # <class 'list'>
```

---

**陷阱 5：浮点精度问题**

```python
import json

# 浮点数精度可能有问题
data = {"price": 0.1 + 0.2}
json_str = json.dumps(data)
print(json_str)  # {"price": 0.30000000000000004}

# 解决方案：使用 Decimal 或四舍五入
from decimal import Decimal
data = {"price": float(Decimal("0.1") + Decimal("0.2"))}
json_str = json.dumps(data)
print(json_str)  # {"price": 0.3}
```

---

#### **总结：json 模块核心要点**

**必须掌握**

| 功能        | 方法           | 用途     |
| ----------- | -------------- | -------- |
| 对象→字符串 | `json.dumps()` | 序列化   |
| 字符串→对象 | `json.loads()` | 反序列化 |
| 对象→文件   | `json.dump()`  | 保存文件 |
| 文件→对象   | `json.load()`  | 读取文件 |

**常用参数**

| 参数                    | 作用                 |
| ----------------------- | -------------------- |
| `indent=2`              | 美化输出             |
| `ensure_ascii=False`    | 不转义中文           |
| `sort_keys=True`        | 排序键               |
| `default=str`           | 处理无法序列化的对象 |
| `separators=(',', ':')` | 紧凑格式             |

**类型转换**

- [dict](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:89:4-90:65) ↔ JSON object
- `list/tuple` ↔ JSON array
- `str` ↔ JSON string
- `int/float` ↔ JSON number
- `True/False` ↔ `true/false`
- `None` ↔ `null`

### 5.`datetime` - 日期时间

**什么是 datetime？**

- Python 标准库，用于处理**日期和时间**
- 提供日期、时间、时区等操作
- 标准库，无需安装

**核心功能速查表**

**主要类**

| 类          | 作用      | 示例                            |
| ----------- | --------- | ------------------------------- |
| `datetime`  | 日期+时间 | `datetime(2024, 1, 15, 14, 30)` |
| `date`      | 仅日期    | `date(2024, 1, 15)`             |
| `time`      | 仅时间    | `time(14, 30, 0)`               |
| `timedelta` | 时间差    | `timedelta(days=1, hours=2)`    |
| `timezone`  | 时区      | `timezone.utc`                  |

**创建时间对象**

| 方法                         | 作用             | 示例                    |
| ---------------------------- | ---------------- | ----------------------- |
| `datetime.now()`             | 当前时间（本地） | `2024-01-15 14:30:00`   |
| `datetime.utcnow()`          | 当前时间（UTC）  | `2024-01-15 06:30:00`   |
| `datetime.today()`           | 今天日期+时间    | 同 `now()`              |
| `date.today()`               | 今天日期         | `2024-01-15`            |
| `datetime(year, month, day)` | 指定日期时间     | `datetime(2024, 1, 15)` |

**时间格式化**

| 方法                             | 作用          |
| -------------------------------- | ------------- |
| `.strftime(format)`              | 时间 → 字符串 |
| `datetime.strptime(str, format)` | 字符串 → 时间 |
| `.isoformat()`                   | ISO 8601 格式 |

**常用格式代码**

| 代码 | 含义         | 示例     |
| ---- | ------------ | -------- |
| `%Y` | 4位年份      | `2024`   |
| `%m` | 2位月份      | `01`     |
| `%d` | 2位日期      | `15`     |
| `%H` | 24小时制小时 | `14`     |
| `%M` | 分钟         | `30`     |
| `%S` | 秒           | `00`     |
| `%f` | 微秒         | `123456` |

**时间属性**

| 属性           | 作用           |
| -------------- | -------------- |
| `.year`        | 年             |
| `.month`       | 月             |
| `.day`         | 日             |
| `.hour`        | 小时           |
| `.minute`      | 分钟           |
| `.second`      | 秒             |
| `.microsecond` | 微秒           |
| `.weekday()`   | 星期（0=周一） |

**时间运算**

| 操作             | 作用                     |
| ---------------- | ------------------------ |
| `dt1 - dt2`      | 时间差（返回 timedelta） |
| `dt + timedelta` | 加时间                   |
| `dt - timedelta` | 减时间                   |
| `dt1 < dt2`      | 比较                     |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：时区转换（UTC ↔ 用户时区）**
>
> ```python
> # backend/util/timezone_utils.py
> from datetime import datetime
> from zoneinfo import ZoneInfo
> 
> def convert_utc_time_to_user_timezone(utc_time_str: str, user_timezone: str) -> str:
>     """将 UTC 时间转换为用户时区"""
>     
>     # 解析 ISO 格式时间字符串
>     parsed_time = datetime.fromisoformat(utc_time_str.replace("Z", "+00:00"))
>     #             ^^^^^^^^^^^^^^^^^^^^^^ 解析 ISO 格式
>     
>     user_tz = ZoneInfo(user_timezone)  # 用户时区
>     
>     # 如果已有时区信息，转换到用户时区
>     if parsed_time.tzinfo is not None:
>         user_time = parsed_time.astimezone(user_tz)
>         #                       ^^^^^^^^^^^^^^^^^^^ 时区转换
>         return user_time.isoformat()
>     
>     # 如果没有时区信息，假定为 UTC
>     parsed_time = parsed_time.replace(tzinfo=ZoneInfo("UTC"))
>     user_time = parsed_time.astimezone(user_tz)
>     return user_time.isoformat()
> 
> # 使用示例
> utc_time = "2024-01-15T14:30:00Z"
> beijing_time = convert_utc_time_to_user_timezone(utc_time, "Asia/Shanghai")
> # "2024-01-15T22:30:00+08:00"  (UTC+8)
> ```
>
> ---
>
> #### **案例 2：获取当前时间（带时区）**
>
> ```python
> # backend/util/timezone_utils.py
> from datetime import datetime
> from zoneinfo import ZoneInfo
> 
> def convert_cron_to_utc(cron_expr: str, user_timezone: str) -> str:
>     """转换 cron 表达式到 UTC"""
>     
>     user_tz = ZoneInfo(user_timezone)
>     
>     # 获取用户时区的当前时间
>     now_user = datetime.now(user_tz)
>     #          ^^^^^^^^^^^^^^^^^^^^^ 带时区的当前时间
>     
>     # 获取下一次触发时间
>     from croniter import croniter
>     cron = croniter(cron_expr, now_user)
>     next_user_time = cron.get_next(datetime)
>     
>     # 转换到 UTC
>     utc_tz = ZoneInfo("UTC")
>     next_utc_time = next_user_time.astimezone(utc_tz)
>     
>     return utc_cron
> 
> # 使用示例：用户在北京，设置每天 9:00 执行
> # 用户输入：0 9 * * * (北京时间 9:00)
> # 转换结果：0 1 * * * (UTC 1:00，即北京时间 9:00)
> ```
>
> ---
>
> #### **案例 3：时间计算和比较**
>
> ```python
> # backend/executor/manager.py
> from datetime import datetime, timedelta, timezone
> 
> # 计算执行超时时间
> execution_start = datetime.now(timezone.utc)
> timeout = timedelta(minutes=30)
> deadline = execution_start + timeout
> #                            ^^^^^^^^ 时间加法
> 
> # 检查是否超时
> if datetime.now(timezone.utc) > deadline:
>     #                           ^^^^^^^^^ 时间比较
>     raise TimeoutError("执行超时")
> 
> # 计算执行时长
> execution_end = datetime.now(timezone.utc)
> duration = execution_end - execution_start
> #                        ^^^^^^^^^^^^^^^^^^ 时间减法，返回 timedelta
> print(f"执行耗时: {duration.total_seconds()} 秒")
> ```
>
> ---
>
> #### **案例 4：ISO 格式解析**
>
> ```python
> # backend/util/timezone_utils.py
> from datetime import datetime
> 
> # 解析 ISO 8601 格式
> utc_time_str = "2024-01-15T14:30:00Z"
> parsed_time = datetime.fromisoformat(utc_time_str.replace("Z", "+00:00"))
> #             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> #             fromisoformat 不直接支持 'Z'，需要替换为 '+00:00'
> 
> # 或者使用标准格式
> iso_time = "2024-01-15T14:30:00+08:00"
> parsed = datetime.fromisoformat(iso_time)
> print(parsed)  # 2024-01-15 14:30:00+08:00
> ```
>
> ---
>
> #### **案例 5：时区验证**
>
> ```python
> # backend/util/timezone_utils.py
> from zoneinfo import ZoneInfo
> 
> def validate_timezone(timezone: str) -> bool:
>     """验证时区字符串是否有效"""
>     try:
>         ZoneInfo(timezone)
>         return True
>     except Exception:
>         return False
> 
> def get_user_timezone_or_utc(user_timezone: Optional[str]) -> str:
>     """获取用户时区或默认 UTC"""
>     if not user_timezone or user_timezone == "not-set":
>         return "UTC"
>     
>     if validate_timezone(user_timezone):
>         return user_timezone
>     
>     logger.warning(f"无效时区 '{user_timezone}'，使用 UTC")
>     return "UTC"
> 
> # 使用
> user_tz = get_user_timezone_or_utc("Asia/Shanghai")  # "Asia/Shanghai"
> user_tz = get_user_timezone_or_utc("Invalid/Zone")   # "UTC"
> ```
>
> ---
>
> #### **案例 6：测试中的时间模拟**
>
> ```python
> # backend/util/test.py
> from datetime import datetime, timezone
> import uuid
> 
> # 测试默认参数
> test_context = {
>     "graph_exec_id": str(uuid.uuid4()),
>     "node_exec_id": str(uuid.uuid4()),
>     "user_id": str(uuid.uuid4()),
>     "user_context": UserContext(timezone="UTC"),  # 测试默认时区
> }
> ```
>
> ---
>

**详细功能讲解**

**1. 创建日期时间对象**

```python
from datetime import datetime, date, time

# 当前时间（本地时区）
now = datetime.now()
print(now)  # 2024-01-15 14:30:00.123456

# 当前时间（UTC）
utc_now = datetime.utcnow()  # 已弃用，推荐用下面的方式
print(utc_now)  # 2024-01-15 06:30:00.123456

# 带时区的当前时间（推荐）
from datetime import timezone
utc_now = datetime.now(timezone.utc)
print(utc_now)  # 2024-01-15 06:30:00.123456+00:00

# 今天日期
today = date.today()
print(today)  # 2024-01-15

# 指定日期时间
dt = datetime(2024, 1, 15, 14, 30, 0)
#             年    月  日  时  分  秒
print(dt)  # 2024-01-15 14:30:00

# 仅日期
d = date(2024, 1, 15)
print(d)  # 2024-01-15

# 仅时间
t = time(14, 30, 0)
print(t)  # 14:30:00

# 从时间戳创建
timestamp = 1705315800
dt = datetime.fromtimestamp(timestamp)
print(dt)  # 2024-01-15 14:30:00

# UTC 时间戳
dt = datetime.utcfromtimestamp(timestamp)
```

---

**2. 时间格式化（strftime）**

```python
from datetime import datetime

now = datetime.now()

# 常用格式
print(now.strftime("%Y-%m-%d"))           # 2024-01-15
print(now.strftime("%Y-%m-%d %H:%M:%S"))  # 2024-01-15 14:30:00
print(now.strftime("%Y/%m/%d"))           # 2024/01/15
print(now.strftime("%m/%d/%Y"))           # 01/15/2024（美国格式）
print(now.strftime("%d.%m.%Y"))           # 15.01.2024（欧洲格式）

# 12小时制
print(now.strftime("%I:%M %p"))           # 02:30 PM
print(now.strftime("%I:%M:%S %p"))        # 02:30:00 PM

# 星期
print(now.strftime("%A"))                 # Monday
print(now.strftime("%a"))                 # Mon
print(now.strftime("%w"))                 # 1（0=周日）

# 月份
print(now.strftime("%B"))                 # January
print(now.strftime("%b"))                 # Jan

# 完整示例
print(now.strftime("%A, %B %d, %Y %I:%M %p"))
# Monday, January 15, 2024 02:30 PM

# 中文格式
print(now.strftime("%Y年%m月%d日 %H:%M:%S"))
# 2024年01月15日 14:30:00
```

**格式代码速查：**

```python
# 日期
%Y  # 4位年份: 2024
%y  # 2位年份: 24
%m  # 2位月份: 01-12
%B  # 月份全名: January
%b  # 月份缩写: Jan
%d  # 2位日期: 01-31
%A  # 星期全名: Monday
%a  # 星期缩写: Mon
%w  # 星期数字: 0-6 (0=周日)

# 时间
%H  # 24小时制: 00-23
%I  # 12小时制: 01-12
%M  # 分钟: 00-59
%S  # 秒: 00-59
%f  # 微秒: 000000-999999
%p  # AM/PM

# 其他
%j  # 一年中的第几天: 001-366
%U  # 一年中的第几周: 00-53
%z  # UTC偏移: +0800
%Z  # 时区名称: CST
```

---

**3. 解析字符串（strptime）**

```python
from datetime import datetime

# 基础解析
date_str = "2024-01-15"
dt = datetime.strptime(date_str, "%Y-%m-%d")
print(dt)  # 2024-01-15 00:00:00

# 带时间
datetime_str = "2024-01-15 14:30:00"
dt = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M:%S")
print(dt)  # 2024-01-15 14:30:00

# 12小时制
time_str = "01/15/2024 02:30 PM"
dt = datetime.strptime(time_str, "%m/%d/%Y %I:%M %p")
print(dt)  # 2024-01-15 14:30:00

# ISO 8601 格式（推荐）
iso_str = "2024-01-15T14:30:00"
dt = datetime.fromisoformat(iso_str)
print(dt)  # 2024-01-15 14:30:00

# 带时区的 ISO 格式
iso_tz = "2024-01-15T14:30:00+08:00"
dt = datetime.fromisoformat(iso_tz)
print(dt)  # 2024-01-15 14:30:00+08:00

# 实际应用：容错解析
def parse_date(date_str):
    formats = [
        "%Y-%m-%d",
        "%Y/%m/%d",
        "%d-%m-%Y",
        "%m/%d/%Y",
    ]
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    raise ValueError(f"无法解析日期: {date_str}")

# 使用
dt1 = parse_date("2024-01-15")  # ✅
dt2 = parse_date("2024/01/15")  # ✅
dt3 = parse_date("15-01-2024")  # ✅
```

---

**4. 时间运算（timedelta）**

```python
from datetime import datetime, timedelta

now = datetime.now()

# 加时间
tomorrow = now + timedelta(days=1)
one_hour_later = now + timedelta(hours=1)
next_week = now + timedelta(weeks=1)

# 减时间
yesterday = now - timedelta(days=1)
one_hour_ago = now - timedelta(hours=1)

# 复杂运算
future = now + timedelta(days=7, hours=3, minutes=30, seconds=10)

# 计算时间差
dt1 = datetime(2024, 1, 15)
dt2 = datetime(2024, 1, 1)
diff = dt1 - dt2
#            ^^^^^^ 返回 timedelta 对象

print(diff.days)           # 14（天数）
print(diff.seconds)        # 0（秒数，不包括天）
print(diff.total_seconds()) # 1209600.0（总秒数）

# 实际应用：计算年龄
from datetime import date

def calculate_age(birth_date):
    today = date.today()
    age = today.year - birth_date.year
    # 检查今年是否已过生日
    if (today.month, today.day) < (birth_date.month, birth_date.day):
        age -= 1
    return age

birth = date(1990, 3, 15)
age = calculate_age(birth)
print(f"年龄: {age} 岁")
```

**timedelta 参数：**
```python
timedelta(
    days=0,
    seconds=0,
    microseconds=0,
    milliseconds=0,
    minutes=0,
    hours=0,
    weeks=0
)
```

---

**5. 时间比较**

```python
from datetime import datetime

dt1 = datetime(2024, 1, 15, 14, 30)
dt2 = datetime(2024, 1, 16, 10, 00)

# 比较运算符
print(dt1 < dt2)   # True（dt1 更早）
print(dt1 > dt2)   # False
print(dt1 == dt2)  # False
print(dt1 != dt2)  # True

# 最大/最小
dates = [
    datetime(2024, 1, 15),
    datetime(2024, 3, 20),
    datetime(2024, 2, 10),
]
earliest = min(dates)  # 2024-01-15
latest = max(dates)    # 2024-03-20

# 实际应用：检查日期范围
def is_date_in_range(check_date, start_date, end_date):
    return start_date <= check_date <= end_date

event_date = datetime(2024, 1, 15)
start = datetime(2024, 1, 1)
end = datetime(2024, 1, 31)

if is_date_in_range(event_date, start, end):
    print("日期在范围内")
```

---

**6. 时区处理**

```python
from datetime import datetime, timezone
from zoneinfo import ZoneInfo  # Python 3.9+

# UTC 时间
utc_now = datetime.now(timezone.utc)
print(utc_now)  # 2024-01-15 06:30:00+00:00

# 指定时区（使用 zoneinfo）
beijing_tz = ZoneInfo("Asia/Shanghai")
beijing_now = datetime.now(beijing_tz)
print(beijing_now)  # 2024-01-15 14:30:00+08:00

ny_tz = ZoneInfo("America/New_York")
ny_now = datetime.now(ny_tz)
print(ny_now)  # 2024-01-15 01:30:00-05:00

# 时区转换
utc_time = datetime.now(timezone.utc)
beijing_time = utc_time.astimezone(ZoneInfo("Asia/Shanghai"))
#                       ^^^^^^^^^^^ 转换时区
print(beijing_time)  # UTC+8

# 移除时区信息
naive_time = beijing_time.replace(tzinfo=None)
print(naive_time)  # 2024-01-15 14:30:00（无时区）

# 添加时区信息
naive = datetime(2024, 1, 15, 14, 30)
aware = naive.replace(tzinfo=ZoneInfo("Asia/Shanghai"))
print(aware)  # 2024-01-15 14:30:00+08:00

# 常用时区列表
import zoneinfo
available_zones = sorted(zoneinfo.available_timezones())
print(available_zones[:10])
# ['Africa/Abidjan', 'Africa/Accra', ...]
```

---

**7. 时间属性和方法**

```python
from datetime import datetime

dt = datetime(2024, 1, 15, 14, 30, 45, 123456)

# 基本属性
print(dt.year)        # 2024
print(dt.month)       # 1
print(dt.day)         # 15
print(dt.hour)        # 14
print(dt.minute)      # 30
print(dt.second)      # 45
print(dt.microsecond) # 123456

# 星期
print(dt.weekday())   # 0（0=周一，6=周日）
print(dt.isoweekday())# 1（1=周一，7=周日）

# ISO 格式
print(dt.isoformat())       # "2024-01-15T14:30:45.123456"
print(dt.date())            # 2024-01-15（仅日期）
print(dt.time())            # 14:30:45.123456（仅时间）

# 时间戳
print(dt.timestamp())       # 1705308645.123456

# 替换部分值
new_dt = dt.replace(year=2025, month=12)
print(new_dt)  # 2025-12-15 14:30:45.123456

# 获取日期和时间组件
print(dt.date())  # 2024-01-15
print(dt.time())  # 14:30:45.123456
```

---

**8. 特殊日期计算**

```python
from datetime import datetime, timedelta
import calendar

# 本月第一天
today = datetime.now()
first_day = today.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
print(first_day)

# 本月最后一天
last_day_num = calendar.monthrange(today.year, today.month)[1]
last_day = today.replace(day=last_day_num, hour=23, minute=59, second=59)
print(last_day)

# 下个月第一天
if today.month == 12:
    next_month_first = datetime(today.year + 1, 1, 1)
else:
    next_month_first = datetime(today.year, today.month + 1, 1)

# 本周一
monday = today - timedelta(days=today.weekday())
monday = monday.replace(hour=0, minute=0, second=0, microsecond=0)

# 本周日
sunday = monday + timedelta(days=6, hours=23, minutes=59, seconds=59)

# 今天的开始和结束
today_start = today.replace(hour=0, minute=0, second=0, microsecond=0)
today_end = today.replace(hour=23, minute=59, second=59, microsecond=999999)

print(f"今天: {today_start} 到 {today_end}")
```

---

**常见陷阱和注意事项**

**陷阱 1：混淆 aware 和 naive 时间**

```python
from datetime import datetime, timezone

# naive - 没有时区信息
naive = datetime.now()
print(naive.tzinfo)  # None

# aware - 有时区信息
aware = datetime.now(timezone.utc)
print(aware.tzinfo)  # UTC

# ❌ 错误：不能直接比较
try:
    naive < aware
except TypeError as e:
    print(e)  # can't compare offset-naive and offset-aware datetimes

# ✅ 正确：都转为 aware
naive_utc = naive.replace(tzinfo=timezone.utc)
print(naive_utc < aware)  # 可以比较了
```

---

**陷阱 2：datetime.utcnow() 已弃用**

```python
from datetime import datetime, timezone

# ❌ 不推荐：utcnow() 返回 naive 时间
utc_naive = datetime.utcnow()
print(utc_naive.tzinfo)  # None

# ✅ 推荐：使用 timezone.utc
utc_aware = datetime.now(timezone.utc)
print(utc_aware.tzinfo)  # UTC
```

---

**陷阱 3：月份/日期的天数变化**

```python
from datetime import datetime, timedelta

# ❌ 危险：直接加 30 天不等于加 1 个月
date = datetime(2024, 1, 31)
one_month_later = date + timedelta(days=30)
print(one_month_later)  # 2024-03-01（跳过了 2 月）

# ✅ 正确：使用 dateutil 或手动处理
from dateutil.relativedelta import relativedelta
one_month_later = date + relativedelta(months=1)
print(one_month_later)  # 2024-02-29（2月最后一天）
```

---

**陷阱 4：时区名称 'Z' 的处理**

```python
from datetime import datetime

iso_str = "2024-01-15T14:30:00Z"  # 'Z' 表示 UTC

# ❌ 错误：fromisoformat 不支持 'Z'
try:
    dt = datetime.fromisoformat(iso_str)
except ValueError as e:
    print(e)  # Invalid isoformat string

# ✅ 正确：替换 'Z' 为 '+00:00'
dt = datetime.fromisoformat(iso_str.replace("Z", "+00:00"))
print(dt)  # 2024-01-15 14:30:00+00:00
```

---

**陷阱 5：冬令时/夏令时问题**

```python
from datetime import datetime
from zoneinfo import ZoneInfo

# 在有夏令时的地区，时间计算可能不准确
ny_tz = ZoneInfo("America/New_York")

# 2024年3月10日凌晨2点，美国进入夏令时，时钟拨快1小时
dt = datetime(2024, 3, 10, 1, 30, tzinfo=ny_tz)
one_hour_later = dt + timedelta(hours=1)
print(one_hour_later)  # 可能跳到 3:30 而不是 2:30

# ✅ 使用 astimezone 进行正确的时区感知计算
```

---

#### **总结：datetime 模块核心要点**

**必须掌握**

| 功能     | 方法                             | 用途        |
| -------- | -------------------------------- | ----------- |
| 当前时间 | `datetime.now()`                 | 本地时间    |
| UTC时间  | `datetime.now(timezone.utc)`     | UTC时间     |
| 格式化   | `.strftime(format)`              | 时间→字符串 |
| 解析     | `datetime.strptime(str, format)` | 字符串→时间 |
| ISO格式  | `datetime.fromisoformat()`       | 解析ISO     |
| 时间差   | `timedelta(days, hours)`         | 时间运算    |

**常用操作**

- 时间加减：`dt + timedelta(days=1)`
- 时间比较：`dt1 < dt2`
- 时区转换：`dt.astimezone(tz)`
- 获取属性：`.year`, `.month`, `.day`, `.hour`

**最佳实践**

1. 始终使用带时区的时间（aware datetime）
2. 使用 `datetime.now(timezone.utc)` 而非 `datetime.utcnow()`
3. 使用 `fromisoformat()` 解析 ISO 格式
4. 存储时使用 UTC，显示时转换为用户时区

### 6.`typing` - 类型注解

类型注解是 Python 3.5+ 引入的特性，用于**标注变量、函数参数和返回值的类型**。

**没有类型注解（旧式）**

```python
def add(a, b):
    return a + b

result = add(1, 2)  # 可以运行，但不知道 a、b 应该是什么类型
```

**有类型注解（现代）**

```python
def add(a: int, b: int) -> int:
    #      ↑ int  ↑ int    ↑ 返回 int
    return a + b

result: int = add(1, 2)  # 清晰：输入输出都是 int
```

---

 **为什么需要类型注解？**

1. 代码提示（IDE 支持）

```python
def get_user(user_id: int) -> dict:
    return {"id": user_id, "name": "Alice"}

user = get_user(1)
user.  # ← IDE 会提示 dict 的方法：keys(), values(), get() 等
```

2. 错误检查

```python
def process(data: str) -> int:
    return len(data)

# 类型检查工具（如 mypy）会报错
result = process(123)  # ❌ 传入 int，应该是 str
```

3. 自动文档

```python
def create_user(name: str, age: int, email: str) -> dict:
    """不需要额外说明参数类型，一目了然"""
    return {"name": name, "age": age, "email": email}
```

4. 重构保障

当你修改函数签名时，类型检查器会告诉你哪些地方需要更新。

**基础类型（不需要导入 typing）**

```python
# Python 内置类型可以直接用
name: str = "Alice"
age: int = 30
price: float = 9.99
is_active: bool = True
data: list = [1, 2, 3]
config: dict = {"key": "value"}
users: tuple = (1, 2, 3)
tags: set = {"python", "typing"}
```

**从 typing 导入的高级类型**

```python
from typing import List, Dict, Tuple, Set, Optional, Union, Any
```

**1. `Any` - 任意类型**

```python
from typing import Any

data: Any = "可以是任何类型"
data = 123        # ✅ 可以
data = [1, 2, 3]  # ✅ 也可以
data = {"a": 1}   # ✅ 都可以
```

**在 AutoGPT Platform 中的使用：** 

```python
# backend/blocks/basic.py
class Input(BlockSchema):
 text: Any = SchemaField(description="任意类型的数据")
 #     ^^^ 接受任何类型
```

---

**2. `Optional` - 可选类型（可以是 None）**

```python
from typing import Optional

# Optional[str] 等价于 str | None
name: Optional[str] = None
name = "Alice"  # ✅
name = None     # ✅
name = 123      # ❌ 类型错误
```

**实际应用：**
```python
def get_user(user_id: int) -> Optional[dict]:
 if user_id > 0:
     return {"id": user_id, "name": "Alice"}
 return None  # 可能返回 None
```

**在 AutoGPT Platform 中：**
```python
# backend/data/model.py
class User(BaseModel):
 name: Optional[str] = None  # 可选字段
 #     ^^^^^^^^^^^^^^
```

---

**3. `Union` - 多种类型之一**

```python
from typing import Union

# 可以是 int 或 str
value: Union[int, str] = 10
value = "hello"  # ✅
value = 10       # ✅
value = 3.14     # ❌ 类型错误

# 现代写法（Python 3.10+）
value: int | str = 10
```

**实际应用：**
```python
def process(data: Union[str, list]) -> str:
 if isinstance(data, str):
     return data
 elif isinstance(data, list):
     return ", ".join(data)
```

---

**4. `List`, `Dict`, `Tuple`, `Set` - 容器类型**

```python
from typing import List, Dict, Tuple, Set

# List[类型] - 列表，所有元素是同一类型
numbers: List[int] = [1, 2, 3]
names: List[str] = ["Alice", "Bob"]

# Dict[键类型, 值类型] - 字典
user: Dict[str, int] = {"age": 30, "score": 100}
config: Dict[str, Any] = {"name": "Alice", "age": 30}

# Tuple[类型1, 类型2, ...] - 元组（固定长度）
point: Tuple[int, int] = (10, 20)
user: Tuple[str, int, bool] = ("Alice", 30, True)

# Set[类型] - 集合
tags: Set[str] = {"python", "typing"}
```

**在 AutoGPT Platform 中：**
```python
# backend/blocks/basic.py
class Input(BlockSchema):
 input_list: list[Any] = SchemaField(description="列表")
 #           ^^^^^^^^^^

# backend/data/block.py
def get_blocks() -> dict[str, type[Block]]:
 #               ^^^^^^^^^^^^^^^^^^^^^^^^ 返回字典
 return {"block_id": BlockClass}
```

---

**5. `Callable` - 函数类型**

```python
from typing import Callable

# Callable[[参数类型], 返回类型]
def process(callback: Callable[[int, str], bool]) -> None:
 #                 ^^^^^^^^^^^^^^^^^^^^^^^^^^ 接收一个函数
 result = callback(10, "hello")

# 使用
def my_function(num: int, text: str) -> bool:
 return num > 5 and len(text) > 0

process(my_function)
```

**在 AutoGPT Platform 中：**
```python
# backend/data/block.py
BlockTestOutput = BlockOutputEntry | tuple[str, Callable[[Any], bool]]
#                                           ^^^^^^^^^^^^^^^^^^^^^^^^ 函数类型
```

---

**6. `Sequence` - 序列类型**

```python
from typing import Sequence

# 可以是 list, tuple 等序列
def print_items(items: Sequence[str]) -> None:
 for item in items:
     print(item)

print_items(["a", "b"])        # ✅ list
print_items(("a", "b"))        # ✅ tuple
print_items("ab")              # ✅ str 也是序列
```

---

**7. `Type` - 类型本身**

```python
from typing import Type

class Animal:
 pass

class Dog(Animal):
 pass

# 注意：不是实例，而是类本身
def create_animal(animal_class: Type[Animal]) -> Animal:
 #                            ^^^^^^^^^^^^^ 传入类，不是实例
 return animal_class()

dog = create_animal(Dog)  # 传入 Dog 类
```

**在 AutoGPT Platform 中：**
```python
# backend/blocks/__init__.py
def get_blocks() -> dict[str, type[Block]]:
 #                             ^^^^^^^^^^ 返回 Block 类，不是实例
 available_blocks: dict[str, type[Block]] = {}
 for block_cls in all_subclasses(Block):
     block = block_cls()  # 这里才创建实例
```

---

**8. `TypeVar` - 泛型类型变量**

```python
from typing import TypeVar, List

T = TypeVar('T')  # 定义一个类型变量

def first(items: List[T]) -> T:
 #              ^^^^^^    ^^^ 返回类型与输入类型相同
 return items[0]

# 使用
num = first([1, 2, 3])      # num 是 int
text = first(["a", "b"])    # text 是 str
```

**在 AutoGPT Platform 中：**
```python
# backend/util/type.py
T = TypeVar("T")

def convert(value: Any, target_type: Type[T]) -> T:
 #                                    ^^^^    ^^^ 返回指定类型
 return _try_convert(value, target_type)
```

---

**9. `Generic` - 泛型类**

```python
from typing import Generic, TypeVar

T = TypeVar('T')

class Box(Generic[T]):
 def __init__(self, content: T):
     self.content = content

 def get(self) -> T:
     return self.content

# 使用
int_box = Box[int](123)        # Box 装 int
str_box = Box[str]("hello")    # Box 装 str
```

---

**10. `TYPE_CHECKING` - 避免循环导入**

```python
from typing import TYPE_CHECKING

if TYPE_CHECKING:
 # 这里的导入只在类型检查时生效，运行时不执行
 from .graph import Link

class Block:
 def process(self, link: "Link") -> None:  # 使用字符串形式
     #                 ^^^^^^ 前向引用
     pass
```

**在 AutoGPT Platform 中：**
```python
# backend/data/block.py
if TYPE_CHECKING:
 from .graph import Link  # 避免循环导入
```

> ## **AutoGPT Platform 中的实际应用**
>
> ### **示例 1：Block 的类型注解**
>
> ```python
> # backend/data/block.py
> from typing import AsyncGenerator as AsyncGen, Any
> 
> BlockOutputEntry = tuple[str, Any]
> #                  ^^^^^^^^^^^^^^^ Tuple 类型注解
> 
> BlockOutput = AsyncGen[BlockOutputEntry, None]
> #             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 异步生成器类型
> ```
>
> ### **示例 2：函数类型注解**
>
> ```python
> # backend/blocks/basic.py
> async def run(
>     self, 
>     input_data: Input,      # 参数类型
>     **kwargs               # 可变关键字参数
> ) -> BlockOutput:          # 返回类型
>     yield "output", input_data.data or input_data.input
> ```
>
> ### **示例 3：Pydantic 模型中的类型注解**
>
> ```python
> from typing import Any
> from pydantic import BaseModel
> 
> class Input(BaseModel):
>     text: Any = SchemaField(description="...")
>     #     ^^^ 类型注解，Pydantic 会自动验证
>     limit: int = 10
>     #      ^^^ 必须是 int
>     advanced: bool = False
>     #         ^^^^ 必须是 bool
> ```
>

#### 总结：typing 的核心要点

| 类型            | 用途         | 示例                         | **何时使用 (When to Use)**                                   |
| --------------- | ------------ | ---------------------------- | ------------------------------------------------------------ |
| `Any`           | 任意类型     | `data: Any`                  | **作为最后的手段**。当你处理来自外部 API 或动态来源的数据，其结构完全未知或变化多端时使用。它实际上关闭了对该变量的类型检查。在 AutoGPT 中，一个 Agent Block 可能会接收一个来自网页抓取的、结构不确定的 JSON 对象，此时可以用 `Any` 来注解。 |
| `Optional[T]`   | T 或 None    | `name: Optional[str]`        | **非常常用**。当一个变量可以是类型 `T`，也**可能为 `None`** 时使用。最常见的场景是函数的可选参数，其默认值为 `None`。例如，`def get_user(user_id: int, middle_name: Optional[str] = None): ...`。 |
| `Union[T1, T2]` | T1 或 T2     | `value: Union[int, str]`     | 当一个变量可以是**几种明确、已知的类型之一**时使用。例如，一个函数接受的 ID 可能是数据库中的整数 (`int`)，也可能是一个 UUID 字符串 (`str`)：`def process_id(item_id: Union[int, str]): ...`。它比 `Any` 更具体，因此更好。 |
| `List[T]`       | 列表         | `items: List[int]`           | 当你需要一个列表，并且希望**列表中所有元素的类型都相同**时使用。例如，一个 API 端点返回一个任务 ID 列表：`task_ids: List[int]`。 |
| `Dict[K, V]`    | 字典         | `config: Dict[str, str]`     | 当你需要一个字典，并且希望**所有键的类型为 `K`，所有值的类型为 `V`** 时使用。例如，加载环境变量：`env_vars: Dict[str, str] = os.environ`。 |
| `Tuple[T1, T2]` | 元组         | `point: Tuple[int, int]`     | 当你需要一个**固定长度**的元组，并且**每个位置上的元素类型是确定的**时使用。例如，返回一个包含经纬度的坐标点：`location: Tuple[float, float]`。如果元组长度可变但元素类型相同，使用 `Tuple[T, ...]`。 |
| `Callable`      | 函数         | `func: Callable[[int], str]` | 当你需要将**函数作为参数传递**或从函数返回时使用。它描述了函数（或任何可调用对象）的签名。`Callable[[int], str]` 表示一个函数，它接受一个 `int` 参数并返回一个 `str`。这在实现回调函数或插件系统时非常有用。 |
| `Type[T]`       | 类本身       | `cls: Type[Block]`           | 当你引用的不是一个类的**实例**，而是**类本身**时使用。这在工厂模式或类的构造方法 (`@classmethod`) 中很常见。在 AutoGPT 中，一个 Block 注册表可能会存储 Block 的类，而不是它们的实例：`BLOCK_REGISTRY: Dict[str, Type[Block]]`。 |
| `TypeVar`       | 泛型变量     | `T = TypeVar('T')`           | 当你希望一个函数能够处理多种类型，并且输入和输出类型之间存在某种关联时使用。例如，`def get_first(items: List[T]) -> T: return items[0]`，这个函数可以接受 `List[int]` 并返回 `int`，也可以接受 `List[str]` 并返回 `str`。 |
| `TYPE_CHECKING` | 避免循环导入 | `if TYPE_CHECKING:`          | **循环导入 (Circular Import)** 指的是两个或多个 Python 模块（`.py` 文件）相互导入对方，形成了一个闭环依赖 |

### 7. [logging](cci:7://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/autogpt_libs/autogpt_libs/logging:0:0-0:0) - 日志记录

**什么是 logging？**

- Python 标准库，用于记录程序运行时的**日志信息**
- 比 `print()` 更强大：支持级别、格式化、文件输出等
- 标准库，无需安装

**为什么用 logging？**

```python
import logging 

# 基础使用
logging.info("程序启动")
logging.warning("这是一个警告")
logging.error("发生错误")

# 优势：
# 1. 可以设置日志级别（只输出重要信息）
# 2. 可以输出到文件、控制台或其他地方
# 3. 可以格式化输出（时间、模块名、行号等）
# 4. 生产环境必备
```

---

#### **核心功能速查表**

**日志级别（从低到高）**

| 级别       | 数值 | 用途     | 何时使用           |
| ---------- | ---- | -------- | ------------------ |
| `DEBUG`    | 10   | 调试信息 | 开发调试时         |
| `INFO`     | 20   | 一般信息 | 程序正常运行       |
| `WARNING`  | 30   | 警告信息 | 潜在问题           |
| `ERROR`    | 40   | 错误信息 | 功能失败但程序继续 |
| `CRITICAL` | 50   | 严重错误 | 程序崩溃           |

**基础日志方法**

| 方法                     | 用途          |
| ------------------------ | ------------- |
| `logging.debug(msg)`     | 调试信息      |
| `logging.info(msg)`      | 一般信息      |
| `logging.warning(msg)`   | 警告          |
| `logging.error(msg)`     | 错误          |
| `logging.critical(msg)`  | 严重错误      |
| `logging.exception(msg)` | 错误+异常堆栈 |

**配置方法**

| 方法                         | 作用           |
| ---------------------------- | -------------- |
| `logging.basicConfig()`      | 基础配置       |
| `logging.getLogger(name)`    | 获取logger实例 |
| `logger.setLevel(level)`     | 设置日志级别   |
| `logger.addHandler(handler)` | 添加处理器     |

**Handler（输出目标）**

| Handler                    | 输出到             |
| -------------------------- | ------------------ |
| `StreamHandler`            | 控制台             |
| `FileHandler`              | 文件               |
| `RotatingFileHandler`      | 文件（自动轮转）   |
| `TimedRotatingFileHandler` | 文件（按时间轮转） |

**Formatter（格式化）**

| 占位符          | 含义       |
| --------------- | ---------- |
| `%(asctime)s`   | 时间       |
| `%(name)s`      | logger名称 |
| `%(levelname)s` | 日志级别   |
| `%(message)s`   | 日志消息   |
| `%(filename)s`  | 文件名     |
| `%(lineno)d`    | 行号       |
| `%(funcName)s`  | 函数名     |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：基础 logger 创建**
>
> ```python
> # backend/data/block.py
> import logging
> 
> logger = logging.getLogger(__name__)
> #                          ^^^^^^^^ 使用 __name__ 作为 logger 名称
> #                          这会自动使用模块路径，如 "backend.data.block"
> ```
>
> **解释：**
> - `__name__` 是当前模块的名称
> - 使用模块路径可以建立日志层级关系
> - 便于按模块过滤和配置日志
>
> ---
>
> #### **案例 2：不同级别的日志**
>
> ```python
> # backend/util/virus_scanner.py
> import logging
> 
> logger = logging.getLogger(__name__)
> 
> # WARNING - 潜在问题，但不影响运行
> if not self.settings.clamav_service_enabled:
>     logger.warning(f"Virus scanning disabled – accepting {filename}")
> 
> # DEBUG - 调试信息
> logger.debug(
>     f"Scanning {filename} with chunk size: {chunk_size // 1_048_576} MB"
> )
> 
> # ERROR - 功能失败
> logger.error(f"Cannot scan {filename}: {exc}")
> 
> # INFO - 正常操作信息
> logger.info(f"File {filename} passed virus scan in {result.scan_time_ms}ms")
> ```
>
> **解释：**
> - `WARNING` - 扫描被禁用（配置问题，但可以继续）
> - `DEBUG` - 详细的扫描参数（仅开发时需要）
> - `ERROR` - 扫描失败（功能失败）
> - `INFO` - 扫描成功（正常流程）
>
> ---
>
> #### **案例 3：异常日志（CRITICAL + 告警）**
>
> ```python
> # backend/util/retry.py
> import logging
> 
> logger = logging.getLogger(__name__)
> 
> def _send_critical_retry_alert(func_name, attempt_number, exception, context=""):
>     """发送严重错误告警"""
>     
>     # 发送 Discord 告警
>     if send_rate_limited_discord_alert(...):
>         logger.critical(
>             #      ^^^^^^^^ 最高级别，表示严重问题
>             f"CRITICAL ALERT SENT: Operation {func_name} at attempt {attempt_number}"
>         )
> 
> # 记录错误并发送告警失败
> except Exception as alert_error:
>     logger.error(f"Failed to send Discord alert: {alert_error}")
> ```
>
> **解释：**
> - `CRITICAL` - 系统即将失败，需要立即处理
> - 结合外部告警系统（Discord）
> - 错误处理也要记录日志
>
> ---
>
> #### **案例 4：带变量的日志**
>
> ```python
> # backend/util/timezone_utils.py
> import logging
> 
> logger = logging.getLogger(__name__)
> 
> # 使用 f-string 格式化
> logger.debug(
>     f"Converted cron '{cron_expr}' from {user_timezone} to UTC: '{utc_cron}'"
> )
> 
> logger.error(
>     f"Failed to convert cron expression '{cron_expr}' from {user_timezone} to UTC: {e}"
> )
> 
> logger.warning(f"Invalid user timezone '{user_timezone}', falling back to UTC")
> ```
>
> **解释：**
> - 使用 f-string 嵌入变量
> - 提供足够的上下文信息
> - 便于问题排查
>
> ---
>
> #### **案例 5：条件日志级别**
>
> ```python
> # backend/util/service.py
> import logging
> 
> logger = logging.getLogger(__name__)
> 
> def handler(request, exc):
>     if log_error:
>         # 根据状态码选择日志级别
>         if status_code == 500:
>             log = logger.exception  # 服务器错误用 exception
>             #            ^^^^^^^^^ 自动包含堆栈跟踪
>         else:
>             log = logger.error      # 其他错误用 error
>         
>         log(f"{request.method} {request.url.path} failed: {exc}")
> ```
>
> **解释：**
> - 根据错误严重程度选择日志级别
> - `logger.exception()` 自动记录异常堆栈
> - 提供请求上下文（方法、路径）
>
> ---
>
> #### **案例 6：配置 uvicorn 日志**
>
> ```python
> # backend/util/service.py
> import logging
> 
> logger = logging.getLogger(__name__)
> 
> def __start_fastapi(self):
>     logger.info(
>         f"[{self.service_name}] Starting RPC server at http://{api_host}:{self.get_port()}"
>     )
>     
>     # 启动 uvicorn，禁用其默认日志配置
>     uvicorn.run(
>         self.fastapi_app,
>         host=api_host,
>         port=self.get_port(),
>         log_config=None,  # 使用自定义日志配置
>         #          ^^^^ 重要：防止 uvicorn 覆盖日志设置
>         log_level=self.log_level,
>     )
> ```
>
> ---
>

**详细功能讲解**

**1. 基础使用**

```python
import logging

# 最简单的使用（默认级别 WARNING）
logging.warning("这是一个警告")
logging.error("这是一个错误")

# 配置日志级别
logging.basicConfig(level=logging.DEBUG)

# 现在可以看到 DEBUG 和 INFO 级别的日志
logging.debug("调试信息")
logging.info("一般信息")
logging.warning("警告")
logging.error("错误")
logging.critical("严重错误")
```

**输出：**
```
WARNING:root:这是一个警告
ERROR:root:这是一个错误
DEBUG:root:调试信息
INFO:root:一般信息
WARNING:root:警告
ERROR:root:错误
CRITICAL:root:严重错误
```

---

**2. 配置日志格式**

```python
import logging

# 配置格式
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logging.info("程序启动")
```

**输出：**
```
2024-01-15 14:30:00 - root - INFO - 程序启动
```

**常用格式占位符：**
```python
format=(
    '%(asctime)s '          # 时间
    '%(name)s '             # logger名称
    '%(levelname)s '        # 日志级别
    '%(filename)s:'         # 文件名
    '%(lineno)d '           # 行号
    '%(funcName)s() '       # 函数名
    '- %(message)s'         # 消息
)
```

---

**3. 创建自定义 Logger**

```python
import logging

# 获取 logger（推荐使用 __name__）
logger = logging.getLogger(__name__)
#                          ^^^^^^^^ 当前模块名

# 设置级别
logger.setLevel(logging.DEBUG)

# 使用
logger.debug("这是调试信息")
logger.info("这是一般信息")

# 不同模块有不同的 logger
# myapp.py
logger_app = logging.getLogger(__name__)  # "myapp"

# myapp.utils.py
logger_utils = logging.getLogger(__name__)  # "myapp.utils"
```

**为什么用 `__name__`？**
```python
# 在 backend/data/block.py 中
logger = logging.getLogger(__name__)
# logger 名称: "backend.data.block"

# 在 backend/util/retry.py 中
logger = logging.getLogger(__name__)
# logger 名称: "backend.util.retry"

# 好处：
# 1. 可以看出日志来自哪个模块
# 2. 可以针对特定模块配置日志级别
```

---

**4. 输出到文件**

```python
import logging

# 方法 1：使用 basicConfig
logging.basicConfig(
    filename='app.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

logging.info("这会写入文件")

# 方法 2：使用 Handler（更灵活）
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# 文件 handler
file_handler = logging.FileHandler('app.log')
file_handler.setLevel(logging.DEBUG)

# 格式化
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
file_handler.setFormatter(formatter)

# 添加到 logger
logger.addHandler(file_handler)

logger.info("写入文件")
```

---

**5. 同时输出到文件和控制台**

```python
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# 格式化器
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# 文件 handler
file_handler = logging.FileHandler('app.log')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(formatter)

# 控制台 handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)  # 控制台只显示 INFO 及以上
console_handler.setFormatter(formatter)

# 添加两个 handler
logger.addHandler(file_handler)
logger.addHandler(console_handler)

logger.debug("只写入文件")      # 只在文件中
logger.info("文件和控制台")     # 文件 + 控制台
logger.error("文件和控制台")    # 文件 + 控制台
```

---

**6. 日志轮转（避免文件过大）**

```python
import logging
from logging.handlers import RotatingFileHandler

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# 轮转 handler - 按大小
handler = RotatingFileHandler(
    'app.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5            # 保留 5 个备份
)
# 生成文件: app.log, app.log.1, app.log.2, ..., app.log.5

formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)

# 按时间轮转
from logging.handlers import TimedRotatingFileHandler

handler = TimedRotatingFileHandler(
    'app.log',
    when='midnight',  # 每天午夜轮转
    interval=1,       # 间隔 1 天
    backupCount=7     # 保留 7 天
)
# when 可选值: 'S'(秒), 'M'(分), 'H'(时), 'D'(天), 'midnight'
```

---

**7. 记录异常**

```python
import logging

logger = logging.getLogger(__name__)

# 方法 1：使用 logger.exception()（推荐）
try:
    result = 1 / 0
except Exception:
    logger.exception("发生除零错误")
    #      ^^^^^^^^^ 自动记录异常堆栈

# 输出:
# ERROR:__main__:发生除零错误
# Traceback (most recent call last):
#   File "test.py", line 5, in <module>
#     result = 1 / 0
# ZeroDivisionError: division by zero

# 方法 2：使用 exc_info=True
try:
    result = 1 / 0
except Exception as e:
    logger.error("发生错误", exc_info=True)
    # 或者
    logger.error(f"发生错误: {e}", exc_info=True)

# 方法 3：不记录堆栈（仅错误消息）
try:
    result = 1 / 0
except Exception as e:
    logger.error(f"发生错误: {e}")  # 只记录错误消息
```

---

**8. 按模块配置不同级别**

```python
import logging

# 根 logger
logging.basicConfig(level=logging.WARNING)

# 特定模块设置 DEBUG
logging.getLogger('backend.data').setLevel(logging.DEBUG)
logging.getLogger('backend.executor').setLevel(logging.DEBUG)

# 第三方库设置 ERROR（减少噪音）
logging.getLogger('urllib3').setLevel(logging.ERROR)
logging.getLogger('requests').setLevel(logging.ERROR)

# 实际使用
logger_data = logging.getLogger('backend.data.block')
logger_data.debug("这会显示")  # ✅ DEBUG 级别

logger_other = logging.getLogger('backend.other.module')
logger_other.debug("这不会显示")  # ❌ WARNING 级别
```

---

**9. 条件日志（性能优化）**

```python
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ❌ 不好：总是执行字符串格式化
expensive_data = expensive_computation()
logger.debug(f"Data: {expensive_data}")  # 即使不输出也会计算

# ✅ 好：先检查级别
if logger.isEnabledFor(logging.DEBUG):
    expensive_data = expensive_computation()
    logger.debug(f"Data: {expensive_data}")

# 或者使用延迟格式化（旧式）
logger.debug("Data: %s", expensive_data)  # 只在需要时格式化
```

---

**10. 完整配置示例**

```python
import logging
import logging.config

# 字典配置（推荐）
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        },
        'detailed': {
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'standard',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'level': 'DEBUG',
            'formatter': 'detailed',
            'filename': 'app.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5
        }
    },
    'loggers': {
        'backend.data': {
            'level': 'DEBUG',
            'handlers': ['console', 'file'],
            'propagate': False
        },
        'backend.executor': {
            'level': 'INFO',
            'handlers': ['console', 'file'],
            'propagate': False
        }
    },
    'root': {
        'level': 'WARNING',
        'handlers': ['console']
    }
}

# 应用配置
logging.config.dictConfig(LOGGING_CONFIG)

# 使用
logger = logging.getLogger('backend.data.block')
logger.debug("这会输出")
```

---

**常见陷阱和注意事项**

**陷阱 1：多次调用 basicConfig**

```python
import logging

# ❌ 错误：basicConfig 只生效一次
logging.basicConfig(level=logging.DEBUG)
logging.info("第一次配置")

logging.basicConfig(level=logging.ERROR)  # 无效！
logging.info("仍然会显示")  # ✅ 仍然显示

# ✅ 正确：只调用一次 basicConfig
logging.basicConfig(level=logging.DEBUG)
```

---

**陷阱 2：忘记设置 logger 级别**

```python
import logging

# ❌ 错误：logger 和 handler 都有级别
logger = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setLevel(logging.DEBUG)  # 只设置 handler
logger.addHandler(handler)

logger.debug("不会显示")  # ❌ logger 默认是 WARNING

# ✅ 正确：都要设置
logger.setLevel(logging.DEBUG)  # logger 级别
handler.setLevel(logging.DEBUG)  # handler 级别
```

---

**陷阱 3：日志重复输出**

```python
import logging

# ❌ 错误：重复添加 handler
logger = logging.getLogger(__name__)

for i in range(3):
    handler = logging.StreamHandler()
    logger.addHandler(handler)  # 添加了 3 次！

logger.info("重复 3 次")
# INFO:__main__:重复 3 次
# INFO:__main__:重复 3 次
# INFO:__main__:重复 3 次

# ✅ 正确：检查是否已有 handler
if not logger.handlers:
    handler = logging.StreamHandler()
    logger.addHandler(handler)
```

---

**陷阱 4：性能问题（不必要的字符串格式化）**

```python
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ❌ 不好：总是格式化
logger.debug(f"复杂计算: {expensive_function()}")
# 即使不输出，expensive_function() 也会执行！

# ✅ 好：延迟格式化
logger.debug("复杂计算: %s", expensive_function())
# 只在需要输出时才调用 expensive_function()

# ✅ 更好：条件检查
if logger.isEnabledFor(logging.DEBUG):
    result = expensive_function()
    logger.debug(f"复杂计算: {result}")
```

---

**陷阱 5：第三方库日志噪音**

```python
import logging

# ❌ 问题：第三方库日志太多
# requests, urllib3 等库会输出大量 DEBUG 日志

# ✅ 解决：提高第三方库日志级别
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('requests').setLevel(logging.WARNING)
logging.getLogger('boto3').setLevel(logging.WARNING)
```

---

#### **总结：logging 模块核心要点**

**必须掌握**

| 功能        | 方法                                       | 用途            |
| ----------- | ------------------------------------------ | --------------- |
| 创建 logger | `logging.getLogger(__name__)`              | 获取模块 logger |
| 日志级别    | `logger.debug/info/warning/error/critical` | 不同级别        |
| 异常日志    | `logger.exception(msg)`                    | 自动堆栈        |
| 基础配置    | `logging.basicConfig()`                    | 快速配置        |
| 设置级别    | `logger.setLevel(level)`                   | 控制输出        |

**日志级别选择指南**

- **DEBUG** - 详细调试信息（开发时）
- **INFO** - 正常操作流程（用户登录、任务完成）
- **WARNING** - 潜在问题（配置缺失、使用弃用API）
- **ERROR** - 功能失败（API调用失败、数据库错误）
- **CRITICAL** - 系统崩溃（服务不可用）

**最佳实践**

1. 使用 `logging.getLogger(__name__)` 而非根 logger
2. 在模块顶部创建 logger
3. 使用适当的日志级别
4. 记录足够的上下文信息
5. 异常使用 `logger.exception()` 记录
6. 生产环境使用文件轮转
7. 第三方库降低日志级别

### 8.`re` - 正则表达式

**什么是 re？**

- Python 标准库，用于**正则表达式**匹配和文本处理
- 强大的文本搜索、替换、提取工具
- 标准库，无需安装

---

#### **核心功能速查表**

**主要函数**

| 函数                            | 作用               | 返回值            |
| ------------------------------- | ------------------ | ----------------- |
| `re.match(pattern, string)`     | 从**开头**匹配     | Match 对象或 None |
| `re.search(pattern, string)`    | 搜索**第一个**匹配 | Match 对象或 None |
| `re.findall(pattern, string)`   | 查找**所有**匹配   | 列表              |
| `re.finditer(pattern, string)`  | 查找所有（迭代器） | Match 对象迭代器  |
| `re.sub(pattern, repl, string)` | 替换               | 新字符串          |
| `re.split(pattern, string)`     | 分割               | 列表              |
| `re.compile(pattern)`           | 编译正则表达式     | Pattern 对象      |

**常用元字符**

| 元字符  | 含义               | 示例                           |
| ------- | ------------------ | ------------------------------ |
| `.`     | 任意字符（除换行） | `a.c` → `abc`, `a1c`           |
| `^`     | 开头               | `^Hello` → `Hello world`       |
| `$`     | 结尾               | `world$` → `Hello world`       |
| `*`     | 0次或多次          | `ab*c` → `ac`, `abc`, `abbc`   |
| `+`     | 1次或多次          | `ab+c` → `abc`, `abbc`         |
| `?`     | 0次或1次           | `ab?c` → `ac`, `abc`           |
| `{n}`   | 恰好n次            | `a{3}` → `aaa`                 |
| `{n,m}` | n到m次             | `a{2,4}` → `aa`, `aaa`, `aaaa` |

**字符类**

| 表达式 | 含义             | 等价于           |
| ------ | ---------------- | ---------------- |
| `\d`   | 数字             | `[0-9]`          |
| `\D`   | 非数字           | `[^0-9]`         |
| `\w`   | 字母数字下划线   | `[a-zA-Z0-9_]`   |
| `\W`   | 非字母数字下划线 | `[^a-zA-Z0-9_]`  |
| `\s`   | 空白字符         | `[ \t\n\r\f\v]`  |
| `\S`   | 非空白字符       | `[^ \t\n\r\f\v]` |

**特殊构造**

| 构造     | 含义          | 示例                       |
| -------- | ------------- | -------------------------- |
| `[abc]`  | a或b或c       | `[aeiou]` 匹配元音         |
| `[^abc]` | 非a且非b且非c | `[^0-9]` 非数字            |
| `(ab)`   | 捕获分组      | `(abc)+` → `abc`, `abcabc` |
| `(?:ab)` | 非捕获分组    | 不保存匹配结果             |
| `a|b`    | a或b          | `cat|dog`                  |

**标志（flags）**

| 标志                     | 含义                     |
| ------------------------ | ------------------------ |
| `re.IGNORECASE` / `re.I` | 忽略大小写               |
| `re.MULTILINE` / `re.M`  | 多行模式（^和$匹配每行） |
| `re.DOTALL` / `re.S`     | `.` 匹配换行符           |
| `re.VERBOSE` / `re.X`    | 详细模式（可加注释）     |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：编译正则表达式（提高性能）**
>
> ```python
> # backend/util/request.py
> import re
> 
> # 在模块级别编译正则表达式（只编译一次）
> HOSTNAME_REGEX = re.compile(r"^[A-Za-z0-9.-]+$")
> #                ^^^^^^^^^^^ 编译正则表达式，提高重复使用的性能
> 
> # 使用
> def validate_hostname(hostname: str) -> bool:
>     return bool(HOSTNAME_REGEX.match(hostname))
> ```
>
> **解释：**
> - `re.compile()` 将正则表达式编译为 Pattern 对象
> - 如果正则表达式需要重复使用，编译后性能更好
> - 模式：`^[A-Za-z0-9.-]+$` 匹配有效的 DNS 主机名
>
> ---
>
> #### **案例 2：提取子字符串（分组捕获）**
>
> ```python
> # backend/util/request.py
> import re
> 
> # 从 Content-Type 头提取字符编码
> ctype = "text/html; charset=utf-8"
> match = re.search(r"charset=([^\s;]+)", ctype, flags=re.I)
> #                 ^^^^^^^^^^^^^^^^^ 匹配 charset=xxx
> #                          ^^^^^^^^^ 捕获分组：提取字符集名称
> #                                     ^^^^^^^^^ 匹配到空格或分号为止
> #                                                    ^^^^^ 忽略大小写
> 
> encoding = match.group(1) if match else None
> #               ^^^^^^^^ 获取第一个分组的内容
> print(encoding)  # "utf-8"
> ```
>
> **解释：**
> - `()` 创建捕获分组
> - `[^\s;]` - 匹配非空格非分号的字符
> - `+` - 一次或多次
> - `re.I` / `re.IGNORECASE` - 忽略大小写
> - `match.group(1)` - 获取第一个分组
>
> ---
>
> #### **案例 3：匹配和提取 Data URI**
>
> ```python
> # backend/util/file.py
> import re
> 
> # Data URI 格式: data:image/png;base64,iVBORw0KGgo...
> data_uri = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
> 
> match = re.match(r"^data:([^;]+);base64,(.*)$", data_uri, re.DOTALL)
> #                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 匹配整个 Data URI
> #                      ^^^^^^^ 分组1：MIME 类型
> #                                      ^^^^ 分组2：base64 数据
> #                                                           ^^^^^^^^^ 点匹配换行符
> 
> if not match:
>     raise ValueError("Invalid data URI format")
> 
> mime_type = match.group(1).strip().lower()  # "image/png"
> b64_content = match.group(2).strip()        # "iVBORw0KGgo..."
> ```
>
> **解释：**
> - `^` - 开头
> - `([^;]+)` - 捕获 MIME 类型（直到分号）
> - `(.*)` - 捕获所有剩余内容（base64 数据）
> - `$` - 结尾
> - `re.DOTALL` - 让 `.` 匹配换行符
>
> ---
>
> #### **案例 4：简化的 MIME 类型提取**
>
> ```python
> # backend/util/file.py
> import re
> 
> def get_mime_type(file: str) -> str:
>     """从 Data URI 提取 MIME 类型"""
>     if file.startswith("data:"):
>         match = re.match(r"^data:([^;]+);base64,", file)
>         #                      ^^^^^^^ 只提取 MIME 类型部分
>         return match.group(1) if match else "application/octet-stream"
>     return "application/octet-stream"
> 
> # 使用
> mime = get_mime_type("data:image/jpeg;base64,/9j/4AAQ...")
> print(mime)  # "image/jpeg"
> ```
>
> ---
>
> #### **案例 5：清理 PostgreSQL 不兼容字符**
>
> ```python
> # backend/util/json.py
> import re
> 
> # 预编译正则表达式（模块级别）
> POSTGRES_CONTROL_CHARS = re.compile(r"[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]")
> #                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
> #                                    匹配控制字符（保留 tab、换行、回车）
> 
> # 移除 Unicode 转义序列
> POSTGRES_JSON_ESCAPES = re.compile(
>     r"\\u000[0-8]"        # \u0000-\u0008
>     r"|\\u000[bB]"        # \u000B
>     r"|\\u000[cC]"        # \u000C
>     r"|\\u00[0-1][0-9a-fA-F]"  # \u000E-\u001F
>     r"|\\u007[fF]"        # \u007F
>     r"|(?<!\\)\\[bf](?!\\)"    # \b 和 \f（但不是 \\b 或 \b\\）
> )
> 
> # 使用
> json_str = '{"text": "hello\x00world"}'
> cleaned = POSTGRES_CONTROL_CHARS.sub("", json_str)
> print(cleaned)  # '{"text": "helloworld"}'
> ```
>
> **解释：**
> - `[\x00-\x08]` - 十六进制范围（控制字符）
> - `|` - 或运算符
> - `(?<!\\)` - 负向后查找断言（前面不是反斜杠）
> - `(?!\\)` - 负向前查找断言（后面不是反斜杠）
> - `.sub(repl, string)` - 替换所有匹配
>

---

#### **详细功能讲解**

**1. 基础匹配函数**

**match() - 从开头匹配**

```python
import re

# match() 只从字符串开头匹配
result = re.match(r'hello', 'hello world')
print(result)  # <Match object>

result = re.match(r'world', 'hello world')
print(result)  # None（因为 world 不在开头）

# 获取匹配内容
match = re.match(r'(\w+)', 'hello world')
if match:
    print(match.group(0))  # "hello"（完整匹配）
    print(match.group(1))  # "hello"（第一个分组）
```

---

**search() - 搜索第一个匹配**

```python
import re

# search() 在整个字符串中搜索
result = re.search(r'world', 'hello world')
print(result)  # <Match object>

# 获取匹配位置
match = re.search(r'world', 'hello world')
if match:
    print(match.group())     # "world"
    print(match.start())     # 6（开始位置）
    print(match.end())       # 11（结束位置）
    print(match.span())      # (6, 11)（位置元组）
```

---

**findall() - 查找所有匹配**

```python
import re

text = "电话: 010-12345678, 手机: 13800138000"

# 查找所有电话号码
phones = re.findall(r'\d{3,4}-?\d{7,8}', text)
print(phones)  # ['010-12345678', '13800138000']

# 带分组的 findall
text = "Email: user@example.com, Contact: admin@test.org"
emails = re.findall(r'(\w+)@([\w.]+)', text)
print(emails)  # [('user', 'example.com'), ('admin', 'test.org')]
```

---

**finditer() - 查找所有（迭代器）**

```python
import re

text = "cat bat rat"
pattern = r'\w+at'

# finditer 返回迭代器，节省内存
for match in re.finditer(pattern, text):
    print(match.group(), match.span())

# 输出:
# cat (0, 3)
# bat (4, 7)
# rat (8, 11)
```

---

**2. 替换和分割**

**sub() - 替换**

```python
import re

# 简单替换
text = "Hello World"
result = re.sub(r'World', 'Python', text)
print(result)  # "Hello Python"

# 使用分组引用
text = "2024-01-15"
result = re.sub(r'(\d{4})-(\d{2})-(\d{2})', r'\3/\2/\1', text)
#                ^^^^^^^^^^^^^^^^^^^^^^^^   ^^^^^^^^^^^
#                匹配年-月-日                日/月/年
print(result)  # "15/01/2024"

# 替换函数（动态替换）
def double_number(match):
    num = int(match.group())
    return str(num * 2)

text = "价格: 10 和 20"
result = re.sub(r'\d+', double_number, text)
print(result)  # "价格: 20 和 40"

# 限制替换次数
text = "apple apple apple"
result = re.sub(r'apple', 'orange', text, count=2)
print(result)  # "orange orange apple"
```

---

**split() - 分割**

```python
import re

# 按多个分隔符分割
text = "apple,banana;orange|grape"
fruits = re.split(r'[,;|]', text)
print(fruits)  # ['apple', 'banana', 'orange', 'grape']

# 按空白字符分割
text = "hello   world\t\npython"
words = re.split(r'\s+', text)
print(words)  # ['hello', 'world', 'python']

# 保留分隔符（使用分组）
text = "apple,banana;orange"
parts = re.split(r'([,;])', text)
print(parts)  # ['apple', ',', 'banana', ';', 'orange']

# 限制分割次数
text = "a:b:c:d"
parts = re.split(r':', text, maxsplit=2)
print(parts)  # ['a', 'b', 'c:d']
```

---

**3. 编译正则表达式**

```python
import re

# 编译（提高性能）
pattern = re.compile(r'\d+')

# 使用编译后的对象
result = pattern.search("电话: 12345")
print(result.group())  # "12345"

# 所有方法都可用
matches = pattern.findall("10, 20, 30")
print(matches)  # ['10', '20', '30']

# 带标志编译
pattern = re.compile(r'hello', re.IGNORECASE)
result = pattern.search("HELLO world")
print(result.group())  # "HELLO"
```

---

**4. 分组和捕获**

**基础分组**

```python
import re

# 基础分组
text = "John Smith, age: 30"
match = re.search(r'(\w+) (\w+), age: (\d+)', text)

if match:
    print(match.group(0))  # "John Smith, age: 30"（完整匹配）
    print(match.group(1))  # "John"（第一个分组）
    print(match.group(2))  # "Smith"（第二个分组）
    print(match.group(3))  # "30"（第三个分组）
    
    # 或使用 groups() 获取所有分组
    print(match.groups())  # ('John', 'Smith', '30')
```

---

**命名分组**

```python
import re

# 命名分组：(?P<name>pattern)
text = "2024-01-15"
match = re.search(r'(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})', text)

if match:
    print(match.group('year'))   # "2024"
    print(match.group('month'))  # "01"
    print(match.group('day'))    # "15"
    
    # 或使用 groupdict()
    print(match.groupdict())
    # {'year': '2024', 'month': '01', 'day': '15'}

# 在替换中使用命名分组
result = re.sub(
    r'(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})',
    r'\g<day>/\g<month>/\g<year>',
    text
)
print(result)  # "15/01/2024"
```

---

**非捕获分组**

```python
import re

# 非捕获分组：(?:pattern)
# 用于分组但不捕获结果

text = "https://example.com"

# 捕获分组（会保存）
match = re.search(r'(https?)://([\w.]+)', text)
print(match.groups())  # ('https', 'example.com')

# 非捕获分组（不保存）
match = re.search(r'(?:https?)://([\w.]+)', text)
print(match.groups())  # ('example.com',)（只有一个分组）
```

---

**5. 常用模式**

**Email 地址**

```python
import re

email_pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
#                ^^^^^^^^^ 用户名
#                         ^^^^^^^^^ 域名
#                                  ^^^^ 顶级域名

emails = [
    "user@example.com",      # ✅
    "user.name@test.co.uk",  # ✅
    "invalid@",              # ❌
    "@example.com"           # ❌
]

for email in emails:
    if re.match(email_pattern, email):
        print(f"{email} 有效")
    else:
        print(f"{email} 无效")
```

---

**电话号码**

```python
import re

# 中国手机号
phone_pattern = r'^1[3-9]\d{9}$'
#                ^^^^^^^ 1开头，第二位3-9
#                       ^^^^^^ 后面9位数字

phones = ["13800138000", "12345678901", "99988887777"]

for phone in phones:
    if re.match(phone_pattern, phone):
        print(f"{phone} 有效")

# 固定电话（带区号）
landline_pattern = r'^\d{3,4}-?\d{7,8}$'
#                    ^^^^^^^ 3-4位区号
#                           ^^ 可选的短横线
#                             ^^^^^^^^ 7-8位号码

landlines = ["010-12345678", "02012345678", "12345"]

for landline in landlines:
    if re.match(landline_pattern, landline):
        print(f"{landline} 有效")
```

---

**URL**

```python
import re

url_pattern = r'https?://(?:www\.)?[\w\.-]+\.\w+(?:/[\w\.-]*)*'
#             ^^^^^^^ http 或 https
#                    ^^^^^^^^^^ 可选的 www.
#                               ^^^^^^^^^^^^ 域名
#                                           ^^^^^^^^^^^^^^ 路径

urls = [
    "https://example.com",
    "http://www.test.org/path/to/page",
    "invalid-url"
]

for url in urls:
    if re.match(url_pattern, url):
        print(f"{url} 有效")
```

---

**密码强度**

```python
import re

def check_password_strength(password):
    """检查密码强度"""
    if len(password) < 8:
        return "太短（至少8位）"
    
    # 至少一个小写字母
    if not re.search(r'[a-z]', password):
        return "需要小写字母"
    
    # 至少一个大写字母
    if not re.search(r'[A-Z]', password):
        return "需要大写字母"
    
    # 至少一个数字
    if not re.search(r'\d', password):
        return "需要数字"
    
    # 至少一个特殊字符
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        return "需要特殊字符"
    
    return "强密码"

# 测试
passwords = ["weak", "Stronger1", "Strong@123"]
for pwd in passwords:
    print(f"{pwd}: {check_password_strength(pwd)}")
```

---

**6. 标志（Flags）**

```python
import re

text = "Hello World\nPython Programming"

# re.IGNORECASE / re.I - 忽略大小写
result = re.findall(r'hello', text, re.IGNORECASE)
print(result)  # ['Hello']

# re.MULTILINE / re.M - 多行模式（^ 和 $ 匹配每行）
text = "line1\nline2\nline3"
result = re.findall(r'^line', text, re.MULTILINE)
print(result)  # ['line', 'line', 'line']

# re.DOTALL / re.S - . 匹配换行符
text = "hello\nworld"
result = re.search(r'hello.world', text, re.DOTALL)
print(result.group())  # "hello\nworld"

# 组合多个标志
result = re.findall(
    r'^hello',
    "Hello World\nHELLO Python",
    re.IGNORECASE | re.MULTILINE
)
print(result)  # ['Hello', 'HELLO']

# re.VERBOSE / re.X - 详细模式（可加注释）
pattern = re.compile(r'''
    ^                 # 开头
    [\w\.-]+          # 用户名
    @                 # @符号
    [\w\.-]+          # 域名
    \.                # 点
    \w+               # 顶级域名
    $                 # 结尾
''', re.VERBOSE)

result = pattern.match("user@example.com")
print(result.group())  # "user@example.com"
```

---

**7. 贪婪与非贪婪匹配**

```python
import re

text = "<div>content1</div><div>content2</div>"

# 贪婪匹配（默认）- 尽可能多地匹配
result = re.findall(r'<div>.*</div>', text)
print(result)  # ['<div>content1</div><div>content2</div>']
#                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#                 匹配了整个字符串！

# 非贪婪匹配 - 尽可能少地匹配
result = re.findall(r'<div>.*?</div>', text)
#                           ^^ 添加 ? 变为非贪婪
print(result)  # ['<div>content1</div>', '<div>content2</div>']

# 其他非贪婪量词
text = "aaaa"
print(re.match(r'a+', text).group())   # "aaaa"（贪婪）
print(re.match(r'a+?', text).group())  # "a"（非贪婪）

text = "aaaa"
print(re.match(r'a*', text).group())   # "aaaa"（贪婪）
print(re.match(r'a*?', text).group())  # ""（非贪婪，匹配0个）

text = "aaaa"
print(re.match(r'a{2,4}', text).group())   # "aaaa"（贪婪）
print(re.match(r'a{2,4}?', text).group())  # "aa"（非贪婪）
```

---

**8. 前瞻和后顾断言**

```python
import re

# 正向前瞻 (?=...) - 后面必须是...
text = "price: $100"
result = re.findall(r'\d+(?=\$)', text)  # 查找后面是$的数字
# 注意：这里匹配不到，因为$在数字前面

text = "100$ 200€ 300¥"
result = re.findall(r'\d+(?=\$)', text)  # 查找后面是$的数字
print(result)  # ['100']

# 负向前瞻 (?!...) - 后面不能是...
text = "100$ 200€ 300¥"
result = re.findall(r'\d+(?!\$)', text)  # 查找后面不是$的数字
print(result)  # ['200', '300']

# 正向后顾 (?<=...) - 前面必须是...
text = "$100 €200 ¥300"
result = re.findall(r'(?<=\$)\d+', text)  # 查找前面是$的数字
print(result)  # ['100']

# 负向后顾 (?<!...) - 前面不能是...
text = "$100 €200 ¥300"
result = re.findall(r'(?<!\$)\d+', text)  # 查找前面不是$的数字
print(result)  # ['200', '300']

# 实际应用：提取不包含反斜杠的字符
text = r"path\to\file and other text"
result = re.findall(r'(?<!\\)\w+', text)
print(result)  # ['path', 'to', 'file', 'and', 'other', 'text']
```

---

**常见陷阱和注意事项**

**陷阱 1：忘记转义特殊字符**

```python
import re

# ❌ 错误：. 匹配任意字符
text = "example.com"
result = re.match(r'example.com', text)
print(result.group())  # "example.com"（恰好能匹配）

text = "exampleXcom"
result = re.match(r'example.com', text)
print(result.group())  # "exampleXcom"（. 匹配了 X！）

# ✅ 正确：转义点号
result = re.match(r'example\.com', text)
print(result)  # None

# 需要转义的特殊字符
# . ^ $ * + ? { } [ ] \ | ( )
```

---

**陷阱 2：贪婪匹配的意外结果**

```python
import re

html = '<div>content</div>'

# ❌ 错误：匹配过多
result = re.search(r'<div>.*</div>', html)
print(result.group())  # 整个字符串

# ✅ 正确：使用非贪婪
result = re.search(r'<div>.*?</div>', html)
print(result.group())  # '<div>content</div>'

# 或者：使用否定字符类
result = re.search(r'<div>[^<]*</div>', html)
print(result.group())  # '<div>content</div>'
```

---

**陷阱 3：忘记使用原始字符串**

```python
import re

# ❌ 错误：\d 被 Python 解释为转义序列
pattern = "\d+"  # Python 看到 \d 会警告或报错
# SyntaxWarning: invalid escape sequence '\d'

# ✅ 正确：使用原始字符串
pattern = r"\d+"  # r 前缀表示原始字符串

# 对比
print("\t")   # 制表符
print(r"\t")  # 字面上的 \t

# 在正则表达式中总是使用 r"..."
```

---

**陷阱 4：match() vs search() 的混淆**

```python
import re

text = "hello world"

# match() 只从开头匹配
result = re.match(r'world', text)
print(result)  # None（world 不在开头）

# search() 在整个字符串中搜索
result = re.search(r'world', text)
print(result.group())  # "world"

# 如果想要从开头匹配，使用 ^
result = re.search(r'^hello', text)
print(result.group())  # "hello"
```

---

**陷阱 5：分组索引从 1 开始**

```python
import re

text = "John Smith"
match = re.search(r'(\w+) (\w+)', text)

# ❌ 错误：group(0) 是完整匹配
print(match.group(0))  # "John Smith"

# ✅ 正确：分组从 1 开始
print(match.group(1))  # "John"
print(match.group(2))  # "Smith"
```

---

**陷阱 6：性能问题（复杂正则）**

```python
import re

# ❌ 危险：灾难性回溯
text = "a" * 30 + "b"
pattern = r'(a+)+b'  # 嵌套量词可能导致指数级时间复杂度
# 可能非常慢或卡死

# ✅ 改进：简化模式
pattern = r'a+b'  # 更简单高效

# 或使用具体量词
pattern = r'a{1,30}b'
```

---

#### **总结：re 模块核心要点**

**必须掌握**

| 功能       | 方法                            | 用途     |
| ---------- | ------------------------------- | -------- |
| 从开头匹配 | `re.match(pattern, string)`     | 验证格式 |
| 搜索匹配   | `re.search(pattern, string)`    | 查找内容 |
| 查找所有   | `re.findall(pattern, string)`   | 提取数据 |
| 替换       | `re.sub(pattern, repl, string)` | 文本处理 |
| 分割       | `re.split(pattern, string)`     | 解析文本 |

**常用元字符**

- **字符类**: `\d` (数字), `\w` (字母数字), `\s` (空白)
- **量词**: `*` (0+次), `+` (1+次), `?` (0/1次), `{n,m}` (n-m次)
- **锚点**: `^` (开头), `$` (结尾)
- **分组**: `()` (捕获), `(?:)` (非捕获), `(?P<name>)` (命名)

**最佳实践**

1. 始终使用原始字符串 `r"..."`
2. 复杂模式使用 `re.compile()` 编译
3. 优先使用非贪婪匹配 `*?`, `+?`
4. 使用具体字符类而非 `.`
5. 测试边界情况
6. 避免过度复杂的正则表达式

## **重要掌握**
### 9.`collections` - 数据结构

**什么是 collections？**

- Python 标准库，提供**增强的数据结构**
- 比内置的 `list`, [dict](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:89:4-90:65), `set` 更强大、更专业
- 标准库，无需安装

#### **核心功能速查表**

**主要数据结构**

| 类            | 作用           | 何时使用                                       |
| ------------- | -------------- | ---------------------------------------------- |
| `defaultdict` | 带默认值的字典 | 分组、计数、构建图                             |
| `Counter`     | 计数器         | 统计频率、投票                                 |
| `deque`       | 双端队列       | 队列、栈、滑动窗口                             |
| `OrderedDict` | 有序字典       | 需要记住插入顺序（Python 3.7+ 普通dict已有序） |
| `namedtuple`  | 命名元组       | 轻量级的数据类                                 |
| `ChainMap`    | 链式字典       | 多层配置、作用域                               |

**defaultdict 默认工厂函数**

| 工厂函数                                                     | 默认值  | 用途         |
| ------------------------------------------------------------ | ------- | ------------ |
| `int`                                                        | `0`     | 计数         |
| `list`                                                       | `[]`    | 分组         |
| `set`                                                        | `set()` | 去重分组     |
| [dict](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:89:4-90:65) | `{}`    | 嵌套字典     |
| `lambda: value`                                              | 自定义  | 自定义默认值 |

**Counter 常用方法**

| 方法                  | 作用            |
| --------------------- | --------------- |
| `.most_common(n)`     | 最常见的n个元素 |
| `.elements()`         | 展开所有元素    |
| `.update(iterable)`   | 更新计数        |
| `.subtract(iterable)` | 减少计数        |
| `counter1 + counter2` | 合并计数        |
| `counter1 & counter2` | 取最小计数      |

**deque 常用方法**

| 方法                    | 作用     |
| ----------------------- | -------- |
| `.append(x)`            | 右端添加 |
| `.appendleft(x)`        | 左端添加 |
| `.pop()`                | 右端删除 |
| `.popleft()`            | 左端删除 |
| `.rotate(n)`            | 旋转n步  |
| `.extend(iterable)`     | 右端扩展 |
| `.extendleft(iterable)` | 左端扩展 |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：defaultdict 用于分组（构建字典）**
>
> ```python
> # backend/data/graph.py
> from collections import defaultdict
> 
> # 按节点 ID 分组输入链接
> input_links: dict[str, list[Link]] = defaultdict(list)
> #                                    ^^^^^^^^^^^^^^^ 默认值为空列表
> 
> for link in graph.links:
>     input_links[link.sink_id].append(link)
>     #                                ^^^^^^ 不需要检查键是否存在！
> 
> # 如果不用 defaultdict，需要这样写：
> # if link.sink_id not in input_links:
> #     input_links[link.sink_id] = []
> # input_links[link.sink_id].append(link)
> ```
>
> **解释：**
> - `defaultdict(list)` - 当访问不存在的键时，自动创建空列表
> - 极大简化了分组代码
> - 避免 `KeyError`
>
> ---
>
> #### **案例 2：defaultdict 嵌套字典**
>
> ```python
> # backend/data/graph.py
> from collections import defaultdict
> 
> # 收集每个节点的错误信息
> node_errors: dict[str, dict[str, str]] = defaultdict(dict)
> #                                        ^^^^^^^^^^^^^^^^
> #                                        默认值为空字典
> 
> # 使用
> node_errors[node_id]["field_name"] = "错误消息"
> # 自动创建内层字典，无需检查 node_id 是否存在
> 
> # 等价的普通字典写法：
> # if node_id not in node_errors:
> #     node_errors[node_id] = {}
> # node_errors[node_id]["field_name"] = "错误消息"
> ```
>
> ---
>
> #### **案例 3：defaultdict 用于创建对象实例**
>
> ```python
> # backend/executor/manager.py
> from collections import defaultdict
> 
> class NodeExecutionProgress:
>     def __init__(self):
>         self.status = "pending"
>         self.result = None
> 
> # 创建字典，值为对象实例
> running_node_execution: dict[str, NodeExecutionProgress] = defaultdict(
>     NodeExecutionProgress
>     # ^^^^^^^^^^^^^^^^^^^ 传入类本身（不带括号！）
>     # 每次访问不存在的键时，会自动调用 NodeExecutionProgress()
> )
> 
> # 使用
> node_id = "node_123"
> running_node_execution[node_id].status = "running"
> # 第一次访问时自动创建 NodeExecutionProgress 实例
> 
> # 等价写法：
> # if node_id not in running_node_execution:
> #     running_node_execution[node_id] = NodeExecutionProgress()
> # running_node_execution[node_id].status = "running"
> ```
>
> ---
>
> #### **案例 4：Counter 统计工具调用**
>
> ```python
> # backend/blocks/smart_decision_maker.py
> from collections import Counter
> 
> def get_pending_tool_calls(conversation_history: list[Any]) -> dict[str, int]:
>     """统计待处理的工具调用"""
>     
>     pending_calls = Counter()
>     #               ^^^^^^^ 创建计数器
>     
>     # 统计工具请求（增加计数）
>     for history in conversation_history:
>         for call_id in _get_tool_requests(history):
>             pending_calls[call_id] += 1
>             #                        ^^^ 自动初始化为 0 后再加 1
>     
>     # 统计工具响应（减少计数）
>     for history in conversation_history:
>         for call_id in _get_tool_responses(history):
>             pending_calls[call_id] -= 1
>             #                        ^^^ Counter 支持减法
>     
>     # 返回计数 > 0 的项（待处理的）
>     return {call_id: count for call_id, count in pending_calls.items() if count > 0}
> 
> # 使用示例
> # conversation_history = [
> #     {"role": "assistant", "tool_calls": [{"id": "call_1"}]},  # 请求
> #     {"role": "assistant", "tool_calls": [{"id": "call_2"}]},  # 请求
> #     {"role": "tool", "tool_call_id": "call_1"},               # 响应
> # ]
> # 结果: {"call_2": 1}  # call_1 已响应，call_2 待处理
> ```
>
> **解释：**
> - `Counter()` 自动将不存在的键初始化为 0
> - 支持加减操作
> - 非常适合统计场景
>

---

#### **详细功能讲解**

**1. defaultdict - 带默认值的字典**

**基础用法**

```python
from collections import defaultdict

# 创建 defaultdict
# 方式 1：使用内置类型
d1 = defaultdict(int)      # 默认值 0
d2 = defaultdict(list)     # 默认值 []
d3 = defaultdict(set)      # 默认值 set()
d4 = defaultdict(dict)     # 默认值 {}
d5 = defaultdict(str)      # 默认值 ""

# 方式 2：使用 lambda
d6 = defaultdict(lambda: "N/A")        # 默认值 "N/A"
d7 = defaultdict(lambda: [0, 0, 0])    # 默认值 [0, 0, 0]

# 使用
d1["key"]  # 0（自动创建）
d2["key"]  # []（自动创建）
d6["key"]  # "N/A"（自动创建）
```

---

**实际应用：计数**

```python
from collections import defaultdict

# 统计单词频率
text = "apple banana apple cherry banana apple"
words = text.split()

word_count = defaultdict(int)
for word in words:
    word_count[word] += 1

print(dict(word_count))
# {'apple': 3, 'banana': 2, 'cherry': 1}

# 普通字典的写法（更繁琐）：
word_count = {}
for word in words:
    if word not in word_count:
        word_count[word] = 0
    word_count[word] += 1
```

---

**实际应用：分组**

```python
from collections import defaultdict

# 按类别分组
students = [
    {"name": "Alice", "grade": "A"},
    {"name": "Bob", "grade": "B"},
    {"name": "Charlie", "grade": "A"},
    {"name": "David", "grade": "B"},
]

groups = defaultdict(list)
for student in students:
    groups[student["grade"]].append(student["name"])

print(dict(groups))
# {'A': ['Alice', 'Charlie'], 'B': ['Bob', 'David']}
```

---

**实际应用：图结构（邻接表）**

```python
from collections import defaultdict

# 构建图的邻接表
edges = [
    ("A", "B"),
    ("A", "C"),
    ("B", "D"),
    ("C", "D"),
    ("D", "E"),
]

graph = defaultdict(list)
for source, target in edges:
    graph[source].append(target)

print(dict(graph))
# {'A': ['B', 'C'], 'B': ['D'], 'C': ['D'], 'D': ['E']}

# 查找节点的邻居
neighbors = graph["A"]  # ['B', 'C']
neighbors = graph["X"]  # []（不存在的节点返回空列表）
```

---

**实际应用：嵌套字典**

```python
from collections import defaultdict

# 二级字典
data = [
    ("user1", "2024-01", 100),
    ("user1", "2024-02", 150),
    ("user2", "2024-01", 200),
]

# 方法 1：使用 lambda
stats = defaultdict(lambda: defaultdict(int))
for user, month, value in data:
    stats[user][month] += value

print(dict(stats))
# {'user1': {'2024-01': 100, '2024-02': 150}, 'user2': {'2024-01': 200}}

# 方法 2：使用嵌套 defaultdict
stats = defaultdict(lambda: defaultdict(int))
stats["user1"]["2024-01"] += 100  # 自动创建两层
```

---

**2. Counter - 计数器**

**基础用法**

```python
from collections import Counter

# 创建 Counter
# 方式 1：从可迭代对象
c1 = Counter(['a', 'b', 'a', 'c', 'b', 'a'])
# Counter({'a': 3, 'b': 2, 'c': 1})

# 方式 2：从字典
c2 = Counter({'a': 3, 'b': 2})

# 方式 3：从关键字参数
c3 = Counter(a=3, b=2)

# 访问计数
print(c1['a'])  # 3
print(c1['z'])  # 0（不存在的键返回 0，不报错）

# 所有方法
print(c1.most_common(2))  # [('a', 3), ('b', 2)]
print(list(c1.elements()))  # ['a', 'a', 'a', 'b', 'b', 'c']
```

---

**常用方法**

```python
from collections import Counter

votes = Counter(['A', 'B', 'A', 'C', 'A', 'B', 'D'])

# most_common(n) - 最常见的n个元素
print(votes.most_common(2))  # [('A', 3), ('B', 2)]
print(votes.most_common())   # 所有元素，按频率排序

# elements() - 展开所有元素
print(list(votes.elements()))
# ['A', 'A', 'A', 'B', 'B', 'C', 'D']

# update() - 增加计数
votes.update(['A', 'B'])
print(votes)  # Counter({'A': 4, 'B': 3, ...})

# subtract() - 减少计数
votes.subtract(['A', 'B'])
print(votes)  # Counter({'A': 3, 'B': 2, ...})

# total() - 总计数（Python 3.10+）
print(votes.total())  # 7
```

---

**Counter  运算**

```python
from collections import Counter

c1 = Counter(['a', 'b', 'a', 'c'])
c2 = Counter(['a', 'b', 'b', 'd'])

# 加法：合并计数
print(c1 + c2)  # Counter({'a': 3, 'b': 3, 'c': 1, 'd': 1})

# 减法：减去计数（负数和零被移除）
print(c1 - c2)  # Counter({'a': 1, 'c': 1})

# 交集：取最小计数
print(c1 & c2)  # Counter({'a': 1, 'b': 1})

# 并集：取最大计数
print(c1 | c2)  # Counter({'a': 2, 'b': 2, 'c': 1, 'd': 1})
```

---

**实际应用：统计字符频率**

```python
from collections import Counter

text = "hello world"
char_count = Counter(text)
print(char_count)
# Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})

# 找出最常见的字符
most_common = char_count.most_common(3)
print(most_common)  # [('l', 3), ('o', 2), ('h', 1)]
```

---

**实际应用：找出重复元素**

```python
from collections import Counter

numbers = [1, 2, 3, 2, 4, 3, 2, 5]
counts = Counter(numbers)

# 找出重复的元素
duplicates = [num for num, count in counts.items() if count > 1]
print(duplicates)  # [2, 3]

# 找出出现次数最多的元素
most_common = counts.most_common(1)[0][0]
print(most_common)  # 2
```

---

**3. deque - 双端队列**

**基础用法**

```python
from collections import deque

# 创建 deque
d1 = deque([1, 2, 3])
d2 = deque(maxlen=3)  # 限制最大长度

# 右端操作
d1.append(4)        # deque([1, 2, 3, 4])
d1.pop()            # 4, deque([1, 2, 3])

# 左端操作
d1.appendleft(0)    # deque([0, 1, 2, 3])
d1.popleft()        # 0, deque([1, 2, 3])

# 扩展
d1.extend([4, 5])       # deque([1, 2, 3, 4, 5])
d1.extendleft([0, -1])  # deque([-1, 0, 1, 2, 3, 4, 5])

# 旋转
d1.rotate(2)   # 右旋2步: deque([4, 5, -1, 0, 1, 2, 3])
d1.rotate(-2)  # 左旋2步: deque([-1, 0, 1, 2, 3, 4, 5])
```

---

**实际应用：队列（FIFO）**

```python
from collections import deque

# BFS 队列
queue = deque()
queue.append("start")  # 入队

while queue:
    node = queue.popleft()  # 出队（O(1)）
    print(f"访问: {node}")
    
    # 添加邻居节点
    # queue.append(neighbor)

# 对比：使用 list 作为队列（效率低）
# list.pop(0) 是 O(n) 操作！
```

---

**实际应用：栈（LIFO）**

```python
from collections import deque

# 使用 deque 作为栈
stack = deque()
stack.append(1)  # 入栈
stack.append(2)
stack.append(3)

print(stack.pop())  # 3（后进先出）
print(stack.pop())  # 2
```

---

**实际应用：滑动窗口**

```python
from collections import deque

# 保持最近的 N 个元素
window = deque(maxlen=3)  # 最多保存 3 个元素

window.append(1)  # deque([1])
window.append(2)  # deque([1, 2])
window.append(3)  # deque([1, 2, 3])
window.append(4)  # deque([2, 3, 4])（自动移除最左边的 1）

# 实际应用：移动平均
def moving_average(data, window_size):
    window = deque(maxlen=window_size)
    averages = []
    
    for value in data:
        window.append(value)
        averages.append(sum(window) / len(window))
    
    return averages

data = [10, 20, 30, 40, 50]
print(moving_average(data, 3))
# [10.0, 15.0, 20.0, 30.0, 40.0]
```

---

**实际应用：最近访问历史**

```python
from collections import deque

class RecentHistory:
    def __init__(self, max_size=10):
        self.history = deque(maxlen=max_size)
    
    def add(self, item):
        self.history.append(item)
    
    def get_recent(self, n=5):
        return list(self.history)[-n:]

# 使用
history = RecentHistory(max_size=5)
for i in range(10):
    history.add(f"action_{i}")

print(history.get_recent(3))
# ['action_7', 'action_8', 'action_9']
```

---

**4. namedtuple - 命名元组**

```python
from collections import namedtuple

# 定义命名元组
Point = namedtuple('Point', ['x', 'y'])
#                  ^^^^^^^ 类型名
#                           ^^^^^^^^^^^ 字段名

# 创建实例
p1 = Point(10, 20)
p2 = Point(x=30, y=40)

# 访问（两种方式）
print(p1.x, p1.y)  # 10 20（像对象一样访问）
print(p1[0], p1[1])  # 10 20（像元组一样访问）

# 不可变
# p1.x = 100  # AttributeError

# 转换
print(p1._asdict())  # {'x': 10, 'y': 20}
print(p1._replace(x=100))  # Point(x=100, y=20)

# 实际应用：函数返回多个值
Person = namedtuple('Person', ['name', 'age', 'city'])

def get_user(user_id):
    return Person('Alice', 30, 'Beijing')

user = get_user(1)
print(user.name)  # 'Alice'
print(user.age)   # 30
```

---

**5. OrderedDict - 有序字典**

```python
from collections import OrderedDict

# 注意：Python 3.7+ 普通 dict 已经保持插入顺序
# OrderedDict 主要用于向后兼容

# 创建
od = OrderedDict()
od['a'] = 1
od['b'] = 2
od['c'] = 3

print(od)  # OrderedDict([('a', 1), ('b', 2), ('c', 3)])

# 移动到末尾
od.move_to_end('a')
print(od)  # OrderedDict([('b', 2), ('c', 3), ('a', 1)])

# 移动到开头
od.move_to_end('c', last=False)
print(od)  # OrderedDict([('c', 3), ('b', 2), ('a', 1)])

# 弹出最后一项
key, value = od.popitem()
print(key, value)  # 'a', 1

# 弹出第一项
key, value = od.popitem(last=False)
print(key, value)  # 'c', 3
```

---

**6. ChainMap - 链式字典**

```python
from collections import ChainMap

# 多层配置
defaults = {'theme': 'dark', 'language': 'en', 'notifications': True}
user_config = {'theme': 'light'}
cli_args = {'notifications': False}

# 创建链式字典（优先级：cli_args > user_config > defaults）
config = ChainMap(cli_args, user_config, defaults)

print(config['theme'])         # 'light'（来自 user_config）
print(config['language'])      # 'en'（来自 defaults）
print(config['notifications']) # False（来自 cli_args）

# 查看所有映射
print(config.maps)
# [{'notifications': False}, {'theme': 'light'}, {...}]

# 实际应用：作用域查找
global_vars = {'x': 10}
local_vars = {'y': 20}

scope = ChainMap(local_vars, global_vars)
print(scope['x'])  # 10（从 global_vars）
print(scope['y'])  # 20（从 local_vars）
```

---

**常见陷阱和注意事项**

**陷阱 1：defaultdict 的默认值是调用结果**

```python
from collections import defaultdict
import time

# ❌ 错误：使用函数调用结果
d = defaultdict(time.time())  # TypeError！
# time.time() 立即执行，返回一个浮点数

# ✅ 正确：传入函数或 lambda
d = defaultdict(time.time)  # 传入函数本身
d = defaultdict(lambda: time.time())  # 或使用 lambda
```

---

**陷阱 2：Counter 的零和负数**

```python
from collections import Counter

c = Counter(['a', 'b', 'a'])
# Counter({'a': 2, 'b': 1})

# 访问不存在的键返回 0
print(c['z'])  # 0

# 减法后的零和负数会被移除
c['b'] -= 1
print(c)  # Counter({'a': 2, 'b': 0})

c['b'] -= 1
print(c)  # Counter({'a': 2})（b 被移除）

# 如果需要保留零和负数，手动设置
c['b'] = -1
print(c)  # Counter({'a': 2, 'b': -1})
```

---

**陷阱 3：deque 的 maxlen**

```python
from collections import deque

# 创建时指定 maxlen
d = deque([1, 2, 3], maxlen=3)

d.append(4)
print(d)  # deque([2, 3, 4])（自动移除最左边的 1）

# ⚠️ 注意：maxlen 不能事后修改
# d.maxlen = 5  # AttributeError
```

---

**陷阱 4：namedtuple 是不可变的**

```python
from collections import namedtuple

Point = namedtuple('Point', ['x', 'y'])
p = Point(10, 20)

# ❌ 错误：不能修改
# p.x = 100  # AttributeError

# ✅ 正确：使用 _replace 创建新实例
new_p = p._replace(x=100)
print(new_p)  # Point(x=100, y=20)
print(p)      # Point(x=10, y=20)（原对象不变）
```

---

#### **总结：collections 模块核心要点**

**必须掌握**

| 类            | 核心用途   | 典型场景           |
| ------------- | ---------- | ------------------ |
| `defaultdict` | 自动初始化 | 计数、分组、图结构 |
| `Counter`     | 计数统计   | 频率分析、投票     |
| `deque`       | 高效队列   | BFS、栈、滑动窗口  |
| `namedtuple`  | 轻量数据类 | 返回多值、简单对象 |

**性能对比**

| 操作     | list | deque  |
| -------- | ---- | ------ |
| 右端添加 | O(1) | O(1)   |
| 左端添加 | O(n) | O(1) ⭐ |
| 右端删除 | O(1) | O(1)   |
| 左端删除 | O(n) | O(1) ⭐ |
| 随机访问 | O(1) | O(n)   |

**最佳实践**

1. **defaultdict** - 用于避免键不存在检查
2. **Counter** - 用于统计，而不是手动字典计数
3. **deque** - 队列操作用 deque，不用 list
4. **namedtuple** - 简单数据结构用 namedtuple，不用 dict
5. **编译** - 需要重复使用时编译正则表达式

### 10.`enum` - 枚举类型

**什么是 enum？**

- Python 标准库，用于定义**枚举类型**（Enumeration）
- 一组**命名的常量**，比普通常量更安全、更清晰
- 标准库，无需安装

**为什么用 enum？**

```python
from enum import Enum

# ❌ 不好：使用字符串常量（容易拼写错误）
status = "running"
if status == "runing":  # 拼写错误！不会报错
    pass

# ✅ 好：使用枚举（类型安全）
class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"

status = Status.RUNNING
if status == Status.RUNING:  # 编辑器会立即提示错误！
    pass

# 优势：
# 1. 防止拼写错误
# 2. IDE 自动补全
# 3. 类型检查
# 4. 清晰的文档
```

---

#### **核心功能速查表**

**枚举类型**

| 类型      | 作用                | 示例                       |
| --------- | ------------------- | -------------------------- |
| `Enum`    | 基础枚举            | `Color.RED`                |
| `IntEnum` | 整数枚举            | `Priority.HIGH = 1`        |
| `StrEnum` | 字符串枚举（3.11+） | `Status.ACTIVE = "active"` |
| `Flag`    | 位标志              | `Permission.READ \| WRITE` |
| `IntFlag` | 整数位标志          | 可与整数运算               |
| `auto()`  | 自动赋值            | `RED = auto()`             |

**常用属性和方法**

| 属性/方法                                                    | 作用             | 示例                                                         |
| ------------------------------------------------------------ | ---------------- | ------------------------------------------------------------ |
| [.name](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:476:4-478:38) | 成员名称         | [Color.RED.name](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:476:4-478:38) → `"RED"` |
| `.value`                                                     | 成员值           | `Color.RED.value` → `1`                                      |
| `ClassName(value)`                                           | 通过值获取成员   | `Color(1)` → `Color.RED`                                     |
| `ClassName['name']`                                          | 通过名称获取成员 | `Color['RED']` → `Color.RED`                                 |
| `list(ClassName)`                                            | 获取所有成员     | `list(Color)`                                                |

**比较操作**

| 操作           | Enum | IntEnum | StrEnum |
| -------------- | ---- | ------- | ------- |
| `==`           | ✅    | ✅       | ✅       |
| `is`           | ✅    | ✅       | ✅       |
| `<`, `>`       | ❌    | ✅       | ✅       |
| 与基础类型比较 | ❌    | ✅       | ✅       |

---

> ## **AutoGPT Platform 中 的实际使用**
>
> #### **案例 1：BlockType - Block 类型枚举**
>
> ```python
> # backend/data/block.py
> from enum import Enum
> 
> class BlockType(Enum):
>     STANDARD = "Standard"
>     INPUT = "Input"
>     OUTPUT = "Output"
>     NOTE = "Note"
>     WEBHOOK = "Webhook"
>     WEBHOOK_MANUAL = "Webhook (manual)"
>     AGENT = "Agent"
>     AI = "AI"
>     AYRSHARE = "Ayrshare"
> ```
>
> **解释：**
> - 定义了 Block 的所有可能类型
> - 使用字符串作为值（便于序列化和显示）
> - 比硬编码字符串更安全
>
> **使用方式：**
> ```python
> # 比较 Block 类型
> if block.type == BlockType.INPUT:
>     print("这是输入块")
> 
> # 获取值用于显示
> display_name = block.type.value  # "Input"
> 
> # 从字符串创建枚举
> block_type = BlockType("Input")  # BlockType.INPUT
> ```
>
> ---
>
> #### **案例 2：BlockCategory - Block 分类枚举**
>
> ```python
> # backend/data/block.py
> from enum import Enum
> 
> class BlockCategory(Enum):
>     AI = "Block that leverages AI to perform a task."
>     SOCIAL = "Block that interacts with social media platforms."
>     TEXT = "Block that processes text data."
>     SEARCH = "Block that searches or extracts information from the internet."
>     BASIC = "Block that performs basic operations."
>     INPUT = "Block that interacts with input of the graph."
>     OUTPUT = "Block that interacts with output of the graph."
>     LOGIC = "Programming logic to control the flow of your agent"
>     COMMUNICATION = "Block that interacts with communication platforms."
>     DEVELOPER_TOOLS = "Developer tools such as GitHub blocks."
>     DATA = "Block that interacts with structured data."
>     HARDWARE = "Block that interacts with hardware."
>     AGENT = "Block that interacts with other agents."
> ```
>
> **解释：**
> - 枚举值是描述性的字符串
> - 既是标识符也是文档
> - 用于 Block 的分类和展示
>
> ---
>
> #### **案例 3：HttpMethod - HTTP 方法枚举**
>
> ```python
> # backend/blocks/http.py
> from enum import Enum
> 
> class HttpMethod(Enum):
>     GET = "GET"
>     POST = "POST"
>     PUT = "PUT"
>     DELETE = "DELETE"
>     PATCH = "PATCH"
>     OPTIONS = "OPTIONS"
>     HEAD = "HEAD"
> 
> # 在 Block 中使用
> class SendWebRequestBlock(Block):
>     class Input(BlockSchema):
>         url: str = SchemaField(
>             description="The URL to send the request to",
>             placeholder="https://api.example.com",
>         )
>         method: HttpMethod = SchemaField(
>             #      ^^^^^^^^^^ 使用枚举作为字段类型
>             description="The HTTP method to use for the request",
>             default=HttpMethod.POST,
>             #       ^^^^^^^^^^^^^^^ 枚举作为默认值
>         )
> ```
>
> **解释：**
> - 限制用户只能选择有效的 HTTP 方法
> - IDE 提供自动补全
> - 前端可以自动生成下拉菜单
>
> ---
>
> #### **案例 4：Operation - 数学运算枚举**
>
> ```python
> # backend/blocks/maths.py
> from enum import Enum
> import operator
> 
> class Operation(Enum):
>     ADD = "Add"
>     SUBTRACT = "Subtract"
>     MULTIPLY = "Multiply"
>     DIVIDE = "Divide"
>     POWER = "Power"
> 
> class CalculatorBlock(Block):
>     class Input(BlockSchema):
>         operation: Operation = SchemaField(
>             description="Choose the math operation you want to perform",
>             placeholder="Select an operation",
>         )
>         a: float = SchemaField(description="Enter the first number (A)")
>         b: float = SchemaField(description="Enter the second number (B)")
>     
>     async def run(self, input_data: Input, **kwargs) -> BlockOutput:
>         operation = input_data.operation
>         #           ^^^^^^^^^^^^^^^^^^^^ 枚举类型
>         
>         # 映射枚举到实际操作
>         operations = {
>             Operation.ADD: operator.add,
>             Operation.SUBTRACT: operator.sub,
>             Operation.MULTIPLY: operator.mul,
>             Operation.DIVIDE: operator.truediv,
>             Operation.POWER: operator.pow,
>         }
>         
>         # 使用枚举作为字典键
>         func = operations[operation]
>         result = func(input_data.a, input_data.b)
>         
>         yield "result", result
> ```
>
> **解释：**
> - 枚举成员可以作为字典的键
> - 比字符串匹配更安全
> - 便于扩展新操作
>
> ---
>
> #### **案例 5：StrEnum - 字符串枚举（第三方库）**
>
> ```python
> # backend/integrations/webhooks/github.py
> from strenum import StrEnum  # 第三方库
> 
> class GithubWebhookType(StrEnum):
>     REPO = "repo"
> 
> # StrEnum 的特点：枚举成员可以直接与字符串比较
> webhook_type = GithubWebhookType.REPO
> if webhook_type == "repo":  # ✅ StrEnum 支持
>     print("仓库 webhook")
> 
> # 普通 Enum 不支持：
> class NormalEnum(Enum):
>     REPO = "repo"
> 
> normal = NormalEnum.REPO
> if normal == "repo":  # ❌ 返回 False！
>     print("不会打印")
> ```
>
> **解释：**
> - `StrEnum` 是字符串的子类
> - 可以直接与字符串比较
> - Python 3.11+ 内置了 `StrEnum`
>
> ---
>
> #### **案例 6：ExecutionStatus - 从 Prisma 导入**
>
> ```python
> # backend/data/execution.py
> from prisma.enums import AgentExecutionStatus
> 
> # 直接使用 Prisma ORM 生成的枚举
> ExecutionStatus = AgentExecutionStatus
> 
> # 状态转换验证
> VALID_STATUS_TRANSITIONS = {
>     ExecutionStatus.QUEUED: [
>         ExecutionStatus.INCOMPLETE,
>     ],
>     ExecutionStatus.RUNNING: [
>         ExecutionStatus.QUEUED,
>         ExecutionStatus.INCOMPLETE,
>     ],
>     # ...
> }
> ```
>
> **解释：**
> - Prisma ORM 自动从数据库 schema 生成枚举
> - 保证代码与数据库的一致性
>

---

#### **详细功能讲解**

**1. 基础枚举（Enum）**

**定义枚举**

```python
from enum import Enum

# 基础枚举
class Color(Enum):
    RED = 1
    GREEN = 2
    BLUE = 3

# 字符串值
class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"

# 混合类型（不推荐）
class Mixed(Enum):
    INT_VALUE = 1
    STR_VALUE = "text"
    TUPLE_VALUE = (1, 2)
```

---

**访问枚举成员**

```python
from enum import Enum

class Color(Enum):
    RED = 1
    GREEN = 2
    BLUE = 3

# 直接访问
red = Color.RED

# 通过值获取
color = Color(1)  # Color.RED
print(color)  # Color.RED

# 通过名称获取
color = Color['RED']  # Color.RED

# 获取名称和值
print(Color.RED.name)   # "RED"
print(Color.RED.value)  # 1

# 遍历所有成员
for color in Color:
    print(f"{color.name} = {color.value}")
# RED = 1
# GREEN = 2
# BLUE = 3

# 获取所有成员
print(list(Color))  # [<Color.RED: 1>, <Color.GREEN: 2>, <Color.BLUE: 3>]
```

---

**枚举比较**

```python
from enum import Enum

class Color(Enum):
    RED = 1
    GREEN = 2

# 身份比较（推荐）
print(Color.RED is Color.RED)  # True
print(Color.RED is Color.GREEN)  # False

# 相等比较
print(Color.RED == Color.RED)  # True
print(Color.RED == Color.GREEN)  # False

# ❌ 不能与值直接比较
print(Color.RED == 1)  # False（普通 Enum）

# ❌ 不能大小比较
# print(Color.RED < Color.GREEN)  # TypeError

# 可以用在字典和集合中
colors = {Color.RED, Color.GREEN}
color_map = {Color.RED: "红色", Color.GREEN: "绿色"}
```

---

**2. auto() - 自动赋值**

```python
from enum import Enum, auto

class Color(Enum):
    RED = auto()     # 1
    GREEN = auto()   # 2
    BLUE = auto()    # 3

print(Color.RED.value)    # 1
print(Color.GREEN.value)  # 2

# 混合使用
class Status(Enum):
    PENDING = auto()     # 1
    RUNNING = 10
    COMPLETED = auto()   # 11（从最大值继续）

# 自定义 auto() 行为
class AutoName(Enum):
    def _generate_next_value_(name, start, count, last_values):
        return name.lower()

class Color(AutoName):
    RED = auto()     # "red"
    GREEN = auto()   # "green"

print(Color.RED.value)  # "red"
```

---

**3. IntEnum - 整数枚举**

```python
from enum import IntEnum

class Priority(IntEnum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3

# IntEnum 可以与整数比较和运算
print(Priority.HIGH == 3)       # True
print(Priority.HIGH > Priority.LOW)  # True
print(Priority.HIGH + 1)        # 4

# 可以用在需要整数的地方
priorities = [Priority.LOW, Priority.HIGH]
print(max(priorities))          # Priority.HIGH

# 排序
tasks = [
    {"name": "Task 1", "priority": Priority.HIGH},
    {"name": "Task 2", "priority": Priority.LOW},
    {"name": "Task 3", "priority": Priority.MEDIUM},
]
sorted_tasks = sorted(tasks, key=lambda t: t["priority"])
```

---

**4. StrEnum - 字符串枚举（Python 3.11+）**

```python
from enum import StrEnum  # Python 3.11+

class Status(StrEnum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"

# StrEnum 可以与字符串比较
print(Status.PENDING == "pending")  # True
print(Status.PENDING == "PENDING")  # False（大小写敏感）

# 可以用字符串方法
print(Status.PENDING.upper())  # "PENDING"
print(Status.PENDING.startswith("pen"))  # True

# 自动转换为字符串
def process_status(status: str):
    print(f"Processing: {status}")

process_status(Status.PENDING)  # "Processing: pending"
```

**Python 3.10 及以下的替代方案：**
```python
# 使用第三方库 strenum
from strenum import StrEnum

# 或者手动继承 str
class Status(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
```

---

**5. Flag - 位标志枚举**

```python
from enum import Flag, auto

class Permission(Flag):
    READ = auto()      # 1
    WRITE = auto()     # 2
    EXECUTE = auto()   # 4
    DELETE = auto()    # 8

# 组合标志（使用 | 运算符）
user_permission = Permission.READ | Permission.WRITE
print(user_permission)  # Permission.READ|WRITE

# 检查权限（使用 in 或 &）
if Permission.READ in user_permission:
    print("有读权限")

if user_permission & Permission.WRITE:
    print("有写权限")

# 添加权限
user_permission |= Permission.EXECUTE

# 移除权限
user_permission &= ~Permission.WRITE

# 实际应用
def check_permission(user_perm: Permission, required: Permission) -> bool:
    return (user_perm & required) == required

admin = Permission.READ | Permission.WRITE | Permission.DELETE
print(check_permission(admin, Permission.READ | Permission.WRITE))  # True
```

---

**6. 枚举的高级特性**

**为枚举添加方法**

```python
from enum import Enum

class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    
    def is_finished(self) -> bool:
        """检查状态是否已完成"""
        return self in (Status.COMPLETED, Status.FAILED)
    
    def can_cancel(self) -> bool:
        """检查是否可以取消"""
        return self in (Status.PENDING, Status.RUNNING)

# 使用
status = Status.RUNNING
if status.can_cancel():
    print("可以取消")

if status.is_finished():
    print("已完成")
else:
    print("进行中")
```

---

**为枚举添加属性**

```python
from enum import Enum

class HTTPStatus(Enum):
    def __init__(self, code, description):
        self.code = code
        self.description = description
    
    OK = 200, "Request succeeded"
    NOT_FOUND = 404, "Resource not found"
    SERVER_ERROR = 500, "Internal server error"

# 使用
status = HTTPStatus.OK
print(status.code)        # 200
print(status.description) # "Request succeeded"
print(status.value)       # (200, "Request succeeded")

# 实际应用
def handle_response(status: HTTPStatus):
    if status == HTTPStatus.OK:
        print(f"Success: {status.description}")
    else:
        print(f"Error {status.code}: {status.description}")
```

---

**枚举的唯一性约束**

```python
from enum import Enum, unique

# @unique 装饰器确保所有值都是唯一的
@unique
class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    # ACTIVE = "running"  # ValueError: duplicate values found

# 允许别名（不使用 @unique）
class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    ACTIVE = "running"   # 别名，指向 RUNNING

print(Status.ACTIVE is Status.RUNNING)  # True
print(Status.ACTIVE.value)              # "running"

# 遍历时别名不会单独列出
for status in Status:
    print(status)
# Status.PENDING
# Status.RUNNING（只列出主名称）
```

---

**7. 实际应用场景**

**状态机**

```python
from enum import Enum

class OrderStatus(Enum):
    CREATED = "created"
    PAID = "paid"
    SHIPPED = "shipped"
    DELIVERED = "delivered"
    CANCELLED = "cancelled"

VALID_TRANSITIONS = {
    OrderStatus.CREATED: [OrderStatus.PAID, OrderStatus.CANCELLED],
    OrderStatus.PAID: [OrderStatus.SHIPPED, OrderStatus.CANCELLED],
    OrderStatus.SHIPPED: [OrderStatus.DELIVERED],
    OrderStatus.DELIVERED: [],
    OrderStatus.CANCELLED: [],
}

def can_transition(current: OrderStatus, target: OrderStatus) -> bool:
    """检查状态转换是否有效"""
    return target in VALID_TRANSITIONS.get(current, [])

# 使用
current = OrderStatus.CREATED
if can_transition(current, OrderStatus.PAID):
    print("可以支付")
```

---

**配置选项**

```python
from enum import Enum

class Environment(Enum):
    DEVELOPMENT = "dev"
    STAGING = "staging"
    PRODUCTION = "prod"
    
    @property
    def is_production(self) -> bool:
        return self == Environment.PRODUCTION
    
    @property
    def debug_mode(self) -> bool:
        return self in (Environment.DEVELOPMENT, Environment.STAGING)

# 使用
env = Environment.DEVELOPMENT
if env.debug_mode:
    print("调试模式已启用")
```

---

**API 响应代码**

```python
from enum import IntEnum

class ErrorCode(IntEnum):
    SUCCESS = 0
    INVALID_INPUT = 1001
    UNAUTHORIZED = 1002
    NOT_FOUND = 1003
    SERVER_ERROR = 5000

def create_response(code: ErrorCode, message: str):
    return {
        "code": code.value,
        "name": code.name,
        "message": message
    }

# 使用
response = create_response(ErrorCode.SUCCESS, "操作成功")
# {"code": 0, "name": "SUCCESS", "message": "操作成功"}
```

---

**常见陷阱和注意事项**

**陷阱 1：普通 Enum 不能与值直接比较**

```python
from enum import Enum

class Status(Enum):
    PENDING = "pending"

# ❌ 错误：普通 Enum 不等于其值
status = Status.PENDING
if status == "pending":  # False！
    print("不会打印")

# ✅ 正确：比较 value
if status.value == "pending":
    print("会打印")

# ✅ 或使用 StrEnum（Python 3.11+）
from enum import StrEnum

class Status(StrEnum):
    PENDING = "pending"

status = Status.PENDING
if status == "pending":  # True
    print("会打印")
```

---

**陷阱 2：不能修改枚举成员**

```python
from enum import Enum

class Color(Enum):
    RED = 1

# ❌ 错误：枚举是不可变的
# Color.RED = 2  # AttributeError
# Color.RED.value = 2  # AttributeError

# ❌ 错误：不能添加新成员
# Color.YELLOW = 4  # AttributeError
```

---

**陷阱 3：枚举成员名称不能重复**

```python
from enum import Enum

# ❌ 错误：名称必须唯一
class Status(Enum):
    PENDING = "pending"
    PENDING = "waiting"  # SyntaxError

# ✅ 正确：值可以重复（创建别名）
class Status(Enum):
    PENDING = "pending"
    WAITING = "pending"  # 别名

print(Status.WAITING is Status.PENDING)  # True
```

---

**陷阱 4：枚举的布尔值**

```python
from enum import Enum

class Status(Enum):
    INACTIVE = 0
    ACTIVE = 1

# ⚠️ 注意：所有枚举成员的布尔值都是 True
status = Status.INACTIVE
if status:  # True（即使值是 0）
    print("会打印")

# ✅ 正确：比较值
if status.value:
    print("不会打印")
```

---

**陷阱 5：JSON 序列化**

```python
import json
from enum import Enum

class Status(Enum):
    PENDING = "pending"

data = {"status": Status.PENDING}

# ❌ 错误：Enum 不能直接序列化
# json.dumps(data)  # TypeError

# ✅ 正确：使用 value
data = {"status": Status.PENDING.value}
json.dumps(data)  # '{"status": "pending"}'

# ✅ 或自定义 encoder
class EnumEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Enum):
            return obj.value
        return super().default(obj)

json.dumps({"status": Status.PENDING}, cls=EnumEncoder)
```

---

#### **总结：enum 模块核心要点**

**必须掌握**

| 概念                                                         | 说明             |
| ------------------------------------------------------------ | ---------------- |
| `Enum`                                                       | 基础枚举类       |
| [.name](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:476:4-478:38) | 成员名称         |
| `.value`                                                     | 成员值           |
| `ClassName(value)`                                           | 通过值获取成员   |
| `ClassName['name']`                                          | 通过名称获取成员 |

**常用类型**

| 类型      | 特点           | 何时使用       |
| --------- | -------------- | -------------- |
| `Enum`    | 基础枚举       | 一般场景       |
| `IntEnum` | 可与整数比较   | 优先级、状态码 |
| `StrEnum` | 可与字符串比较 | API 参数、配置 |
| `Flag`    | 位标志         | 权限、选项组合 |
| `auto()`  | 自动赋值       | 简化定义       |

**最佳实践**

1. **使用枚举而非常量** - 类型安全、自动补全
2. **选择合适的基类** - `IntEnum`/`StrEnum` 根据需求
3. **添加方法** - 封装业务逻辑
4. **文档化** - 枚举值应该是自解释的
5. **状态机** - 使用字典定义有效转换

### 11.`abc` - 抽象基类

**什么是 abc？**

- Python 标准库，用于定义**抽象基类**（Abstract Base Class）
- 强制子类实现特定的方法和属性
- 提供"接口"或"契约"的概念
- 标准库，无需安装

**为什么用 abc？**

1. **强制子类实现方法** - 编译时检查
2. **明确的接口定义** - 清晰的契约
3. **更好的文档** - 一眼看出必须实现什么
4. **防止实例化抽象类** - 只能实例化具体类

---

#### **核心功能速查表**

**主要装饰器和类**

| 名称                | 作用                                                 |
| ------------------- | ---------------------------------------------------- |
| `ABC`               | 抽象基类的基类                                       |
| `@abstractmethod`   | 标记抽象方法（必须实现）                             |
| `@abstractproperty` | 抽象属性（已废弃，用 `@property + @abstractmethod`） |
| `ABCMeta`           | 抽象基类的元类                                       |

**抽象成员类型**

| 类型         | 定义方式                            | 说明             |
| ------------ | ----------------------------------- | ---------------- |
| 抽象方法     | `@abstractmethod`                   | 子类必须实现     |
| 抽象属性     | `@property` + `@abstractmethod`     | 子类必须提供     |
| 抽象类方法   | `@classmethod` + `@abstractmethod`  | 类方法必须实现   |
| 抽象静态方法 | `@staticmethod` + `@abstractmethod` | 静态方法必须实现 |

**检查方法**

| 方法                          | 作用         |
| ----------------------------- | ------------ |
| `isinstance(obj, Class)`      | 检查实例     |
| `issubclass(SubClass, Class)` | 检查继承     |
| `Class.register(SubClass)`    | 虚拟子类注册 |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：Block - 核心抽象基类**
>
> ```python
> # backend/data/block.py
> from abc import ABC, abstractmethod
> from typing import Generic, TypeVar
> 
> BlockSchemaInputType = TypeVar("BlockSchemaInputType", bound=BlockSchema)
> BlockSchemaOutputType = TypeVar("BlockSchemaOutputType", bound=BlockSchema)
> 
> class Block(ABC, Generic[BlockSchemaInputType, BlockSchemaOutputType]):
>     #         ^^^ 继承 ABC，表示这是一个抽象基类
>     
>     def __init__(
>         self,
>         id: str = "",
>         description: str = "",
>         input_schema: Type[BlockSchemaInputType] = EmptySchema,
>         output_schema: Type[BlockSchemaOutputType] = EmptySchema,
>         # ... 其他参数
>     ):
>         """初始化 Block（所有子类共享的逻辑）"""
>         self.id = id
>         self.description = description
>         self.input_schema = input_schema
>         self.output_schema = output_schema
>         # ...
>     
>     @abstractmethod
>     #^^^^^^^^^^^^^^^^ 标记为抽象方法
>     async def run(self, input_data: BlockSchemaInputType, **kwargs) -> BlockOutput:
>         """
>         Run the block with the given input data.
>         
>         ⚠️ 所有子类 MUST 实现这个方法！
>         """
>         # 占位代码，永远不会执行
>         if False:
>             yield "name", "value"
>         raise NotImplementedError(f"{self.name} does not implement the run method.")
>     
>     # 非抽象方法（子类可以直接使用）
>     async def run_once(self, input_data: BlockSchemaInputType, **kwargs) -> Any:
>         """辅助方法，可以直接使用"""
>         async for item in self.run(input_data, **kwargs):
>             name, data = item
>             return data
> ```
>
> **解释：**
> - [Block](cci:2://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:339:0-545:9) 是抽象基类，不能直接实例化
> - [run()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:439:4-461:84) 是抽象方法，所有子类必须实现
> - [__init__()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:340:4-433:36) 和 [run_once()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:463:4-470:80) 是具体方法，子类可以直接使用
>
> ---
>
> #### **案例 2：FileStoreBlock - 实现抽象方法**
>
> ```python
> # backend/blocks/basic.py
> from backend.data.block import Block, BlockOutput, BlockSchema
> 
> class FileStoreBlock(Block):
>     #                  ^^^^^ 继承 Block（抽象基类）
>     
>     class Input(BlockSchema):
>         file_in: MediaFileType = SchemaField(
>             description="The file to store in the temporary directory"
>         )
>     
>     class Output(BlockSchema):
>         file_out: MediaFileType = SchemaField(
>             description="The relative path to the stored file"
>         )
>     
>     def __init__(self):
>         super().__init__(  # 调用父类的 __init__
>             id="cbb50872-625b-42f0-8203-a2ae78242d8a",
>             description="Stores the input file in the temporary directory.",
>             input_schema=FileStoreBlock.Input,
>             output_schema=FileStoreBlock.Output,
>         )
>     
>     # ✅ 实现抽象方法
>     async def run(
>         self,
>         input_data: Input,
>         *,
>         graph_exec_id: str,
>         user_id: str,
>         **kwargs,
>     ) -> BlockOutput:
>         """实现了 Block 的抽象方法"""
>         yield "file_out", await store_media_file(
>             graph_exec_id=graph_exec_id,
>             file=input_data.file_in,
>             user_id=user_id,
>         )
> 
> # 使用
> block = FileStoreBlock()  # ✅ 可以实例化（因为实现了所有抽象方法）
> ```
>
> **如果忘记实现会怎样？**
>
> ```python
> class IncompleteBlock(Block):
>     def __init__(self):
>         super().__init__(id="test")
>     
>     # ❌ 忘记实现 run() 方法
> 
> # 尝试实例化
> block = IncompleteBlock()
> # TypeError: Can't instantiate abstract class IncompleteBlock 
> # with abstract method run
> ```
>
> ---
>
> #### **案例 3：UserCreditBase - 多个抽象方法**
>
> ```python
> # backend/data/credit.py
> from abc import ABC, abstractmethod
> 
> class UserCreditBase(ABC):
>     """用户积分系统的抽象基类"""
>     
>     @abstractmethod
>     async def get_credits(self, user_id: str) -> int:
>         """获取用户积分（必须实现）"""
>         pass
>     
>     @abstractmethod
>     async def spend_credits(
>         self,
>         user_id: str,
>         cost: int,
>         metadata: UsageTransactionMetadata,
>     ) -> int:
>         """消费积分（必须实现）"""
>         pass
>     
>     @abstractmethod
>     async def top_up_credits(self, user_id: str, amount: int):
>         """充值积分（必须实现）"""
>         pass
>     
>     @abstractmethod
>     async def get_transaction_history(
>         self,
>         user_id: str,
>         transaction_count_limit: int,
>     ) -> TransactionHistory:
>         """获取交易历史（必须实现）"""
>         pass
>     
>     # ... 还有更多抽象方法
> 
> # 具体实现（在其他文件中）
> class DatabaseCreditManager(UserCreditBase):
>     """使用数据库的具体实现"""
>     
>     async def get_credits(self, user_id: str) -> int:
>         # 从数据库查询
>         return await db.query(...)
>     
>     async def spend_credits(self, user_id: str, cost: int, metadata) -> int:
>         # 更新数据库
>         return await db.update(...)
>     
>     # ... 实现所有抽象方法
> ```
>
> **解释：**
> - [UserCreditBase](cci:2://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/credit.py:63:0-380:59) 定义了积分系统的"契约"
> - 任何实现都必须提供这些方法
> - 可以有多个实现（数据库、缓存、测试 mock 等）
>
> ---
>
> #### **案例 4：BaseOAuthHandler - OAuth 处理器基类**
>
> ```python
> # backend/integrations/oauth/base.py
> from abc import ABC, abstractmethod
> from typing import ClassVar
> 
> class BaseOAuthHandler(ABC):
>     PROVIDER_NAME: ClassVar[ProviderName | str]
>     DEFAULT_SCOPES: ClassVar[list[str]] = []
>     
>     @abstractmethod
>     def __init__(self, client_id: str, client_secret: str, redirect_uri: str):
>         """子类必须实现构造函数"""
>         ...
>     
>     @abstractmethod
>     def get_login_url(
>         self, scopes: list[str], state: str, code_challenge: Optional[str]
>     ) -> str:
>         """获取登录 URL（必须实现）"""
>         ...
>     
>     @abstractmethod
>     async def exchange_code_for_tokens(
>         self, code: str, scopes: list[str], code_verifier: Optional[str]
>     ) -> tuple[str, str]:
>         """交换授权码为令牌（必须实现）"""
>         ...
>     
>     @abstractmethod
>     async def _refresh_tokens(self, credentials: OAuth2Credentials) -> OAuth2Credentials:
>         """刷新令牌（必须实现）"""
>         ...
>     
>     @abstractmethod
>     async def revoke_tokens(self, credentials: OAuth2Credentials) -> bool:
>         """撤销令牌（必须实现）"""
>         ...
> 
> # 具体实现
> class GitHubOAuthHandler(BaseOAuthHandler):
>     PROVIDER_NAME = ProviderName.GITHUB
>     DEFAULT_SCOPES = ["user:email"]
>     
>     def __init__(self, client_id: str, client_secret: str, redirect_uri: str):
>         self.client_id = client_id
>         self.client_secret = client_secret
>         self.redirect_uri = redirect_uri
>     
>     def get_login_url(self, scopes, state, code_challenge):
>         return f"https://github.com/login/oauth/authorize?..."
>     
>     # ... 实现所有抽象方法
> ```
>

#### **详细功能讲解**

**1. 基础用法**

**定义抽象基类**

```python
from abc import ABC, abstractmethod

# 方式 1：继承 ABC（推荐）
class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        pass
    
    @abstractmethod
    def move(self):
        pass

# 方式 2：使用 ABCMeta 元类（不推荐）
from abc import ABCMeta

class Animal(metaclass=ABCMeta):
    @abstractmethod
    def make_sound(self):
        pass
```

---

**实现抽象基类**

```python
from abc import ABC, abstractmethod

class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        pass

# ✅ 正确：实现所有抽象方法
class Dog(Animal):
    def make_sound(self):
        return "汪汪"

dog = Dog()  # ✅ 可以实例化
print(dog.make_sound())  # "汪汪"

# ❌ 错误：没有实现抽象方法
class Cat(Animal):
    pass  # 忘记实现 make_sound

cat = Cat()  # TypeError: Can't instantiate abstract class Cat
```

---

**2. 抽象方法的变体**

**抽象属性（@property + @abstractmethod）**

```python
from abc import ABC, abstractmethod

class Shape(ABC):
    @property
    @abstractmethod
    def area(self) -> float:
        """面积（必须实现）"""
        pass
    
    @property
    @abstractmethod
    def perimeter(self) -> float:
        """周长（必须实现）"""
        pass

class Rectangle(Shape):
    def __init__(self, width: float, height: float):
        self.width = width
        self.height = height
    
    @property
    def area(self) -> float:
        return self.width * self.height
    
    @property
    def perimeter(self) -> float:
        return 2 * (self.width + self.height)

# 使用
rect = Rectangle(10, 5)
print(rect.area)       # 50
print(rect.perimeter)  # 30
```

---

**抽象类方法（@classmethod + @abstractmethod）**

```python
from abc import ABC, abstractmethod

class DataSource(ABC):
    @classmethod
    @abstractmethod
    def from_url(cls, url: str) -> "DataSource":
        """从 URL 创建数据源（必须实现）"""
        pass
    
    @abstractmethod
    def read(self) -> str:
        """读取数据（必须实现）"""
        pass

class FileDataSource(DataSource):
    def __init__(self, path: str):
        self.path = path
    
    @classmethod
    def from_url(cls, url: str) -> "FileDataSource":
        # 实现类方法
        path = url.replace("file://", "")
        return cls(path)
    
    def read(self) -> str:
        with open(self.path) as f:
            return f.read()

# 使用
source = FileDataSource.from_url("file:///path/to/file.txt")
data = source.read()
```

---

**抽象静态方法（@staticmethod + @abstractmethod）**

```python
from abc import ABC, abstractmethod

class Validator(ABC):
    @staticmethod
    @abstractmethod
    def validate(value: str) -> bool:
        """验证值（必须实现）"""
        pass

class EmailValidator(Validator):
    @staticmethod
    def validate(value: str) -> bool:
        return "@" in value and "." in value

# 使用
print(EmailValidator.validate("user@example.com"))  # True
print(EmailValidator.validate("invalid"))           # False
```

---

**3. 混合抽象和具体方法**

```python
from abc import ABC, abstractmethod

class Database(ABC):
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.is_connected = False
    
    @abstractmethod
    def connect(self):
        """连接数据库（子类必须实现）"""
        pass
    
    @abstractmethod
    def execute(self, query: str) -> list:
        """执行查询（子类必须实现）"""
        pass
    
    # 具体方法（子类可以直接使用）
    def disconnect(self):
        """断开连接（提供默认实现）"""
        self.is_connected = False
        print("已断开连接")
    
    # 具体方法（使用抽象方法）
    def query_one(self, query: str):
        """查询单个结果（使用抽象方法 execute）"""
        results = self.execute(query)
        return results[0] if results else None

class PostgreSQL(Database):
    def connect(self):
        print(f"连接到 PostgreSQL: {self.connection_string}")
        self.is_connected = True
    
    def execute(self, query: str) -> list:
        print(f"执行查询: {query}")
        return [{"id": 1, "name": "Alice"}]

# 使用
db = PostgreSQL("postgres://localhost/mydb")
db.connect()
result = db.query_one("SELECT * FROM users")  # 使用具体方法
print(result)
db.disconnect()  # 使用具体方法
```

---

**4. 模板方法模式**

```python
from abc import ABC, abstractmethod

class DataProcessor(ABC):
    """模板方法模式：定义算法骨架"""
    
    def process(self, data: str):
        """模板方法（定义处理流程）"""
        # 1. 验证
        if not self.validate(data):
            raise ValueError("数据验证失败")
        
        # 2. 转换
        transformed = self.transform(data)
        
        # 3. 保存
        self.save(transformed)
        
        # 4. 通知
        self.notify()
    
    @abstractmethod
    def validate(self, data: str) -> bool:
        """验证数据（子类实现）"""
        pass
    
    @abstractmethod
    def transform(self, data: str) -> str:
        """转换数据（子类实现）"""
        pass
    
    @abstractmethod
    def save(self, data: str):
        """保存数据（子类实现）"""
        pass
    
    def notify(self):
        """通知（可选覆盖）"""
        print("处理完成")

class CSVProcessor(DataProcessor):
    def validate(self, data: str) -> bool:
        return "," in data
    
    def transform(self, data: str) -> str:
        return data.upper()
    
    def save(self, data: str):
        print(f"保存 CSV: {data}")

# 使用
processor = CSVProcessor()
processor.process("name,age\nAlice,30")
```

---

**5. 检查和注册**

**检查类型**

```python
from abc import ABC, abstractmethod

class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        pass

class Dog(Animal):
    def make_sound(self):
        return "汪汪"

dog = Dog()

# 检查实例
print(isinstance(dog, Animal))  # True
print(isinstance(dog, Dog))     # True

# 检查子类
print(issubclass(Dog, Animal))  # True
print(issubclass(Animal, Dog))  # False
```

---

**虚拟子类（register）**

```python
from abc import ABC

class Drawable(ABC):
    @abstractmethod
    def draw(self):
        pass

# 外部类（无法修改源码）
class Circle:
    def draw(self):
        print("画圆")

# 注册为虚拟子类
Drawable.register(Circle)

circle = Circle()
print(isinstance(circle, Drawable))  # True（虚拟继承）
print(issubclass(Circle, Drawable))  # True

# 但是 Circle 没有真正继承 Drawable
print(Circle.__bases__)  # (<class 'object'>)
```

---

**6. 部分实现（中间抽象类）**

```python
from abc import ABC, abstractmethod

class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        pass
    
    @abstractmethod
    def move(self):
        pass

class Mammal(Animal):
    """中间抽象类：实现部分方法"""
    
    def move(self):
        return "四条腿走路"  # 实现了 move
    
    # make_sound 仍然是抽象的（没有实现）

class Dog(Mammal):
    """具体类：实现所有剩余的抽象方法"""
    
    def make_sound(self):
        return "汪汪"

# ❌ 不能实例化中间抽象类
# mammal = Mammal()  # TypeError

# ✅ 可以实例化具体类
dog = Dog()
print(dog.make_sound())  # "汪汪"
print(dog.move())        # "四条腿走路"
```

---

**7. 带参数的抽象方法**

```python
from abc import ABC, abstractmethod
from typing import Any

class Storage(ABC):
    @abstractmethod
    def save(self, key: str, value: Any) -> None:
        """保存数据"""
        pass
    
    @abstractmethod
    def load(self, key: str) -> Any:
        """加载数据"""
        pass
    
    @abstractmethod
    def delete(self, key: str) -> bool:
        """删除数据"""
        pass

class FileStorage(Storage):
    def __init__(self, directory: str):
        self.directory = directory
    
    def save(self, key: str, value: Any) -> None:
        path = f"{self.directory}/{key}.json"
        with open(path, 'w') as f:
            json.dump(value, f)
    
    def load(self, key: str) -> Any:
        path = f"{self.directory}/{key}.json"
        with open(path, 'r') as f:
            return json.load(f)
    
    def delete(self, key: str) -> bool:
        path = f"{self.directory}/{key}.json"
        if os.path.exists(path):
            os.remove(path)
            return True
        return False
```

---

**常见陷阱和注意事项**

**陷阱 1：忘记 @abstractmethod 装饰器**

```python
from abc import ABC

class Animal(ABC):
    def make_sound(self):  # ❌ 忘记 @abstractmethod
        pass

class Dog(Animal):
    pass  # 没有实现 make_sound

dog = Dog()  # ✅ 可以实例化（但这不是我们想要的）
```

---

**陷阱 2：装饰器顺序错误**

```python
from abc import ABC, abstractmethod

class Shape(ABC):
    # ❌ 错误：顺序反了
    @abstractmethod
    @property
    def area(self):
        pass
    
    # ✅ 正确：@property 在上
    @property
    @abstractmethod
    def perimeter(self):
        pass
```

**规则：`@abstractmethod` 应该在最里层（最后一个）**

```python
# 正确顺序
@classmethod
@abstractmethod

@staticmethod
@abstractmethod

@property
@abstractmethod
```

---

**陷阱 3：抽象方法中写了实现**

```python
from abc import ABC, abstractmethod

class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        return "默认声音"  # 可以有默认实现

class Dog(Animal):
    def make_sound(self):
        # 可以调用父类的实现
        default = super().make_sound()
        return f"{default} - 汪汪"

dog = Dog()
print(dog.make_sound())  # "默认声音 - 汪汪"
```

**注意：**抽象方法可以有默认实现，子类可以选择调用或覆盖。

---

**陷阱 4：直接实例化抽象基类**

```python
from abc import ABC, abstractmethod

class Animal(ABC):
    @abstractmethod
    def make_sound(self):
        pass

# ❌ 错误：不能实例化抽象类
animal = Animal()  # TypeError: Can't instantiate abstract class Animal
```

---

**陷阱 5：多重继承时的抽象方法**

```python
from abc import ABC, abstractmethod

class Flyable(ABC):
    @abstractmethod
    def fly(self):
        pass

class Swimmable(ABC):
    @abstractmethod
    def swim(self):
        pass

class Duck(Flyable, Swimmable):
    # 必须实现两个抽象方法
    def fly(self):
        return "鸭子飞"
    
    def swim(self): 
        return "鸭子游"

duck = Duck()  # ✅ 实现了所有抽象方法
```

---

#### **总结：abc 模块核心要点**

**必须掌握**

| 概念              | 说明                     |
| ----------------- | ------------------------ |
| `ABC`             | 抽象基类的基类           |
| `@abstractmethod` | 标记抽象方法             |
| 不能实例化        | 抽象类不能直接创建实例   |
| 强制实现          | 子类必须实现所有抽象方法 |

**使用场景**

| 场景     | 说明                   |
| -------- | ---------------------- |
| 定义接口 | 规定子类必须实现的方法 |
| 模板方法 | 定义算法骨架           |
| 插件系统 | 定义插件接口           |
| 多态     | 不同实现共享接口       |

**最佳实践**

1. **使用 ABC 定义接口** - 明确契约
2. **抽象方法要有文档** - 说明期望的行为
3. **混合具体方法** - 提供通用功能
4. **装饰器顺序正确** - `@abstractmethod` 在最里层
5. **合理设计层次** - 不要过度抽象

> ### **AutoGPT Platform 中的应用**
> ```python
> # Block 系统
> Block (ABC)
> ├── FileStoreBlock
> ├── StoreValueBlock
> ├── HttpRequestBlock
> └── LLMBlock
> 
> # 积分系统
> UserCreditBase (ABC)
> ├── DatabaseCreditManager
> └── MockCreditManager
> 
> # OAuth 处理
> BaseOAuthHandler (ABC)
> ├── GitHubOAuthHandler
> ├── GoogleOAuthHandler
> └── DiscordOAuthHandler
> ```
>

### 12.`functools` - 函数工具

**什么是 functools？**

- Python 标准库，用于**高阶函数**和函数操作
- 提供函数式编程工具
- 增强函数功能（缓存、偏函数、装饰器等）
- 标准库，无需安装

---

#### **核心功能速查表**

**主要函数**

| 函数              | 作用             | 使用场景     |
| ----------------- | ---------------- | ------------ |
| `@lru_cache`      | LRU 缓存装饰器   | 缓存函数结果 |
| `@cache`          | 无限缓存（3.9+） | 简单缓存     |
| `@wraps`          | 保留函数元数据   | 编写装饰器   |
| `partial`         | 部分应用函数     | 固定部分参数 |
| `reduce`          | 累积操作         | 聚合计算     |
| `@total_ordering` | 自动生成比较方法 | 自定义排序   |
| `@singledispatch` | 单分派泛型函数   | 函数重载     |

**缓存装饰器对比**

| 装饰器                     | 容量 | 淘汰策略            | Python 版本 |
| -------------------------- | ---- | ------------------- | ----------- |
| `@lru_cache(maxsize=128)`  | 限制 | LRU（最近最少使用） | 3.2+        |
| `@lru_cache(maxsize=None)` | 无限 | 无                  | 3.2+        |
| `@cache`                   | 无限 | 无                  | 3.9+        |

**常用参数**

| 函数        | 参数              | 说明                  |
| ----------- | ----------------- | --------------------- |
| `lru_cache` | `maxsize`         | 缓存大小（None=无限） |
| `lru_cache` | `typed`           | 是否区分参数类型      |
| `partial`   | `func`            | 要包装的函数          |
| `partial`   | `*args, **kwargs` | 固定的参数            |

---

> **AutoGPT Platform 中的实际使用**
>
> **案例 1：@wraps - 保留函数元数据（装饰器必备）**
>
> ```python
> # backend/util/decorator.py
> import functools
> 
> def time_measured(func: Callable) -> Callable:
>     """测量函数执行时间的装饰器"""
>     
>     @functools.wraps(func)
>     #^^^^^^^^^^^^^^^^^ 保留原函数的 __name__, __doc__ 等元数据
>     def wrapper(*args, **kwargs):
>         start_time = time.time()
>         try:
>             result = func(*args, **kwargs)
>         except BaseException as e:
>             result = e
>         finally:
>             duration = time.time() - start_time
>             timing_info = TimingInfo(wall_time=duration)
>         return timing_info, result
>     
>     return wrapper
> 
> # 使用
> @time_measured
> def process_data(data):
>     """处理数据的函数"""
>     return data * 2
> 
> print(process_data.__name__)  # "process_data"（如果没有 @wraps 会是 "wrapper"）
> print(process_data.__doc__)   # "处理数据的函数"（保留了原文档）
> ```
>
> **为什么需要 @wraps？**
>
> ```python
> # ❌ 不使用 @wraps
> def bad_decorator(func):
>     def wrapper(*args, **kwargs):
>         return func(*args, **kwargs)
>     return wrapper
> 
> @bad_decorator
> def my_function():
>     """我的函数"""
>     pass
> 
> print(my_function.__name__)  # "wrapper" ❌ 错误！
> print(my_function.__doc__)   # None ❌ 丢失了文档！
> 
> # ✅ 使用 @wraps
> from functools import wraps
> 
> def good_decorator(func):
>     @wraps(func)  # 保留元数据
>     def wrapper(*args, **kwargs):
>         return func(*args, **kwargs)
>     return wrapper
> 
> @good_decorator
> def my_function():
>     """我的函数"""
>     pass
> 
> print(my_function.__name__)  # "my_function" ✅ 正确！
> print(my_function.__doc__)   # "我的函数" ✅ 保留了文档！
> ```
>
> ---
>
> **案例 2：@wraps 用于异步装饰器**
>
> ```python
> # backend/util/decorator.py
> import functools
> 
> def async_time_measured(func: Callable) -> Callable:
>     """异步函数的时间测量装饰器"""
>     
>     @functools.wraps(func)
>     async def async_wrapper(*args, **kwargs):
>         start_time = time.time()
>         try:
>             result = await func(*args, **kwargs)  # await 异步函数
>         except BaseException as e:
>             result = e
>         finally:
>             duration = time.time() - start_time
>             timing_info = TimingInfo(wall_time=duration)
>         return timing_info, result
>     
>     return async_wrapper
> 
> # 使用
> @async_time_measured
> async def fetch_data(url):
>     """异步获取数据"""
>     return await http_client.get(url)
> ```
>
> ---
>
> **案例 3：@wraps 用于错误处理装饰器**
>
> ```python
> # backend/util/decorator.py
> import functools
> 
> def error_logged(*, swallow: bool = True):
>     """记录错误的装饰器"""
>     
>     def decorator(f: Callable) -> Callable:
>         @functools.wraps(f)
>         #^^^^^^^^^^^^^^^^^ 保留原函数信息
>         def wrapper(*args, **kwargs):
>             try:
>                 return f(*args, **kwargs)
>             except BaseException as e:
>                 logger.exception(f"Error in {f.__name__}: {e}")
>                 #                          ^^^^^^^^^ 使用原函数名（因为有 @wraps）
>                 if not swallow:
>                     raise
>                 return None
>         return wrapper
>     return decorator
> 
> # 使用
> @error_logged(swallow=False)
> def risky_operation():
>     """可能出错的操作"""
>     return 1 / 0
> ```
>
> ---
>
> **案例 4：@wraps 用于特性开关装饰器**
>
> ```python
> # backend/util/feature_flag.py
> from functools import wraps
> 
> def feature_flag(flag_key: str, default: bool = False):
>     """特性开关装饰器"""
>     
>     def decorator(func: Callable) -> Callable:
>         @wraps(func)
>         #^^^^^ 保留原函数的元数据
>         async def async_wrapper(*args, **kwargs):
>             user_id = kwargs.get("user_id")
>             
>             # 检查特性是否启用
>             is_enabled = await get_feature_flag_value(flag_key, user_id, default)
>             
>             if not is_enabled:
>                 raise HTTPException(status_code=404, detail="Feature not available")
>             
>             # 特性启用，执行原函数
>             return await func(*args, **kwargs)
>         
>         return async_wrapper
>     
>     return decorator
> 
> # 使用
> @feature_flag("beta-feature", default=False)
> async def beta_endpoint(user_id: str):
>     """测试版功能端点"""
>     return {"message": "欢迎使用测试版功能"}
> ```
>
> ---
>
> **案例 5：@wraps 用于重试装饰器**
>
> ```python
> # backend/util/retry.py
> from functools import wraps
> 
> def conn_retry(resource_name: str, action_name: str, max_retry: int = 100):
>     """连接重试装饰器"""
>     
>     def decorator(func):
>         # 先应用 tenacity 的 retry
>         retry_decorator = retry(
>             stop=stop_after_attempt(max_retry + 1),
>             wait=wait_exponential_jitter(max=30),
>         )
>         wrapped_func = retry_decorator(func)
>         
>         @wraps(func)
>         #^^^^^ 保留原函数元数据
>         def sync_wrapper(*args, **kwargs):
>             logger.info(f"{resource_name} {action_name} started...")
>             try:
>                 result = wrapped_func(*args, **kwargs)
>                 logger.info(f"{resource_name} {action_name} completed.")
>                 return result
>             except Exception as e:
>                 logger.error(f"{resource_name} {action_name} failed: {e}")
>                 raise
>         
>         @wraps(func)
>         async def async_wrapper(*args, **kwargs):
>             logger.info(f"{resource_name} {action_name} started...")
>             try:
>                 result = await wrapped_func(*args, **kwargs)
>                 logger.info(f"{resource_name} {action_name} completed.")
>                 return result
>             except Exception as e:
>                 logger.error(f"{resource_name} {action_name} failed: {e}")
>                 raise
>         
>         # 根据函数类型返回对应的 wrapper
>         is_coroutine = asyncio.iscoroutinefunction(func)
>         return async_wrapper if is_coroutine else sync_wrapper
>     
>     return decorator
> 
> # 使用
> @conn_retry("Database", "Connect")
> def connect_to_database():
>     """连接数据库"""
>     return db.connect()
> ```
>

#### **详细功能讲解**

**1. @wraps - 保留函数元数据**

**基础用法**

```python
from functools import wraps

def my_decorator(func):
    @wraps(func)  # 关键：保留原函数的元数据
    def wrapper(*args, **kwargs):
        print("Before")
        result = func(*args, **kwargs)
        print("After")
        return result
    return wrapper

@my_decorator
def greet(name):
    """问候函数"""
    return f"Hello, {name}!"

# 查看元数据
print(greet.__name__)    # "greet"（原函数名）
print(greet.__doc__)     # "问候函数"（原文档）
print(greet.__module__)  # "__main__"（原模块）
```

---

**@wraps 保留哪些属性？**

```python
from functools import wraps

def decorator(func):
    @wraps(func)  # 等价于：wrapper = update_wrapper(wrapper, func)
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

# @wraps 保留以下属性：
# - __name__       函数名
# - __doc__        文档字符串
# - __module__     模块名
# - __qualname__   限定名
# - __annotations__ 类型注解
# - __dict__       函数属性字典
```

---

**2. @lru_cache - LRU 缓存**

**基础用法**

```python
from functools import lru_cache

@lru_cache(maxsize=128)
#          ^^^^^^^^^^^^ 最多缓存 128 个结果
def fibonacci(n):
    """计算斐波那契数"""
    if n < 2:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# 第一次调用：计算
print(fibonacci(10))  # 55（需要计算）

# 第二次调用：从缓存读取
print(fibonacci(10))  # 55（直接从缓存返回）

# 查看缓存信息
print(fibonacci.cache_info())
# CacheInfo(hits=8, misses=11, maxsize=128, currsize=11)
```

---

**无限缓存**

```python
from functools import lru_cache

@lru_cache(maxsize=None)
#          ^^^^^^^^^^^^^ 无限缓存
def expensive_computation(x):
    print(f"计算 {x}")
    return x ** 2

print(expensive_computation(5))  # 计算 5
print(expensive_computation(5))  # 直接从缓存（不打印）
```

---

**Python 3.9+ 的 @cache**

```python
from functools import cache  # Python 3.9+

@cache  # 等价于 @lru_cache(maxsize=None)
def factorial(n):
    if n < 2:
        return 1
    return n * factorial(n-1)

print(factorial(10))  # 3628800
```

---

**手动清除缓存**

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_data(key):
    print(f"Fetching {key}")
    return f"Data for {key}"

print(get_data("user1"))  # Fetching user1
print(get_data("user1"))  # 从缓存（不打印）

# 清除所有缓存
get_data.cache_clear()

print(get_data("user1"))  # Fetching user1（重新获取）
```

---

**typed 参数（区分参数类型）**

```python
from functools import lru_cache

@lru_cache(maxsize=128, typed=False)
#                       ^^^^^^^^^^^^ 不区分类型（默认）
def add(a, b):
    print(f"计算 {a} + {b}")
    return a + b
  
add(1, 2)    # 计算 1 + 2
add(1.0, 2.0)  # 从缓存（因为 1 == 1.0）

# 使用 typed=True
@lru_cache(maxsize=128, typed=True)
#                       ^^^^^^^^^^^ 区分类型
def add_typed(a, b):
    print(f"计算 {a} + {b}")
    return a + b

add_typed(1, 2)    # 计算 1 + 2
add_typed(1.0, 2.0)  # 计算 1.0 + 2.0（因为类型不同）
```

---

**3. partial - 偏函数（固定参数）**

**基础用法**

```python
from functools import partial

def power(base, exponent):
    return base ** exponent

# 创建偏函数：固定 exponent=2
square = partial(power, exponent=2)
#                       ^^^^^^^^^^^ 固定参数

print(square(5))   # 25（相当于 power(5, exponent=2)）
print(square(10))  # 100

# 创建偏函数：固定 exponent=3
cube = partial(power, exponent=3)
print(cube(5))     # 125
```

---

**固定位置参数**

```python
from functools import partial

def greet(greeting, name):
    return f"{greeting}, {name}!"

# 固定第一个参数
say_hello = partial(greet, "Hello")
print(say_hello("Alice"))  # "Hello, Alice!"

say_hi = partial(greet, "Hi")
print(say_hi("Bob"))  # "Hi, Bob!"
```

---

**实际应用：回调函数**

```python
from functools import partial

def handle_button_click(button_id, event):
    print(f"按钮 {button_id} 被点击: {event}")

# 为不同按钮创建回调
button1_callback = partial(handle_button_click, "btn1")
button2_callback = partial(handle_button_click, "btn2")

# 模拟点击
button1_callback({"x": 10, "y": 20})  # 按钮 btn1 被点击
button2_callback({"x": 30, "y": 40})  # 按钮 btn2 被点击
```

---

**实际应用：多线程**

```python
from functools import partial
from concurrent.futures import ThreadPoolExecutor

def process_item(item, multiplier):
    return item * multiplier

items = [1, 2, 3, 4, 5]

# 创建偏函数：固定 multiplier=10
process_with_10 = partial(process_item, multiplier=10)

# 在线程池中使用
with ThreadPoolExecutor() as executor:
    results = executor.map(process_with_10, items)
    print(list(results))  # [10, 20, 30, 40, 50]
```

---

**4. reduce - 累积操作**

```python
from functools import reduce

# 计算列表总和
numbers = [1, 2, 3, 4, 5]
total = reduce(lambda x, y: x + y, numbers)
print(total)  # 15

# 等价于
total = 0
for num in numbers:
    total = total + num

# 计算列表乘积
product = reduce(lambda x, y: x * y, numbers)
print(product)  # 120

# 找最大值
numbers = [3, 7, 2, 9, 1]
maximum = reduce(lambda x, y: x if x > y else y, numbers)
print(maximum)  # 9

# 使用初始值
numbers = [1, 2, 3]
result = reduce(lambda x, y: x + y, numbers, 100)
#                                            ^^^ 初始值
print(result)  # 106（100 + 1 + 2 + 3）
```

---

**5. @total_ordering - 自动生成比较方法**

```python
from functools import total_ordering

@total_ordering
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age
    
    def __eq__(self, other):
        """只需实现 __eq__"""
        return self.age == other.age
    
    def __lt__(self, other):
        """只需实现 __lt__"""
        return self.age < other.age
    
    # @total_ordering 自动生成：
    # __le__, __gt__, __ge__

# 使用
alice = Person("Alice", 30)
bob = Person("Bob", 25)

print(alice > bob)   # True（自动生成）
print(alice >= bob)  # True（自动生成）
print(alice <= bob)  # False（自动生成）
```

---

**6. @singledispatch - 单分派泛型函数**

```python
from functools import singledispatch

@singledispatch
def process(data):
    """默认处理函数"""
    raise NotImplementedError(f"Cannot process type {type(data)}")

@process.register(int)
def _(data):
    """处理整数"""
    return f"整数: {data * 2}"

@process.register(str)
def _(data):
    """处理字符串"""
    return f"字符串: {data.upper()}"

@process.register(list)
def _(data):
    """处理列表"""
    return f"列表长度: {len(data)}"

# 使用（根据参数类型自动分派）
print(process(10))           # "整数: 20"
print(process("hello"))      # "字符串: HELLO"
print(process([1, 2, 3]))    # "列表长度: 3"
```

---

**7. cached_property - 缓存属性**

```python
from functools import cached_property

class DataLoader:
    def __init__(self, filename):
        self.filename = filename
    
    @cached_property
    def data(self):
        """加载数据（只加载一次）"""
        print(f"加载 {self.filename}...")
        with open(self.filename) as f:
            return f.read()

# 使用
loader = DataLoader("data.txt")

# 第一次访问：加载数据
print(loader.data)  # "加载 data.txt..."

# 第二次访问：从缓存读取（不打印）
print(loader.data)  # 直接返回缓存的数据
```

---

**常见陷阱和注意事项**

**陷阱 1：忘记使用 @wraps**

```python
# ❌ 问题：丢失元数据
def decorator(func):
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

@decorator
def my_func():
    """我的函数"""
    pass

print(my_func.__name__)  # "wrapper" ❌
print(my_func.__doc__)   # None ❌

# ✅ 解决：使用 @wraps
from functools import wraps

def decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper
```

---

**陷阱 2：@lru_cache 用于可变参数**

```python
from functools import lru_cache

# ❌ 错误：列表不可哈希
@lru_cache
def process(items):  # items 是列表
    return sum(items)

process([1, 2, 3])  # TypeError: unhashable type: 'list'

# ✅ 解决：转换为元组
@lru_cache
def process(items: tuple):  # 使用元组
    return sum(items)

process((1, 2, 3))  # ✅ 正常工作
```

---

**陷阱 3：@lru_cache 导致内存泄漏**

```python
from functools import lru_cache

@lru_cache(maxsize=None)  # ❌ 无限缓存
def process(obj):
    return obj.data

# 对象永远不会被垃圾回收（缓存持有引用）

# ✅ 解决：限制缓存大小
@lru_cache(maxsize=128)
def process(obj):
    return obj.data

# 或定期清除缓存
process.cache_clear()
```

---

**陷阱 4：partial 与关键字参数冲突**

```python
from functools import partial

def func(a, b, c=3):
    print(f"a={a}, b={b}, c={c}")

# 固定 c=10
partial_func = partial(func, c=10)

# ❌ 冲突
partial_func(1, 2, c=20)  # TypeError: multiple values for keyword argument 'c'

# ✅ 正确
partial_func(1, 2)  # a=1, b=2, c=10
```

---

**陷阱 5：@wraps 用于类方法**

```python
from functools import wraps

def decorator(func):
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        #        ^^^^ 不要忘记 self
        return func(self, *args, **kwargs)
    return wrapper

class MyClass:
    @decorator
    def method(self):
        """类方法"""
        pass
```

---

#### **总结：functools 模块核心要点**

**必须掌握**

| 函数         | 作用           | 何时使用           |
| ------------ | -------------- | ------------------ |
| `@wraps`     | 保留函数元数据 | 编写装饰器（必备） |
| `@lru_cache` | LRU 缓存       | 缓存昂贵计算       |
| `partial`    | 固定参数       | 创建专用函数       |
| `reduce`     | 累积操作       | 聚合计算           |

**使用场景**

| 场景             | 工具                   |
| ---------------- | ---------------------- |
| 编写装饰器       | `@wraps`               |
| 缓存函数结果     | `@lru_cache`, `@cache` |
| 固定函数参数     | `partial`              |
| 累积计算         | `reduce`               |
| 自动生成比较方法 | `@total_ordering`      |
| 函数重载         | `@singledispatch`      |

**最佳实践**

1. **总是使用 @wraps** - 编写装饰器时
2. **限制缓存大小** - 避免内存泄漏
3. **只缓存纯函数** - 相同输入总是返回相同输出
4. **定期清除缓存** - 长期运行的应用
5. **使用 partial 简化回调** - 多线程、事件处理

### 13.`itertools` - 迭代工具

**什么是 itertools？**

- Python 标准库，用于**高效迭代**和**组合操作**
- 提供大量用于创建和操作迭代器的函数
- 内存高效（惰性求值，不立即生成所有结果）
- 标准库，无需安装

**为什么用 itertools？**

```python
import itertools

# 1. 无限迭代器
counter = itertools.count(start=1, step=1)
print(next(counter))  # 1
print(next(counter))  # 2
print(next(counter))  # 3

# 2. 组合迭代器
# 排列组合（内存高效）
for combo in itertools.combinations([1, 2, 3], 2):
    print(combo)  # (1, 2), (1, 3), (2, 3)

# 3. 链接迭代器
list1 = [1, 2, 3]
list2 = [4, 5, 6]
combined = itertools.chain(list1, list2)
print(list(combined))  # [1, 2, 3, 4, 5, 6]

# 优势：
# 1. 内存高效（不创建中间列表）
# 2. 惰性求值（按需生成）
# 3. 可处理无限序列
```

---

#### **核心功能速查表**

**无限迭代器**

| 函数                 | 作用     | 示例                              |
| -------------------- | -------- | --------------------------------- |
| `count(start, step)` | 无限计数 | `count(10, 2)` → 10, 12, 14...    |
| `cycle(iterable)`    | 无限循环 | `cycle([1,2,3])` → 1,2,3,1,2,3... |
| `repeat(obj, times)` | 重复对象 | `repeat('A', 3)` → A, A, A        |

**终止迭代器**

| 函数                        | 作用              | 示例                                          |
| --------------------------- | ----------------- | --------------------------------------------- |
| `chain(*iterables)`         | 链接多个迭代器    | `chain([1,2], [3,4])` → 1,2,3,4               |
| `islice(it, stop)`          | 切片              | `islice(range(10), 5)` → 0,1,2,3,4            |
| `takewhile(pred, it)`       | 满足条件时取值    | `takewhile(lambda x: x<5, [1,4,6,2])` → 1,4   |
| `dropwhile(pred, it)`       | 跳过满足条件的值  | `dropwhile(lambda x: x<5, [1,4,6,2])` → 6,2   |
| `filterfalse(pred, it)`     | 过滤为 False 的值 | `filterfalse(lambda x: x%2, [1,2,3,4])` → 2,4 |
| `compress(data, selectors)` | 根据选择器过滤    | `compress('ABCD', [1,0,1,0])` → A,C           |

**组合迭代器**

| 函数                            | 作用         | 示例                                                         |
| ------------------------------- | ------------ | ------------------------------------------------------------ |
| `product(*iterables)`           | 笛卡尔积     | `product([1,2], ['a','b'])` → (1,'a'),(1,'b'),(2,'a'),(2,'b') |
| `permutations(it, r)`           | 排列（有序） | `permutations([1,2,3], 2)` → (1,2),(1,3),(2,1),(2,3),(3,1),(3,2) |
| `combinations(it, r)`           | 组合（无序） | `combinations([1,2,3], 2)` → (1,2),(1,3),(2,3)               |
| `combinations_with_replacement` | 可重复组合   | `combinations_with_replacement([1,2], 2)` → (1,1),(1,2),(2,2) |

**分组迭代器**

| 函数                      | 作用               | 示例                                                         |
| ------------------------- | ------------------ | ------------------------------------------------------------ |
| `groupby(iterable, key)`  | 分组               | `groupby('AAABBBCC')` → ('A',[A,A,A]),('B',[B,B,B]),('C',[C,C]) |
| `zip_longest(*iterables)` | 拉链（填充短序列） | `zip_longest([1,2], ['a'], fillvalue='-')` → (1,'a'),(2,'-') |

---

#### **详细功能讲解**

**1. 无限迭代器**

**count() - 无限计数器**

```python
import itertools

# 基础用法 
counter = itertools.count(start=1, step=1)
print(next(counter))  # 1
print(next(counter))  # 2
print(next(counter))  # 3

# 自定义起始值和步长
counter = itertools.count(start=10, step=2)
print(next(counter))  # 10
print(next(counter))  # 12
print(next(counter))  # 14

# 浮点数计数
counter = itertools.count(start=0.5, step=0.1)
print(next(counter))  # 0.5
print(next(counter))  # 0.6

# 实际应用：自动编号
tasks = ['任务A', '任务B', '任务C']
for task_id, task in zip(itertools.count(1), tasks):
    print(f"{task_id}. {task}")
# 1. 任务A
# 2. 任务B
# 3. 任务C

# 等价于 enumerate，但更灵活
for task_id, task in enumerate(tasks, start=1):
    print(f"{task_id}. {task}")
```

---

**cycle() - 无限循环**

```python
import itertools

# 基础用法
cycler = itertools.cycle([1, 2, 3])
print(next(cycler))  # 1
print(next(cycler))  # 2
print(next(cycler))  # 3
print(next(cycler))  # 1（循环）
print(next(cycler))  # 2

# 实际应用：轮询
colors = itertools.cycle(['red', 'green', 'blue'])
items = ['Item 1', 'Item 2', 'Item 3', 'Item 4', 'Item 5']

for item, color in zip(items, colors):
    print(f"{item}: {color}")
# Item 1: red
# Item 2: green
# Item 3: blue
# Item 4: red
# Item 5: green

# 实际应用：负载均衡
servers = itertools.cycle(['server1', 'server2', 'server3'])
requests = ['req1', 'req2', 'req3', 'req4', 'req5']

for request, server in zip(requests, servers):
    print(f"{request} → {server}")
```

---

**repeat() - 重复对象**

```python
import itertools

# 基础用法
repeater = itertools.repeat('A', times=3)
print(list(repeater))  # ['A', 'A', 'A']

# 无限重复
repeater = itertools.repeat('X')
print(next(repeater))  # 'X'
print(next(repeater))  # 'X'

# 实际应用：与 map 配合
def power(base, exponent):
    return base ** exponent

bases = [2, 3, 4, 5]
result = list(map(power, bases, itertools.repeat(2)))
#                                 ^^^^^^^^^^^^^^^^^^^ 所有元素都用 2 作为指数
print(result)  # [4, 9, 16, 25]

# 实际应用：填充默认值
keys = ['a', 'b', 'c']
default_value = 0
result = dict(zip(keys, itertools.repeat(default_value)))
print(result)  # {'a': 0, 'b': 0, 'c': 0}
```

---

**2. 终止迭代器**

**chain() - 链接迭代器**

```python
import itertools

# 基础用法
result = itertools.chain([1, 2, 3], [4, 5, 6])
print(list(result))  # [1, 2, 3, 4, 5, 6]

# 链接多个迭代器
result = itertools.chain([1, 2], ['a', 'b'], [True, False])
print(list(result))  # [1, 2, 'a', 'b', True, False]

# chain.from_iterable - 展平嵌套列表
nested = [[1, 2], [3, 4], [5, 6]]
result = itertools.chain.from_iterable(nested)
print(list(result))  # [1, 2, 3, 4, 5, 6]

# 实际应用：合并多个数据源
users_db1 = [{'id': 1, 'name': 'Alice'}]
users_db2 = [{'id': 2, 'name': 'Bob'}]
users_db3 = [{'id': 3, 'name': 'Charlie'}]

all_users = itertools.chain(users_db1, users_db2, users_db3)
for user in all_users:
    print(user)

# 实际应用：展平 Block 的输出
block_outputs = [
    [('output1', 'value1'), ('output2', 'value2')],
    [('output3', 'value3')],
    [('output4', 'value4'), ('output5', 'value5')],
]
all_outputs = itertools.chain.from_iterable(block_outputs)
print(list(all_outputs))
```

---

**islice() - 迭代器切片**

```python
import itertools

# 基础用法
result = itertools.islice(range(10), 5)
#                         ^^^^^^^^  ^^^ 取前 5 个
print(list(result))  # [0, 1, 2, 3, 4]

# 指定起始和结束
result = itertools.islice(range(10), 2, 7)
#                                    ^  ^
#                                  start stop
print(list(result))  # [2, 3, 4, 5, 6]

# 指定步长
result = itertools.islice(range(10), 0, 10, 2)
#                                    ^  ^^  ^
#                                 start stop step
print(list(result))  # [0, 2, 4, 6, 8]

# 实际应用：分页
def paginate(items, page_size):
    """分页生成器"""
    iterator = iter(items)
    while True:
        page = list(itertools.islice(iterator, page_size))
        if not page:
            break
        yield page

items = range(1, 11)
for page_num, page in enumerate(paginate(items, 3), start=1):
    print(f"Page {page_num}: {page}")
# Page 1: [1, 2, 3]
# Page 2: [4, 5, 6]
# Page 3: [7, 8, 9]
# Page 4: [10]

# 实际应用：处理大文件（只读取前 N 行）
def read_first_n_lines(filename, n):
    with open(filename) as f:
        return list(itertools.islice(f, n))
```

---

**takewhile() 和 dropwhile()**

```python
import itertools

# takewhile - 满足条件时取值（直到遇到 False）
result = itertools.takewhile(lambda x: x < 5, [1, 4, 6, 4, 1])
#                                              ^^^^^^^^^^^^^^^^
#                                              取到 6 就停止（因为 6 >= 5）
print(list(result))  # [1, 4]（不会继续取后面的 4 和 1）

# dropwhile - 跳过满足条件的值（直到遇到 False）
result = itertools.dropwhile(lambda x: x < 5, [1, 4, 6, 4, 1])
#                                              ^^^^^^^^^^^^^^^^
#                                              跳过 1 和 4，从 6 开始
print(list(result))  # [6, 4, 1]

# 实际应用：跳过文件头部注释
def read_without_comments(lines):
    """跳过以 # 开头的注释行"""
    return itertools.dropwhile(lambda line: line.startswith('#'), lines)

lines = [
    '# 这是注释',
    '# 另一条注释',
    'data_line_1',
    'data_line_2',
]
print(list(read_without_comments(lines)))
# ['data_line_1', 'data_line_2']

# 实际应用：读取日志直到错误
def read_until_error(log_lines):
    """读取日志直到遇到 ERROR"""
    return itertools.takewhile(
        lambda line: 'ERROR' not in line,
        log_lines
    )
```

---

**filterfalse() - 过滤为 False 的值**

```python
import itertools

# filterfalse - 保留条件为 False 的元素
result = itertools.filterfalse(lambda x: x % 2, [1, 2, 3, 4, 5, 6])
#                                ^^^^^^^^^^^^^^^
#                                奇数返回 True，偶数返回 False
#                                filterfalse 保留 False（偶数）
print(list(result))  # [2, 4, 6]

# 等价于
result = filter(lambda x: not (x % 2), [1, 2, 3, 4, 5, 6])
print(list(result))  # [2, 4, 6]

# 实际应用：过滤无效数据
data = [
    {'id': 1, 'valid': True},
    {'id': 2, 'valid': False},
    {'id': 3, 'valid': True},
    {'id': 4, 'valid': False},
]

invalid_data = itertools.filterfalse(lambda x: x['valid'], data)
print(list(invalid_data))
# [{'id': 2, 'valid': False}, {'id': 4, 'valid': False}]
```

---

**compress() - 根据选择器过滤**

```python
import itertools

# 基础用法
data = ['A', 'B', 'C', 'D', 'E']
selectors = [1, 0, 1, 0, 1]
#           ↑  ↑  ↑  ↑  ↑
#           取 不 取 不 取

result = itertools.compress(data, selectors)
print(list(result))  # ['A', 'C', 'E']

# 实际应用：根据掩码选择数据
users = ['Alice', 'Bob', 'Charlie', 'David']
is_active = [True, False, True, False]

active_users = itertools.compress(users, is_active)
print(list(active_users))  # ['Alice', 'Charlie']

# 实际应用：Block 输出过滤
outputs = [
    ('output1', 'value1'),
    ('output2', 'value2'),
    ('output3', 'value3'),
]
enabled = [True, False, True]

filtered_outputs = itertools.compress(outputs, enabled)
print(list(filtered_outputs))
# [('output1', 'value1'), ('output3', 'value3')]
```

---

**3. 组合迭代器**

**product() - 笛卡尔积**

```python
import itertools

# 基础用法
result = itertools.product([1, 2], ['a', 'b'])
print(list(result))
# [(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]

# 多个序列
result = itertools.product([1, 2], ['a', 'b'], [True, False])
print(list(result))
# [(1, 'a', True), (1, 'a', False), (1, 'b', True), ...]

# repeat 参数（自身与自身的笛卡尔积）
result = itertools.product([1, 2], repeat=2)
#                                   ^^^^^^^^ 等价于 product([1, 2], [1, 2])
print(list(result))
# [(1, 1), (1, 2), (2, 1), (2, 2)]

# 实际应用：生成所有组合的测试用例
environments = ['dev', 'staging', 'prod']
browsers = ['chrome', 'firefox', 'safari']

test_cases = itertools.product(environments, browsers)
for env, browser in test_cases:
    print(f"测试环境: {env}, 浏览器: {browser}")

# 实际应用：生成所有可能的配置
block_types = ['INPUT', 'PROCESS', 'OUTPUT']
execution_modes = ['SYNC', 'ASYNC']

configs = itertools.product(block_types, execution_modes)
for block_type, mode in configs:
    print(f"Block类型: {block_type}, 执行模式: {mode}")
```

---

**permutations() - 排列（有序）**

```python
import itertools

# 基础用法
result = itertools.permutations([1, 2, 3])
print(list(result))
# [(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]

# 指定长度
result = itertools.permutations([1, 2, 3], 2)
print(list(result))
# [(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]

# 实际应用：生成所有可能的顺序
tasks = ['Task A', 'Task B', 'Task C']
for order in itertools.permutations(tasks, 2):
    print(f"执行顺序: {' -> '.join(order)}")
# 执行顺序: Task A -> Task B
# 执行顺序: Task A -> Task C
# 执行顺序: Task B -> Task A
# ...

# 实际应用：测试不同的 Block 执行顺序
blocks = ['Block1', 'Block2', 'Block3']
for execution_order in itertools.permutations(blocks):
    print(f"执行顺序: {execution_order}")
```

---

**combinations() - 组合（无序）**

```python
import itertools

# 基础用法
result = itertools.combinations([1, 2, 3], 2)
print(list(result))
# [(1, 2), (1, 3), (2, 3)]

# 与 permutations 的区别
perms = list(itertools.permutations([1, 2, 3], 2))
combos = list(itertools.combinations([1, 2, 3], 2))
print(f"排列数: {len(perms)}")  # 6（有序）
print(f"组合数: {len(combos)}")  # 3（无序）

# 实际应用：选择 N 个元素的所有方式
users = ['Alice', 'Bob', 'Charlie', 'David']
for team in itertools.combinations(users, 2):
    print(f"团队: {team}")
# 团队: ('Alice', 'Bob')
# 团队: ('Alice', 'Charlie')
# 团队: ('Alice', 'David')
# 团队: ('Bob', 'Charlie')
# 团队: ('Bob', 'David')
# 团队: ('Charlie', 'David')

# 实际应用：测试 Block 连接的所有可能
blocks = ['Block A', 'Block B', 'Block C']
for connection in itertools.combinations(blocks, 2):
    print(f"连接: {connection[0]} -> {connection[1]}")
```

---

**combinations_with_replacement() - 可重复组合**

```python
import itertools

# 基础用法
result = itertools.combinations_with_replacement([1, 2], 2)
print(list(result))
# [(1, 1), (1, 2), (2, 2)]

# 与 combinations 的区别
combos = list(itertools.combinations([1, 2], 2))
combos_rep = list(itertools.combinations_with_replacement([1, 2], 2))
print(f"不可重复组合: {combos}")      # [(1, 2)]
print(f"可重复组合: {combos_rep}")    # [(1, 1), (1, 2), (2, 2)]

# 实际应用：生成重复选择的组合
colors = ['red', 'blue']
for combo in itertools.combinations_with_replacement(colors, 3):
    print(combo)
# ('red', 'red', 'red')
# ('red', 'red', 'blue')
# ('red', 'blue', 'blue')
# ('blue', 'blue', 'blue')
```

---

**4. 分组迭代器**

**groupby() - 分组**

```python
import itertools

# 基础用法（需要先排序）
data = ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C']
for key, group in itertools.groupby(data):
    print(f"{key}: {list(group)}")
# A: ['A', 'A', 'A']
# B: ['B', 'B']
# C: ['C', 'C', 'C', 'C']

# 使用 key 函数
data = [
    {'name': 'Alice', 'age': 25},
    {'name': 'Bob', 'age': 25},
    {'name': 'Charlie', 'age': 30},
    {'name': 'David', 'age': 30},
]

# 按年龄分组（先排序）
data.sort(key=lambda x: x['age'])
for age, group in itertools.groupby(data, key=lambda x: x['age']):
    print(f"年龄 {age}: {list(group)}")
# 年龄 25: [{'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 25}]
# 年龄 30: [{'name': 'Charlie', 'age': 30}, {'name': 'David', 'age': 30}]

# ⚠️ 注意：groupby 只分组连续的相同元素
data = ['A', 'B', 'A', 'B']  # 没有排序
for key, group in itertools.groupby(data):
    print(f"{key}: {list(group)}")
# A: ['A']
# B: ['B']
# A: ['A']
# B: ['B']

# 实际应用：按状态分组 Block 执行结果
executions = [
    {'block': 'A', 'status': 'success'},
    {'block': 'B', 'status': 'success'},
    {'block': 'C', 'status': 'failed'},
    {'block': 'D', 'status': 'failed'},
]

executions.sort(key=lambda x: x['status'])
for status, group in itertools.groupby(executions, key=lambda x: x['status']):
    blocks = [e['block'] for e in group]
    print(f"{status}: {blocks}")
# failed: ['C', 'D']
# success: ['A', 'B']
```

---

**zip_longest() - 拉链（填充短序列）**

```python
import itertools

# 基础 zip（短的序列决定长度）
result = zip([1, 2, 3], ['a', 'b'])
print(list(result))  # [(1, 'a'), (2, 'b')]（丢失了 3）

# zip_longest（长的序列决定长度）
result = itertools.zip_longest([1, 2, 3], ['a', 'b'])
print(list(result))  # [(1, 'a'), (2, 'b'), (3, None)]

# 自定义填充值
result = itertools.zip_longest([1, 2, 3], ['a', 'b'], fillvalue='X')
print(list(result))  # [(1, 'a'), (2, 'b'), (3, 'X')]

# 实际应用：合并不等长的数据
inputs = ['input1', 'input2', 'input3']
outputs = ['output1', 'output2']

for inp, out in itertools.zip_longest(inputs, outputs, fillvalue='N/A'):
    print(f"{inp} -> {out}")
# input1 -> output1
# input2 -> output2
# input3 -> N/A
```

---

**实际应用场景**

**场景 1：批处理数据**

```python
import itertools

def batch_process(items, batch_size):
    """将数据分批处理"""
    iterator = iter(items)
    while True:
        batch = list(itertools.islice(iterator, batch_size))
        if not batch:
            break
        yield batch

# 使用
items = range(1, 11)
for batch in batch_process(items, 3):
    print(f"处理批次: {batch}")
# 处理批次: [1, 2, 3]
# 处理批次: [4, 5, 6]
# 处理批次: [7, 8, 9]
# 处理批次: [10]
```

---

**场景 2：窗口滑动**

```python
import itertools

def sliding_window(iterable, n):
    """滑动窗口"""
    iterators = itertools.tee(iterable, n)
    for i, it in enumerate(iterators):
        # 跳过前 i 个元素
        for _ in range(i):
            next(it, None)
    return zip(*iterators)

# 使用
data = [1, 2, 3, 4, 5]
for window in sliding_window(data, 3):
    print(window)
# (1, 2, 3)
# (2, 3, 4)
# (3, 4, 5)
```

---

**场景 3：Round-robin（轮询）**

> 轮询是一种基础且重要的调度算法，广泛应用于各种场景，核心思想是**负载均衡**和**公平性**。
>
> 1. **服务器负载均衡 (Load Balancing)**
>    - **场景**: 这是最经典的例子。当有大量用户请求时，一个负载均衡器会使用轮询策略，将请求依次分发给后端的多个服务器（服务器A -> 服务器B -> 服务器C -> 服务器A...）。
>    - **目的**: 确保没有单个服务器压力过大，实现请求的公平分配。
> 2. **操作系统 CPU 时间分配**
>    - **场景**: 你的电脑同时运行着多个程序（浏览器、IDE、音乐播放器）。操作系统会给每个程序分配一个极短的CPU“时间片”。
>    - **目的**: 通过在程序间快速轮询，制造出所有程序“同时”运行的假象，保证系统的响应性和公平性。
> 3. **数据处理与合并**
>    - **场景**: 正如你的代码所示，当你需要以一种公平的方式合并来自多个数据源（如多个日志文件、传感器数据流、API响应）的数据时，轮询非常有用。
>    - **目的**: 避免长时间只处理一个数据源而饿死（starve）其他数据源，确保数据被交错处理。
> 4. **资源池管理**
>    - **场景**: 在一个数据库连接池或线程池中，当有多个任务需要资源时，可以轮询地从池中分配可用的连接或线程。
>    - **目的**: 公平地响应任务请求，避免资源分配不均。

```python
import itertools

def roundrobin(*iterables):
    """Round-robin 轮询多个迭代器"""
    pending = len(iterables)
    nexts = itertools.cycle(iter(it).__next__ for it in iterables)
    while pending:
        try:
            for next_func in nexts:
                yield next_func()
        except StopIteration:
            pending -= 1
            nexts = itertools.cycle(itertools.islice(nexts, pending))

# 使用
list1 = [1, 2, 3]
list2 = ['a', 'b']
list3 = [10, 20, 30, 40]

result = list(roundrobin(list1, list2, list3))
print(result)
# [1, 'a', 10, 2, 'b', 20, 3, 30, 40]
```

---

**场景 4：展平嵌套结构**

```python
import itertools

def flatten(nested_list):
    """展平任意深度的嵌套列表"""
    for item in nested_list:
        if isinstance(item, list):
            yield from flatten(item)
        else:
            yield item

# 使用
nested = [1, [2, 3, [4, 5]], 6, [7, [8, 9]]]
result = list(flatten(nested))
print(result)  # [1, 2, 3, 4, 5, 6, 7, 8, 9]

# 或使用 chain.from_iterable（只能展平一层）
nested = [[1, 2], [3, 4], [5, 6]]
result = list(itertools.chain.from_iterable(nested))
print(result)  # [1, 2, 3, 4, 5, 6]
```

---

**常见陷阱和注意事项**

**陷阱 1：迭代器只能使用一次**

> **迭代器 (Iterator)**
>
> 1. **懒加载 (Lazy Evaluation)**：迭代器不会一次性把所有数据都加载到内存里。它只在你需要下一个数据时，才去计算或获取它。这使得处理非常大或无限的数据流成为可能。
>
> 2. **有状态 (Stateful)**：它始终记得自己“取到哪里了”。当你向它要下一个数据时，它会从当前位置继续，而不是从头开始。
>
> 3. **单向前进 (Forward-only)**：你只能不断地向它要“下一个”数据，不能后退，也不能回到开头。
>
> 4. 迭代器只维护一个指向当前位置的“指针”。每次你从迭代器中取出一个元素（调用 `__next__()`），这个指针就会向前移动，并且**它不会记录已经走过的路**。
>
>    当指针移动到数据流的末尾时，迭代器就“耗尽” (exhausted) 了。它内部没有机制可以“重置”或“倒带”这个指针。如果你再尝试向它要数据，它只能告诉你：“没有更多数据了”（通过抛出 `StopIteration` 异常）。

```python
import itertools

# ❌ 错误：迭代器用完就没了
result = itertools.chain([1, 2], [3, 4])
print(list(result))  # [1, 2, 3, 4]
print(list(result))  # []（迭代器已耗尽）

# ✅ 解决：重新创建或转换为列表
result = list(itertools.chain([1, 2], [3, 4]))
print(result)  # [1, 2, 3, 4]
print(result)  # [1, 2, 3, 4]（列表可以多次访问）
```

---

**陷阱 2：groupby 需要先排序**

```python
import itertools

# ❌ 错误：没有排序
data = ['A', 'B', 'A', 'B']
for key, group in itertools.groupby(data):
    print(f"{key}: {list(group)}")
# A: ['A']
# B: ['B']
# A: ['A']
# B: ['B']（分成了 4 组）

# ✅ 正确：先排序
data = ['A', 'B', 'A', 'B']
data.sort()
for key, group in itertools.groupby(data):
    print(f"{key}: {list(group)}")
# A: ['A', 'A']
# B: ['B', 'B']（分成了 2 组）
```

---

**陷阱 3：无限迭代器需要限制**

```python
import itertools

# ❌ 危险：无限循环
# for i in itertools.count():
#     print(i)  # 永远不会停止

# ✅ 正确：使用 zip 限制
for i, item in zip(itertools.count(), ['a', 'b', 'c']):
    print(f"{i}: {item}")
# 0: a
# 1: b
# 2: c

# ✅ 或使用 islice 限制
for i in itertools.islice(itertools.count(), 5):
    print(i)
# 0, 1, 2, 3, 4
```

---

**陷阱 4：product 组合数爆炸**

```python
import itertools

# ⚠️ 注意：组合数会非常大
lists = [[1, 2, 3]] * 10  # 10 个列表，每个 3 个元素
result = itertools.product(*lists)
# 总共 3^10 = 59,049 个组合

# ✅ 解决：限制或分批处理
result = itertools.islice(itertools.product(*lists), 100)
print(len(list(result)))  # 只取前 100 个
```

---

#### **总结：itertools 模块核心要点**

**必须掌握**

| 函数           | 作用       | 典型场景       |
| -------------- | ---------- | -------------- |
| `chain`        | 链接迭代器 | 合并多个数据源 |
| `islice`       | 切片       | 分页、限制数量 |
| `product`      | 笛卡尔积   | 生成所有组合   |
| `combinations` | 组合       | 选择子集       |
| `groupby`      | 分组       | 按属性分组     |

**性能优势**

```python
# 内存对比
# 方式 1：列表推导（占用大量内存）
result = [x * 2 for x in range(1000000)]  # 创建完整列表

# 方式 2：itertools（惰性求值）
result = (x * 2 for x in range(1000000))  # 按需生成
```

**最佳实践**

1. **用于大数据集** - 避免内存溢出
2. **惰性求值** - 按需生成，不提前计算
3. **组合生成** - 避免手写嵌套循环
4. **先排序再分组** - groupby 的要求
5. **注意无限迭代器** - 总是限制数量

---



| 函数             | 作用       | 示例                              |
| ---------------- | ---------- | --------------------------------- |
| `chain()`        | 链接迭代器 | `chain([1,2],[3,4])` → 1,2,3,4    |
| `islice()`       | 切片       | `islice(range(10),5)` → 0,1,2,3,4 |
| `product()`      | 笛卡尔积   | `product([1,2],['a','b'])`        |
| `combinations()` | 组合       | `combinations([1,2,3],2)`         |
| `groupby()`      | 分组       | `groupby('AAABBB')`               |

### 14.`uuid` - UUID 生成

**什么是 uuid？**

- Python 标准库，用于生成**唯一标识符**（UUID）
- UUID = Universally Unique Identifier（通用唯一标识符）
- 128 位数字，几乎不可能重复
- 标准库，无需安装

**为什么用 uuid？**

1. 全局唯一（不需要中央服务器协调）
2. 无需数据库自增

3. 分布式系统友好

4.  可预测性低（安全）

**UUID 格式：**
```
xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx
8位-4位-4位-4位-12位（共32个十六进制数字）

示例：550e8400-e29b-41d4-a716-446655440000
```

---

#### **UUID 版本速查表**

| 版本      | 生成方式       | 特点                 | 使用场景       |
| --------- | -------------- | -------------------- | -------------- |
| `uuid1()` | MAC地址+时间戳 | 可追踪、有序         | 需要时序的场景 |
| `uuid3()` | MD5哈希        | 可重现               | 基于名称的ID   |
| `uuid4()` | 随机数         | **最常用**、不可预测 | 通用唯一ID     |
| `uuid5()` | SHA-1哈希      | 可重现、更安全       | 基于名称的ID   |

**推荐：99% 情况使用 `uuid4()`**

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：生成连接 ID（追踪）**
>
> ```python
> # backend/util/retry.py
> from uuid import uuid4
> 
> def conn_retry(resource_name: str, action_name: str):
>     conn_id = str(uuid4())
>     #              ^^^^^^^ 生成唯一连接 ID
>     
>     def on_retry(retry_state):
>         prefix = f"[{resource_name}-{conn_id}]"
>         #                           ^^^^^^^^ 用于日志追踪
>         logger.info(f"{prefix} {action_name} started...")
> 
> # 使用场景：追踪同一连接的所有重试日志
> # 示例日志：
> # [Database-550e8400] Connect started...
> # [Database-550e8400] Connect retry attempt 1...
> # [Database-550e8400] Connect completed.
> ```
>
> #### **案例 2：生成临时文件名**
>
> ```python
> # backend/util/file.py
> import uuid
> 
> async def store_media_file(graph_exec_id: str, file: MediaFileType):
>     base_path = Path(f"/temp/exec_file/{graph_exec_id}")
>     
>     # 生成唯一文件名
>     unique_filename = f"{uuid.uuid4()}{extension}"
>     #                   ^^^^^^^^^^^^^ 避免文件名冲突
>     file_path = base_path / unique_filename
>     
>     # 保存文件
>     file_path.write_bytes(content)
>     return str(file_path)
> 
> # 生成的文件名示例：
> # 550e8400-e29b-41d4-a716-446655440000.jpg
> ```
>
> #### **案例 3：Graph 和 Node ID（数据库主键）**
>
> ```python
> # backend/data/graph.py
> import uuid
> 
> class Graph:
>     def create_new_graph(self, name: str, user_id: str):
>         # 使用 UUID 作为主键
>         graph_id = str(uuid.uuid4())
>         #               ^^^^^^^^^^^^
>         
>         # 存入数据库
>         graph = {
>             "id": graph_id,
>             "name": name,
>             "user_id": user_id,
>         }
>         db.insert(graph)
>         return graph_id
> 
> # 优势：
> # 1. 不需要数据库自增ID
> # 2. 分布式系统中不会冲突
> # 3. 可以在插入数据库前生成ID
> ```
>

#### **详细功能讲解**

**1. uuid4() - 最常用（随机）**

```python
import uuid

# 生成 UUID
id1 = uuid.uuid4()
print(id1)  # UUID对象: 550e8400-e29b-41d4-a716-446655440000

# 转为字符串
id_str = str(uuid.uuid4())
print(id_str)  # "550e8400-e29b-41d4-a716-446655440000"

# 生成多个（每次都不同）
for i in range(3):
    print(uuid.uuid4())
# 550e8400-e29b-41d4-a716-446655440000
# 7c9e6679-7425-40de-944b-e07fc1f90ae7
# 9fe2c4e9-3654-4c77-b00e-8fc3a2bcd0ed
```

**使用场景：**
- 数据库主键
- 文件名
- 会话ID
- 任务ID

---

**2. UUID 对象操作**

```python
import uuid

# 创建 UUID 对象
id1 = uuid.uuid4()

# 属性
print(id1.hex)       # 没有连字符: "550e8400e29b41d4a716446655440000"
print(id1.int)       # 整数形式: 113059749145936325402354257176981405696
print(id1.bytes)     # 字节形式: b'U\x0e\x84\x00...'
print(str(id1))      # 标准格式: "550e8400-e29b-41d4-a716-446655440000"

# 版本
print(id1.version)   # 4（uuid4生成）

# 比较
id2 = uuid.uuid4()
print(id1 == id2)    # False（几乎不可能相同）
print(id1 < id2)     # True/False（可排序）
```

---

**3. 从字符串创建 UUID**

```python
import uuid

# 从字符串创建
id_str = "550e8400-e29b-41d4-a716-446655440000"
id_obj = uuid.UUID(id_str)
print(id_obj)  # UUID('550e8400-e29b-41d4-a716-446655440000')

# 验证 UUID 格式
try:
    uuid.UUID("invalid-uuid-string")
except ValueError as e:
    print("无效的 UUID 格式")

# 实际应用：验证用户输入
def validate_uuid(uuid_string):
    try:
        uuid.UUID(uuid_string)
        return True
    except ValueError:
        return False

print(validate_uuid("550e8400-e29b-41d4-a716-446655440000"))  # True
print(validate_uuid("not-a-uuid"))  # False
```

---

**4. 其他 UUID 版本**

**uuid1() - 基于时间和MAC地址**

```python
import uuid

# 生成 UUID1
id1 = uuid.uuid1()
print(id1)  # e.g., "a8098c1a-f86e-11da-bd1a-00112444be1e"

# 问题：可能暴露MAC地址（安全隐患）
# 优势：包含时间戳，可排序
```

**uuid3() 和 uuid5() - 基于名称的哈希**

```python
import uuid

# uuid3（MD5）
namespace = uuid.NAMESPACE_DNS
name = "example.com"
id3 = uuid.uuid3(namespace, name)
print(id3)  # 固定结果（相同输入总是相同输出）

# uuid5（SHA-1，更安全）
id5 = uuid.uuid5(namespace, name)
print(id5)  # 固定结果

# 相同输入，相同输出
assert uuid.uuid5(namespace, "example.com") == uuid.uuid5(namespace, "example.com")

# 内置命名空间
print(uuid.NAMESPACE_DNS)   # DNS 命名空间
print(uuid.NAMESPACE_URL)   # URL 命名空间
print(uuid.NAMESPACE_OID)   # ISO OID 命名空间
print(uuid.NAMESPACE_X500)  # X.500 DN 命名空间
```

---

#### **实际应用场景**

**场景 1：数据库主键**

```python
import uuid
from datetime import datetime

class User:
    def __init__(self, name: str, email: str):
        self.id = str(uuid.uuid4())  # 主键
        self.name = name
        self.email = email
        self.created_at = datetime.now()

# 创建用户
user = User("Alice", "alice@example.com")
print(f"新用户ID: {user.id}")

# 优势：
# 1. 无需等待数据库返回自增ID
# 2. 分布式系统中不会冲突
# 3. ID在插入前就已知
```

---

**场景 2：文件上传**

```python
import uuid
from pathlib import Path

def save_uploaded_file(content: bytes, original_filename: str) -> str:
    """保存上传的文件，使用UUID防止文件名冲突"""
    
    # 提取扩展名
    ext = Path(original_filename).suffix
    
    # 生成唯一文件名
    unique_name = f"{uuid.uuid4()}{ext}"
    
    # 保存文件
    save_path = Path("uploads") / unique_name
    save_path.write_bytes(content)
    
    return unique_name

# 使用
filename = save_uploaded_file(b"file content", "photo.jpg")
print(filename)  # "550e8400-e29b-41d4-a716-446655440000.jpg"
```

---

**场景 3：分布式任务ID**

```python
import uuid

class TaskQueue:
    def submit_task(self, func, *args, **kwargs):
        """提交任务到队列"""
        task_id = str(uuid.uuid4())
        
        task = {
            "id": task_id,
            "function": func.__name__,
            "args": args,
            "kwargs": kwargs,
        }
        
        # 发送到队列
        queue.push(task)
        
        return task_id

# 使用
task_id = queue.submit_task(process_data, data={"key": "value"})
print(f"任务ID: {task_id}")

# 优势：多个服务器可以独立生成任务ID，不会冲突
```

---

**场景 4：会话管理**

```python
import uuid
from datetime import datetime, timedelta

class SessionManager:
    def __init__(self):
        self.sessions = {}
    
    def create_session(self, user_id: str) -> str:
        """创建新会话"""
        session_id = str(uuid.uuid4())
        
        self.sessions[session_id] = {
            "user_id": user_id,
            "created_at": datetime.now(),
            "expires_at": datetime.now() + timedelta(hours=24),
        }
        
        return session_id
    
    def validate_session(self, session_id: str) -> bool:
        """验证会话是否有效"""
        session = self.sessions.get(session_id)
        if not session:
            return False
        return datetime.now() < session["expires_at"]

# 使用
manager = SessionManager()
session_id = manager.create_session("user123")
print(f"会话ID: {session_id}")
```

---

**常见陷阱**

**陷阱 1：UUID 不是字符串**

```python
import uuid

# ❌ 错误：UUID 对象不能直接与字符串比较
id1 = uuid.uuid4()
if id1 == "550e8400-e29b-41d4-a716-446655440000":
    print("相等")  # 永远不会执行

# ✅ 正确：转为字符串
if str(id1) == "550e8400-e29b-41d4-a716-446655440000":
    print("相等")

# ✅ 或者转为 UUID 对象
if id1 == uuid.UUID("550e8400-e29b-41d4-a716-446655440000"):
    print("相等")
```

---

**陷阱 2：UUID 是随机的，不能用于排序**

```python
import uuid

# ❌ 不推荐：UUID4 是随机的，不反映时间顺序
ids = [uuid.uuid4() for _ in range(5)]
ids.sort()  # 排序结果没有意义

# ✅ 如果需要按创建时间排序，添加时间戳字段
records = [
    {"id": str(uuid.uuid4()), "created_at": datetime.now()},
    # ...
]
records.sort(key=lambda x: x["created_at"])
```

---

**陷阱 3：uuid1 暴露 MAC 地址**

```python
import uuid

# ⚠️ 安全问题：uuid1 包含 MAC 地址
id1 = uuid.uuid1()
print(id1.node)  # MAC 地址（十进制）

# ✅ 推荐：使用 uuid4（随机，无隐私问题）
id4 = uuid.uuid4()
```

---

#### **总结：uuid 模块核心要点**

**版本选择**

| 使用场景   | 推荐版本  | 原因             |
| ---------- | --------- | ---------------- |
| **通用ID** | `uuid4()` | 随机、安全、通用 |
| 需要时序   | `uuid1()` | 包含时间戳       |
| 基于名称   | `uuid5()` | 可重现、安全     |

**最佳实践**

1. **99% 使用 uuid4** - 最安全、最通用
2. **转为字符串存储** - 数据库和 API 中使用字符串
3. **验证输入** - 用 `uuid.UUID()` 验证格式
4. **不用于排序** - UUID4 是随机的
5. **避免 uuid1** - 有隐私风险

### 15.`base64` - 编码

**什么是 base64？**

- Python 标准库，用于**二进制数据编码**
- 将二进制数据转换为 ASCII 文本（可安全传输）
- 常用于 URL、Email、JSON 等文本协议
- 标准库，无需安装

**为什么用 base64？**

| 场景                | 为什么需要转换                               | 常用编码   |
| ------------------- | -------------------------------------------- | ---------- |
| **API (JSON/XML)**  | JSON/XML 只支持文本，二进制会破坏其结构。    | **Base64** |
| **Email 附件**      | 邮件协议基于文本，二进制控制字符会引起问题。 | **Base64** |
| **Data URLs (Web)** | 将数据嵌入到本身就是文本的 HTML/CSS 文件中。 | **Base64** |
| **文本数据库/配置** | 存储介质只接受合法的文本字符串。             | **Base64** |

**Base64 原理：** 将 3 个字节（24位）编码为 4 个可打印字符

---

#### **核心函数速查表**

| 函数                   | 作用             | 输入      | 输出                  |
| ---------------------- | ---------------- | --------- | --------------------- |
| `b64encode(data)`      | 标准编码         | bytes     | bytes（带=填充）      |
| `b64decode(data)`      | 标准解码         | bytes/str | bytes                 |
| `urlsafe_b64encode()`  | URL安全编码      | bytes     | bytes（+ → -, / → _） |
| `urlsafe_b64decode()`  | URL安全解码      | bytes/str | bytes                 |
| `standard_b64encode()` | 标准编码（别名） | bytes     | bytes                 |
| `standard_b64decode()` | 标准解码（别名） | bytes     | bytes                 |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：Data URI（文件转 Base64）**
>
> ```python
> # backend/util/file.py
> import base64
> from pathlib import Path
> 
> def _file_to_data_uri(path: Path) -> str:
>     """将文件转换为 Data URI（用于嵌入图片等）"""
>     mime_type = get_mime_type(str(path))
>     
>     # 读取文件并编码为 base64
>     b64 = base64.b64encode(path.read_bytes()).decode("utf-8")
>     #              ^^^^^^^^ 编码二进制数据
>     #                                        ^^^^^^^ 转为字符串
>     
>     # 生成 Data URI
>     return f"data:{mime_type};base64,{b64}"
> 
> # 示例输出：
> # "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
> 
> # 使用场景：在 HTML/CSS 中嵌入图片
> # <img src="data:image/png;base64,iVBORw0KGgo..." />
> ```
>
> ---
>
> #### **案例 2：解码 Data URI**
>
> ```python
> # backend/util/file.py
> import base64
> import re
> 
> # 解析 Data URI
> if file.startswith("data:"):
>     match = re.match(r"^data:([^;]+);base64,(.*)$", file, re.DOTALL)
>     #                      ^^^^^^          ^^^^
>     #                    MIME类型        base64数据
>     
>     if not match:
>         raise ValueError("Invalid data URI format")
>     
>     mime_type = match.group(1).strip().lower()
>     b64_content = match.group(2).strip()
>     
>     # 解码 base64 数据
>     content = base64.b64decode(b64_content)
>     #                ^^^^^^^^^ 解码回二进制
>     
>     # 保存文件
>     target_path.write_bytes(content)
> 
> # 示例输入：
> # "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
> # 
> # 输出：保存为图片文件
> ```
>
> ---
>
> #### **案例 3：HTTP Basic Authentication**
>
> ```python
> # backend/integrations/oauth/notion.py
> from base64 import b64encode
> 
> class NotionOAuthHandler:
>     async def exchange_code_for_tokens(self, code: str):
>         # 创建 Basic Auth 头
>         auth_str = b64encode(
>             f"{self.client_id}:{self.client_secret}".encode()
>         ).decode()
>         #   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>         #   格式：client_id:client_secret
>         
>         headers = {
>             "Authorization": f"Basic {auth_str}",
>             #                        ^^^^^^^^^^
>             #                 Base64编码的凭证
>         }
>         
>         response = await Requests().post(
>             self.token_url, 
>             json=request_body, 
>             headers=headers
>         )
> 
> # HTTP Basic Auth 格式：
> # Authorization: Basic Y2xpZW50X2lkOmNsaWVudF9zZWNyZXQ=
> #                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> #                      base64("client_id:client_secret")
> ```
>

#### **详细功能讲解**

**1. 基础编码与解码**

```python
import base64

# 编码字符串
text = "Hello, World!"
encoded = base64.b64encode(text.encode())
#                          ^^^^^^^^^^^^^^ 必须先转为 bytes
print(encoded)  # b'SGVsbG8sIFdvcmxkIQ=='

# 解码回字符串
decoded = base64.b64decode(encoded)
print(decoded.decode())  # "Hello, World!"
#            ^^^^^^^^ bytes 转回字符串

# 完整流程
text = "Python"
# 1. str → bytes
bytes_data = text.encode()  # b'Python'
# 2. bytes → base64
encoded = base64.b64encode(bytes_data)  # b'UHl0aG9u'
# 3. base64 → bytes
decoded_bytes = base64.b64decode(encoded)  # b'Python'
# 4. bytes → str
decoded_text = decoded_bytes.decode()  # 'Python'
```

---

**2. 编码二进制文件**

```python
import base64

# 读取图片文件
with open("image.png", "rb") as f:
    image_data = f.read()

# 编码为 base64
encoded_image = base64.b64encode(image_data)
print(encoded_image[:50])  # b'iVBORw0KGgoAAAANSUhEUgAA...'

# 保存编码后的数据
with open("image_base64.txt", "w") as f:
    f.write(encoded_image.decode())

# 从 base64 还原图片
with open("image_base64.txt", "r") as f:
    encoded_data = f.read()

decoded_image = base64.b64decode(encoded_data)

# 保存还原的图片
with open("image_restored.png", "wb") as f:
    f.write(decoded_image)
```

---

**3. Data URI（嵌入文件到 HTML/CSS）**

```python
import base64

def create_data_uri(file_path: str) -> str:
    """创建 Data URI"""
    with open(file_path, "rb") as f:
        data = f.read()
    
    # 编码为 base64
    b64_data = base64.b64encode(data).decode()
    
    # 生成 Data URI
    return f"data:image/png;base64,{b64_data}"

# 使用
data_uri = create_data_uri("logo.png")
print(data_uri[:50])
# "data:image/png;base64,iVBORw0KGgoAAAANSUhE..."

# 在 HTML 中使用
html = f'<img src="{data_uri}" alt="Logo">'

# 优势：
# 1. 减少 HTTP 请求
# 2. 便于传输（纯文本）
# 3. 可嵌入 JSON/CSS
```

---

**4. URL 安全的 Base64**

```python
import base64

# 标准 base64（包含 +, /, =）
text = "Hello, World!"
standard = base64.b64encode(text.encode())
print(standard)  # b'SGVsbG8sIFdvcmxkIQ=='

# URL 安全的 base64（替换特殊字符）
urlsafe = base64.urlsafe_b64encode(text.encode())
print(urlsafe)  # b'SGVsbG8sIFdvcmxkIQ=='

# 区别在于特殊字符
text = "subjects?_d"
standard = base64.b64encode(text.encode())
print(standard)  # b'c3ViamVjdHM/X2Q='（包含 /）

urlsafe = base64.urlsafe_b64encode(text.encode())
print(urlsafe)  # b'c3ViamVjdHM_X2Q='（/ → _）

# 对照表：
# 标准：+ / =
# URL安全：- _ =（可选去掉 =）
```

---

**5. 实际应用：JWT Token**

```python
import base64
import json

def create_simple_jwt(payload: dict) -> str:
    """简化版 JWT（仅演示 base64 用法）"""
    # Header
    header = {"alg": "none", "typ": "JWT"}
    
    # 编码 Header
    header_b64 = base64.urlsafe_b64encode(
        json.dumps(header).encode()
    ).decode().rstrip("=")
    
    # 编码 Payload
    payload_b64 = base64.urlsafe_b64encode(
        json.dumps(payload).encode()
    ).decode().rstrip("=")
    
    # 拼接（真实 JWT 还需签名）
    return f"{header_b64}.{payload_b64}.signature"

# 使用
token = create_simple_jwt({"user_id": "123", "role": "admin"})
print(token)
# "eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.eyJ1c2VyX2lkIjoiMTIzIiwicm9sZSI6ImFkbWluIn0.signature"
```

---

**6. HTTP Basic Authentication**

```python
import base64

def create_basic_auth_header(username: str, password: str) -> str:
    """创建 Basic Auth 头"""
    credentials = f"{username}:{password}"
    encoded = base64.b64encode(credentials.encode()).decode()
    return f"Basic {encoded}"

# 使用
auth_header = create_basic_auth_header("admin", "secret123")
print(auth_header)
# "Basic YWRtaW46c2VjcmV0MTIz"

# 在 HTTP 请求中使用
headers = {
    "Authorization": auth_header
}
response = requests.get("https://api.example.com", headers=headers)
```

---

#### **实际应用场景**

**场景 1：API 中传输图片**

```python
import base64
import json

def send_image_to_api(image_path: str):
    """通过 JSON API 发送图片"""
    # 读取图片
    with open(image_path, "rb") as f:
        image_data = f.read()
    
    # 编码为 base64
    image_b64 = base64.b64encode(image_data).decode()
    
    # 发送 JSON
    payload = {
        "filename": "photo.jpg",
        "content": image_b64,
        "mime_type": "image/jpeg"
    }
    
    response = requests.post(
        "https://api.example.com/upload",
        json=payload
    )
    return response.json()
```

---

**场景 2：邮件附件**

```python
import base64
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders

def create_email_with_attachment(file_path: str):
    """创建带附件的邮件"""
    msg = MIMEMultipart()
    msg['Subject'] = '带附件的邮件'
    
    # 添加正文
    msg.attach(MIMEText('请查看附件', 'plain'))
    
    # 添加附件
    with open(file_path, "rb") as f:
        part = MIMEBase('application', 'octet-stream')
        part.set_payload(f.read())
        encoders.encode_base64(part)  # Base64 编码
        part.add_header(
            'Content-Disposition',
            f'attachment; filename={file_path}'
        )
        msg.attach(part)
    
    return msg
```

---

**场景 3：加密敏感数据**

```python
import base64
import hashlib

def obfuscate_data(data: str) -> str:
    """简单混淆数据（非加密）"""
    # 注意：这不是真正的加密！
    # 只是为了让数据不可读
    
    # 转为 base64
    b64 = base64.b64encode(data.encode()).decode()
    
    # 反转字符串
    reversed_b64 = b64[::-1]
    
    return reversed_b64

def deobfuscate_data(obfuscated: str) -> str:
    """还原混淆的数据"""
    # 反转回来
    b64 = obfuscated[::-1]
    
    # 解码 base64
    data = base64.b64decode(b64).decode()
    
    return data

# 使用
original = "secret_password_123"
obfuscated = obfuscate_data(original)
print(f"混淆后: {obfuscated}")

restored = deobfuscate_data(obfuscated)
print(f"还原后: {restored}")
```

---

**常见陷阱**

**陷阱 1：忘记编码/解码字符串**

```python
import base64

# ❌ 错误：字符串不能直接编码
text = "Hello"
# encoded = base64.b64encode(text)  # TypeError

# ✅ 正确：先转为 bytes
encoded = base64.b64encode(text.encode())

# ❌ 错误：解码后还是 bytes
decoded = base64.b64decode(encoded)
# print(decoded + " World")  # TypeError

# ✅ 正确：转回字符串
print(decoded.decode() + " World")
```

---

**陷阱 2：Base64 不是加密**

```python
import base64

# ❌ 错误理解：Base64 ≠ 加密
password = "super_secret"
encoded = base64.b64encode(password.encode())
# 任何人都可以解码：
decoded = base64.b64decode(encoded)  # 轻松还原

# ✅ 正确：Base64 只是编码，需要配合真正的加密
from cryptography.fernet import Fernet
key = Fernet.generate_key()
cipher = Fernet(key)
encrypted = cipher.encrypt(password.encode())
```

---

**陷阱 3：文件大小膨胀**

```python
import base64

# Base64 会增加约 33% 的大小
original_size = 1000  # bytes
encoded_size = len(base64.b64encode(b"x" * original_size))
print(f"原始: {original_size}, 编码后: {encoded_size}")
# 原始: 1000, 编码后: 1336

# 计算：每 3 字节 → 4 字符
# 1000 / 3 * 4 = 1333.33
```

---

**陷阱 4：URL 中的特殊字符**

```python
import base64

data = "subject?"
# ❌ 标准 base64（在 URL 中有问题）
standard = base64.b64encode(data.encode())
print(standard)  # b'c3ViamVjdD8='

# URL: https://example.com?token=c3ViamVjdD8=
#                                           ^ = 是特殊字符

# ✅ 使用 URL 安全版本
urlsafe = base64.urlsafe_b64encode(data.encode())
print(urlsafe)  # b'c3ViamVjdD8='（相同，但替换了 + /）
```

---

#### **总结：base64 模块核心要点**

**核心函数**

| 函数                  | 用途        | 常见场景     |
| --------------------- | ----------- | ------------ |
| `b64encode()`         | 编码        | 通用编码     |
| `b64decode()`         | 解码        | 通用解码     |
| `urlsafe_b64encode()` | URL安全编码 | URL参数、JWT |
| `urlsafe_b64decode()` | URL安全解码 | 解析Token    |

**使用场景**

- ✅ Data URI（图片嵌入HTML）
- ✅ HTTP Basic Auth
- ✅ JWT Token
- ✅ Email附件
- ✅ JSON中传输二进制
- ❌ 不适合加密（容易解码）

**最佳实践**

1. **记住转换流程** - str→bytes→base64
2. **不用于加密** - 只是编码，不安全
3. **注意大小膨胀** - 增加约33%
4. **URL场景用urlsafe** - 避免特殊字符
5. **Data URI加MIME类型** - 完整格式

---

## **进阶掌握**
### 16.`asyncio` - 异步编程

**什么是 asyncio？**

- Python 标准库，用于**异步编程**
- 允许**并发执行**任务（非阻塞 I/O）
- 核心关键字：`async`、`await`
- 标准库，无需安装

**为什么用 asyncio？**

| 特性           | 解释                       | 在 AutoGPT 中的应用                                          |
| -------------- | -------------------------- | ------------------------------------------------------------ |
| **非阻塞 I/O** | 程序在等待时不会被卡住。   | 调用 LLM API、数据库查询、读写文件时，程序可以处理其他请求。 |
| **高并发**     | 用单线程处理大量并发任务。 | FastAPI 后端能同时服务大量用户和 Agent 的 API 请求。         |
| **高效率**     | CPU 时间不被浪费在等待上。 | Agent 执行复杂任务（涉及多次网络和磁盘I/O）的速度更快。      |
| **响应性**     | 系统能更快地响应新事件。   | 即使 Agent 在执行一个耗时很长的任务，UI 依然能得到及时的状态更新。 |

---

#### **核心概念速查表**

| 关键字/函数                                                  | 作用             | 示例                                                         |
| ------------------------------------------------------------ | ---------------- | ------------------------------------------------------------ |
| `async def`                                                  | 定义协程函数     | `async def fetch()`                                          |
| `await`                                                      | 等待异步操作     | `await fetch()`                                              |
| [asyncio.run()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:439:4-461:84) | 运行异步函数     | [asyncio.run(main())](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/block.py:439:4-461:84) |
| `asyncio.gather()`                                           | 并发执行多个任务 | `await gather(task1, task2)`                                 |
| `asyncio.create_task()`                                      | 创建任务         | `task = create_task(coro)`                                   |
| `asyncio.sleep()`                                            | 异步睡眠         | `await sleep(1)`                                             |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### 案例 1：Block.run() - 核心异步方法**
>
> ```python
> # backend/data/block.py
> from abc import abstractmethod
> 
> class Block(ABC):
>     @abstractmethod
>     async def run(self, input_data: BlockSchemaInputType, **kwargs) -> BlockOutput:
>         """
>         所有 Block 的核心方法 - 必须是异步的！
>         
>         为什么是 async？
>         1. Block 可能需要调用 API（网络 I/O）
>         2. Block 可能需要读写数据库（I/O）
>         3. 允许多个 Block 并发执行
>         """
>         yield "output_name", "output_data"
> 
> # 实现示例
> class FileStoreBlock(Block):
>     async def run(self, input_data: Input, **kwargs) -> BlockOutput:
>         # await 调用其他异步函数
>         result = await store_media_file(
>             graph_exec_id=input_data.graph_exec_id,
>             file=input_data.file_in,
>         )
>         yield "file_out", result
>         #^^^^^ 异步生成器（async generator）
> ```
>
> ---
>
> #### **案例 2：并发病毒扫描**
>
> ```python
> # backend/util/virus_scanner.py
> import asyncio
> 
> class VirusScannerService:
>     async def scan_file(self, content: bytes) -> VirusScanResult:
>         """异步扫描文件（分块并发）"""
>         chunk_size = 1024 * 1024  # 1MB
>         
>         # 创建多个扫描任务
>         tasks = [
>             asyncio.create_task(self._instream(content[o:o+chunk_size]))
>             #       ^^^^^^^^^^^ 创建任务
>             for o in range(0, len(content), chunk_size)
>         ]
>         
>         # 并发等待所有任务
>         for coro in asyncio.as_completed(tasks):
>             #          ^^^^^^^^^^^^^^^^^^ 按完成顺序获取结果
>             infected, threat = await coro
>             if infected:
>                 # 发现病毒，取消其他任务
>                 for t in tasks:
>                     if not t.done():
>                         t.cancel()
>                 return VirusScanResult(is_clean=False, threat_name=threat)
>         
>         return VirusScanResult(is_clean=True)
> 
> # 优势：
> # 1. 多个块并发扫描（快）
> # 2. 一旦发现病毒立即取消其他扫描（省资源）
> # 3. 非阻塞（不占用 CPU）
> ```
>
> ---
>
> #### **案例 3：并发测试**
>
> ```python
> # backend/util/virus_scanner_test.py
> import asyncio
> import pytest
> 
> @pytest.mark.asyncio
> #^^^^^^^^^^^^^^^ 标记为异步测试
> async def test_concurrent_scans(scanner):
>     """测试并发扫描"""
>     content1 = b"file1 content"
>     content2 = b"file2 content"
>     
>     # 并发执行两个扫描
>     results = await asyncio.gather(
>         #            ^^^^^^^^^^^^^ 等待所有任务完成
>         scanner.scan_file(content1, filename="file1.txt"),
>         scanner.scan_file(content2, filename="file2.txt"),
>     )
>     
>     # 两个扫描同时进行，总时间约为单个扫描的时间
>     assert len(results) == 2
>     assert all(r.is_clean for r in results)
> ```
>

#### **核心概念详解**

**1. async/await 基础**

```python
import asyncio

# 定义异步函数
async def fetch_data():
    """async def 定义协程函数"""
    print("开始获取数据...")
    await asyncio.sleep(1)  # 模拟网络请求
    #^^^^ await 等待异步操作
    print("数据获取完成")
    return "data"

# 运行异步函数
result = asyncio.run(fetch_data())
#        ^^^^^^^^^^^ 运行协程
print(result)  # "data"

# ❌ 错误：不能直接调用
# result = fetch_data()  # 返回协程对象，不是结果
```

---

**2. 并发执行多个任务**

```python
import asyncio

async def task1():
    await asyncio.sleep(2)
    return "Task 1 完成"

async def task2():
    await asyncio.sleep(1)
    return "Task 2 完成"

async def task3():
    await asyncio.sleep(1.5)
    return "Task 3 完成"

# 方法 1：asyncio.gather（推荐）
async def main():
    results = await asyncio.gather(task1(), task2(), task3())
    #               ^^^^^^^^^^^^^ 并发执行
    print(results)
    # ['Task 1 完成', 'Task 2 完成', 'Task 3 完成']
    # 总时间：2 秒（不是 2+1+1.5=4.5秒）

asyncio.run(main())

# 方法 2：create_task
async def main2():
    t1 = asyncio.create_task(task1())
    t2 = asyncio.create_task(task2())
    t3 = asyncio.create_task(task3())
    
    result1 = await t1
    result2 = await t2
    result3 = await t3
    print([result1, result2, result3])
```

---

**3. 异步生成器（Block 使用）**

```python
import asyncio

# 同步生成器
def sync_generator():
    yield 1
    yield 2
    yield 3

# 异步生成器
async def async_generator():
    yield 1
    await asyncio.sleep(0.1)
    yield 2
    await asyncio.sleep(0.1)
    yield 3

# 使用
async def main():
    async for value in async_generator():
        #^^^^^ async for 遍历异步生成器
        print(value)

asyncio.run(main())

# Block 中的应用
class MyBlock(Block):
    async def run(self, input_data: Input) -> BlockOutput:
        # 执行异步操作
        result1 = await api_call_1()
        yield "output1", result1
        
        result2 = await api_call_2()
        yield "output2", result2
        
        # 可以在生成过程中进行异步操作
```

---

**4. 超时控制**

```python
import asyncio

async def slow_operation():
    await asyncio.sleep(10)
    return "完成"

async def main():
    try:
        # 超时 2 秒
        result = await asyncio.wait_for(slow_operation(), timeout=2.0)
        #              ^^^^^^^^^^^^^^^^ 超时控制
        print(result)
    except asyncio.TimeoutError:
        print("操作超时！")

asyncio.run(main())
```

---

**5. 错误处理**

```python
import asyncio

async def risky_task(n):
    await asyncio.sleep(1)
    if n == 2:
        raise ValueError(f"任务 {n} 出错")
    return f"任务 {n} 成功"

async def main():
    # gather 默认：一个失败全部失败
    try:
        results = await asyncio.gather(
            risky_task(1),
            risky_task(2),  # 这个会失败
            risky_task(3),
        )
    except ValueError as e:
        print(f"捕获异常: {e}")
    
    # return_exceptions=True：返回异常而不是抛出
    results = await asyncio.gather(
        risky_task(1),
        risky_task(2),
        risky_task(3),
        return_exceptions=True
        #^^^^^^^^^^^^^^^^^ 异常作为结果返回
    )
    print(results)
    # ['任务 1 成功', ValueError('任务 2 出错'), '任务 3 成功']

asyncio.run(main())
```

---

#### **实际应用场景**

**场景 1：并发 API 调用**

```python
import asyncio
import aiohttp  # 异步 HTTP 库

async def fetch_url(session, url):
    """异步获取 URL"""
    async with session.get(url) as response:
        return await response.text()

async def fetch_multiple_urls(urls):
    """并发获取多个 URL"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        return results

# 使用
urls = [
    "https://api.example.com/data1",
    "https://api.example.com/data2",
    "https://api.example.com/data3",
]
results = asyncio.run(fetch_multiple_urls(urls))
# 3 个请求并发执行，总时间约为单个请求的时间
```

---

**场景 2：数据库批量操作**

```python
import asyncio

async def save_to_db(record):
    """异步保存到数据库"""
    await asyncio.sleep(0.1)  # 模拟数据库操作
    return f"保存 {record['id']}"

async def batch_save(records):
    """批量保存"""
    tasks = [save_to_db(record) for record in records]
    results = await asyncio.gather(*tasks)
    return results

# 使用
records = [{"id": i, "data": f"data{i}"} for i in range(10)]
results = asyncio.run(batch_save(records))
# 10 个记录并发保存
```

---

**场景 3：生产者-消费者模式**

```python
import asyncio
import random

async def producer(queue, n):
    """生产者"""
    for i in range(n):
        item = f"item-{i}"
        await queue.put(item)
        print(f"生产: {item}")
        await asyncio.sleep(random.random())
    await queue.put(None)  # 结束信号

async def consumer(queue):
    """消费者"""
    while True:
        item = await queue.get()
        if item is None:
            break
        print(f"  消费: {item}")
        await asyncio.sleep(random.random())
        queue.task_done()

async def main():
    queue = asyncio.Queue()
    
    # 并发运行生产者和消费者
    await asyncio.gather(
        producer(queue, 5),
        consumer(queue),
    )

asyncio.run(main())
```

---

**常见陷阱**

**陷阱 1：忘记 await**

```python
import asyncio

async def fetch_data():
    await asyncio.sleep(1)
    return "data"

async def main():
    # ❌ 错误：忘记 await
    result = fetch_data()  # 返回协程对象
    print(result)  # <coroutine object fetch_data at 0x...>
    
    # ✅ 正确：使用 await
    result = await fetch_data()
    print(result)  # "data"

asyncio.run(main())
```

---

**陷阱 2：在同步函数中调用异步函数**

```python
import asyncio

async def async_func():
    return "result"

# ❌ 错误：同步函数不能直接调用异步函数
def sync_func():
    result = await async_func()  # SyntaxError!
    
# ✅ 正确：使用 asyncio.run
def sync_func():
    result = asyncio.run(async_func())
    return result
```

---

**陷阱 3：阻塞操作**

```python
import asyncio
import time

async def bad_async():
    # ❌ 错误：time.sleep 是阻塞的
    time.sleep(1)  # 阻塞整个事件循环
    return "done"

async def good_async():
    # ✅ 正确：使用 asyncio.sleep
    await asyncio.sleep(1)  # 非阻塞
    return "done"

# bad_async 会阻塞其他协程
# good_async 允许其他协程运行
```

---

**陷阱 4：混用 CPU 密集型任务**

```python
import asyncio

def cpu_intensive():
    """CPU 密集型任务（不适合异步）"""
    return sum(i**2 for i in range(10_000_000))

async def main():
    # ❌ 这不会并发执行（GIL）
    await asyncio.gather(
        asyncio.to_thread(cpu_intensive),  # 需要用线程
        asyncio.to_thread(cpu_intensive),
    )

# ✅ 对于 CPU 密集型，使用 multiprocessing
from concurrent.futures import ProcessPoolExecutor

async def main():
    loop = asyncio.get_event_loop()
    with ProcessPoolExecutor() as pool:
        results = await asyncio.gather(
            loop.run_in_executor(pool, cpu_intensive),
            loop.run_in_executor(pool, cpu_intensive),
        )
```

---

#### **总结**：asyncio模块核心要点

**核心概念**

| 概念                    | 说明                 |
| ----------------------- | -------------------- |
| `async def`             | 定义异步函数（协程） |
| `await`                 | 等待异步操作完成     |
| `asyncio.gather()`      | 并发执行多个协程     |
| `asyncio.create_task()` | 创建任务             |
| `async for`             | 遍历异步生成器       |

**何时使用异步**

- ✅ 网络请求（HTTP/API调用）
- ✅ 数据库查询
- ✅ 文件 I/O
- ✅ 等待外部事件
- ❌ CPU 密集型计算

**最佳实践**

1. **I/O 密集型用异步** - 网络、数据库
2. **总是 await** - 不要忘记 await
3. **用 gather 并发** - 同时执行多个任务
4. **避免阻塞操作** - 用 asyncio.sleep 而非 time.sleep
5. **适当的超时** - 用 wait_for 防止卡死

### 17.`threading` - 多线程

**什么是 threading？**

- Python 标准库，用于**多线程编程**
- 允许程序并发执行多个任务
- 适合 **I/O 密集型**任务（但受 GIL 限制）
- 标准库，无需安装

> **`asyncio`** VS **`threading`**
>
> | 特性           | `asyncio` (异步 I/O)                                         | `threading` (多线程)                                         |
> | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | **核心模型**   | **协作式**：任务通过 `await` 关键字**主动**放弃控制权，让其他任务运行。 | **抢占式**：操作系统**强制**暂停一个线程，切换到另一个线程，开发者无法精确控制切换时机。 |
> | **线程数量**   | **单线程**。所有异步任务都在同一个线程内的事件循环 (Event Loop) 中调度。 | **多线程**。每个线程都是一个独立的操作系统级执行单元。       |
> | **适用场景**   | **I/O 密集型 (I/O-Bound)**。如网络请求、数据库读写、文件操作。在等待时可以切换任务，效率极高。 | **I/O 密集型**。在等待 I/O 时，操作系统会切换到其他线程。但对于 CPU 密集型任务，受 GIL 限制。 |
> | **CPU 密集型** | **表现很差**。因为只有一个线程，一个需要大量计算的任务会“霸占”事件循环，阻塞所有其他任务。 | **表现很差 (在 Python 中)**。因为 **GIL (全局解释器锁)** 的存在，同一时间只有一个线程能执行 Python 字节码，无法实现真正的并行计算。 |
> | **切换控制**   | **明确可控**。代码在 `await` 处暂停，逻辑清晰。              | **不可预测**。由操作系统调度，可能在任何一行代码之间切换，容易产生竞态条件。 |
> | **资源消耗**   | **非常低**。成千上万个异步任务只消耗一个线程的资源。         | **较高**。每个线程都有自己的内存堆栈，创建大量线程会消耗大量内存。 |
> | **编程复杂性** | 需要使用 `async`/`await` 语法，具有“传染性”（异步函数调用的也必须是异步函数）。调试调用栈可能更复杂。 | 概念上更传统，但需要手动处理线程同步问题（如锁、信号量），极易出现**死锁**和**竞态条件**。 |

---

#### **核心概念速查表**

| 类/函数               | 作用         | 示例                                                         |
| --------------------- | ------------ | ------------------------------------------------------------ |
| `Thread(target=func)` | 创建线程     | `t = Thread(target=work)`                                    |
| `t.start()`           | 启动线程     | `t.start()`                                                  |
| `t.join()`            | 等待线程结束 | `t.join()`                                                   |
| `Lock()`              | 互斥锁       | `lock.acquire()` / `lock.release()`                          |
| `RLock()`             | 可重入锁     | 同一线程可多次获取                                           |
| `Event()`             | 事件通知     | `event.set()` / `event.wait()`                               |
| `Queue`               | 线程安全队列 | [q.put()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/util/request.py:496:4-497:62) / [q.get()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/util/request.py:490:4-491:62) |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：线程锁保护共享资源**
>
> ```python
> # backend/util/retry.py
> import threading
> 
> # 全局共享资源
> _alert_rate_limiter = {}
> _rate_limiter_lock = threading.Lock()
> #                    ^^^^^^^^^^^^^^^ 创建锁
> 
> def should_send_alert(func_name: str, exception: Exception) -> bool:
>     """检查是否应该发送警告（线程安全）"""
>     error_signature = f"{func_name}:{type(exception).__name__}"
>     current_time = time.time()
>     
>     # 使用锁保护共享字典
>     with _rate_limiter_lock:
>         #^^^ 自动获取和释放锁
>         last_alert_time = _alert_rate_limiter.get(error_signature, 0)
>         if current_time - last_alert_time >= 300:
>             _alert_rate_limiter[error_signature] = current_time
>             return True
>         return False
> 
> # 为什么需要锁？
> # 多个线程可能同时访问 _alert_rate_limiter
> # 没有锁会导致竞态条件（race condition）
> ```
>
> ---
>
> #### **案例 2：后台线程处理消息**
>
> ```python
> # backend/executor/manager.py
> import threading
> 
> class ExecutionManager:
>     @property
>     def cancel_thread(self) -> threading.Thread:
>         """创建取消操作的后台线程"""
>         if self._cancel_thread is None:
>             self._cancel_thread = threading.Thread(
>                 target=lambda: self._consume_execution_cancel(),
>                 #      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 线程执行的函数
>                 daemon=True,
>                 #^^^^^^^^^^^ 守护线程（主程序退出时自动结束）
>             )
>         return self._cancel_thread
>     
>     def run(self):
>         # 启动后台线程
>         self.cancel_thread.start()
>         #                  ^^^^^ 启动线程
>         self.run_thread.start()
>         
>         # 主线程继续运行
>         while True:
>             time.sleep(1e5)
>     
>     def _consume_execution_cancel(self):
>         """在后台线程中运行，处理取消消息"""
>         while not self.stop_consuming.is_set():
>             # 处理消息队列
>             message = self.cancel_client.consume()
>             if message:
>                 self._handle_cancel(message)
> ```
>
> ---
>
> #### **案例 3：Event 用于线程间通信**
>
> ```python
> # backend/executor/manager.py
> import threading
> 
> class ExecutionManager:
>     def __init__(self):
>         self.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}
>         #                                                    ^^^^^^^^^^^^^^
>         #                                                   Event 用于取消
>     
>     @property
>     def stop_consuming(self) -> threading.Event:
>         """创建停止事件"""
>         if self._stop_consuming is None:
>             self._stop_consuming = threading.Event()
>         return self._stop_consuming
>     
>     def execute_graph_run(self, graph_exec_entry):
>         """执行图，创建取消事件"""
>         cancel_event = threading.Event()
>         #              ^^^^^^^^^^^^^^^^^ 每个执行都有自己的取消事件
>         
>         # 提交到线程池
>         future = self.executor.submit(
>             execute_graph, 
>             graph_exec_entry, 
>             cancel_event,  # 传递给工作线程
>             cluster_lock
>         )
>         
>         # 保存引用
>         self.active_graph_runs[graph_exec_id] = (future, cancel_event)
>     
>     def cancel_graph_run(self, graph_exec_id):
>         """取消执行"""
>         if graph_exec_id in self.active_graph_runs:
>             future, cancel_event = self.active_graph_runs[graph_exec_id]
>             cancel_event.set()  # 通知工作线程取消
>             #           ^^^^^ 设置事件
>     
> def execute_graph(graph_exec_entry, cancel_event: threading.Event):
>     """在工作线程中执行"""
>     for node in nodes:
>         # 检查是否被取消
>         if cancel_event.is_set():
>             #              ^^^^^^^ 检查事件状态
>             break
>         # 执行节点...
> ```
>
> ---
>
> #### **案例 4：线程本地存储**
>
> ```python
> # backend/executor/manager.py
> import threading
> 
> # 每个线程有自己的 ExecutionProcessor 实例
> _tls = threading.local()
> #      ^^^^^^^^^^^^^^^^^ 线程本地存储
> 
> def init_worker():
>     """在每个工作线程中初始化"""
>     _tls.processor = ExecutionProcessor()
>     #^^^ 每个线程都有自己的 processor
>     _tls.processor.on_graph_executor_start()
> 
> def execute_graph(graph_exec_entry, cancel_event):
>     """使用线程本地的 processor"""
>     return _tls.processor.on_graph_execution(
>         #   ^^^^^^^^^^^^^ 访问当前线程的 processor
>         graph_exec_entry, cancel_event
>     )
> 
> # 优势：
> # 1. 避免在函数间传递对象
> # 2. 每个线程独立，无需锁
> # 3. 简化代码结构
> ```
>

#### **核心概念详解**

**1. 创建和启动线程**

```python
import threading
import time

def worker(name, delay):
    """工作函数"""
    print(f"{name} 开始")
    time.sleep(delay)
    print(f"{name} 完成")

# 创建线程
t1 = threading.Thread(target=worker, args=("线程1", 2))
#                     ^^^^^^        ^^^^
#                     目标函数      参数

t2 = threading.Thread(target=worker, args=("线程2", 1))

# 启动线程
t1.start()
t2.start()

# 等待线程结束
t1.join()  # 阻塞直到 t1 完成
t2.join()

print("所有线程完成")
# 输出：
# 线程1 开始
# 线程2 开始
# 线程2 完成（1秒后）
# 线程1 完成（2秒后）
# 所有线程完成
```

---

**2. Lock（互斥锁）**

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        # ❌ 没有锁：竞态条件
        # counter += 1
        
        # ✅ 使用锁
        with lock:
            counter += 1

# 创建10个线程
threads = [threading.Thread(target=increment) for _ in range(10)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Counter: {counter}")  # 应该是 1,000,000
```

---

**3. Event（事件通知）**

```python
import threading
import time

event = threading.Event()

def waiter():
    """等待事件"""
    print("等待事件...")
    event.wait()  # 阻塞直到事件被设置
    print("事件已触发！")

def setter():
    """设置事件"""
    time.sleep(2)
    print("设置事件")
    event.set()

# 启动线程
t1 = threading.Thread(target=waiter)
t2 = threading.Thread(target=setter)

t1.start()
t2.start()

t1.join()
t2.join()

# 输出：
# 等待事件...
# （2秒后）
# 设置事件
# 事件已触发！
```

---

**4. Queue（线程安全队列）**

```python
import threading
import queue
import time

q = queue.Queue()

def producer():
    """生产者"""
    for i in range(5):
        print(f"生产: item-{i}")
        q.put(f"item-{i}")
        time.sleep(0.5)
    q.put(None)  # 结束信号

def consumer():
    """消费者"""
    while True:
        item = q.get()
        if item is None:
            break
        print(f"  消费: {item}")
        q.task_done()

# 启动线程
t1 = threading.Thread(target=producer)
t2 = threading.Thread(target=consumer)

t1.start()
t2.start()

t1.join()
t2.join()
```

---

**5. ThreadPoolExecutor（线程池）**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def task(n):
    """任务函数"""
    print(f"Task {n} 开始")
    time.sleep(1)
    return f"Task {n} 结果"

# 创建线程池
with ThreadPoolExecutor(max_workers=3) as executor:
    # 提交任务
    futures = [executor.submit(task, i) for i in range(5)]
    
    # 获取结果
    for future in futures:
        result = future.result()  # 阻塞直到完成
        print(result)

# 总时间：约 2 秒（5个任务，3个线程并发）
```

---

**threading vs asyncio**

> asyncio: 单线程，协程切换（轻量）
>
> threading: 多线程，操作系统调度（重量）

```python
# ===== asyncio（推荐） =====
import asyncio

async def fetch_data(url):
    await asyncio.sleep(1)  # 非阻塞 I/O
    return f"Data from {url}"

async def main():
    results = await asyncio.gather(
        fetch_data("url1"),
        fetch_data("url2"),
        fetch_data("url3"),
    )
    # 单线程，协程切换

# ===== threading =====
import threading

def fetch_data(url):
    time.sleep(1)  # 阻塞 I/O
    return f"Data from {url}"

threads = [
    threading.Thread(target=fetch_data, args=(f"url{i}",))
    for i in range(3)
]
for t in threads:
    t.start()
for t in threads:
    t.join()
# 多线程，操作系统调度
```

| 特性         | asyncio        | threading            |
| ------------ | -------------- | -------------------- |
| **并发模型** | 协程（单线程） | 多线程               |
| **适用场景** | I/O密集型      | 阻塞操作、遗留代码   |
| **GIL影响**  | 无影响         | 受GIL限制            |
| **资源占用** | 轻量           | 重量（每个线程几MB） |
| **调试难度** | 容易           | 困难                 |
| **推荐度**   | ⭐⭐⭐⭐⭐          | ⭐⭐⭐                  |

---

**常见陷阱**

**陷阱 1：忘记使用锁**

> **竞态条件**发生于当多个线程或进程（执行单元）以不可预测的顺序访问和操作**同一个共享资源**时，最终导致程序的结果取决于这些执行单元的“竞赛”——谁先跑完、谁在中间被中断。
>
> 简单来说：**程序的正确性依赖于事件发生的偶然顺序。**

```python
# ❌ 竞态条件
counter = 0

def increment():
    global counter
    for _ in range(10000):
        counter += 1  # 不是原子操作！

threads = [threading.Thread(target=increment) for _ in range(10)]
# 结果可能不是 100,000

# ✅ 使用锁
lock = threading.Lock()

def increment():
    global counter
    for _ in range(10000):
        with lock:
            counter += 1
```

---

**陷阱 2：死锁**

```python
import threading

lock1 = threading.Lock()
lock2 = threading.Lock()

def thread1():
    with lock1:
        time.sleep(0.1)
        with lock2:  # 等待 lock2
            pass

def thread2():
    with lock2:
        time.sleep(0.1)
        with lock1:  # 等待 lock1
            pass  # 💀 死锁！

# ✅ 解决：始终按相同顺序获取锁
```

---

**陷阱 3：守护线程的陷阱**

```python
import threading
import time

def worker():
    time.sleep(2)
    print("工作完成")  # 可能不会打印

t = threading.Thread(target=worker, daemon=True)
t.start()
# 主程序退出，守护线程被强制终止

# ✅ 如果需要完成工作，不要用 daemon
# 或者 t.join()
```

---

#### **总结：threading模块核心要点**

**核心类**

| 类        | 用途         | 常用方法                                                     |
| --------- | ------------ | ------------------------------------------------------------ |
| `Thread`  | 创建线程     | `start()`, `join()`                                          |
| `Lock`    | 互斥锁       | `acquire()`, `release()`                                     |
| `Event`   | 事件通知     | `set()`, `wait()`, `is_set()`                                |
| `Queue`   | 线程安全队列 | `put()`, [get()](cci:1://file:///d:/%E8%BD%AC%E7%A0%81/AI-all/AutoGPT/autogpt_platform/backend/backend/data/execution.py:1035:4-1036:31) |
| `local()` | 线程本地存储 | 直接赋值属性                                                 |

**何时使用 threading**

- ✅ 调用阻塞的第三方库
- ✅ 需要真正的并行执行（多核 CPU 密集型需要用 multiprocessing）
- ✅ 遗留同步代码
- ❌ I/O 密集型（优先用 asyncio）

**最佳实践**

1. **优先用 asyncio** - 现代 I/O 密集型应用
2. **总是使用锁** - 保护共享资源
3. **避免死锁** - 统一锁顺序
4. **使用 with 语句** - 自动释放锁
5. **谨慎使用守护线程** - 可能数据丢失

### 18.`concurrent.futures` - 并发

**什么是 concurrent.futures？**

- Python 标准库，用于**高级并发编程**
- 提供 **ThreadPoolExecutor** 和 **ProcessPoolExecutor**
- 统一的接口处理线程和进程
- 比 threading 更简单易用
- 标准库，无需安装

**为什么用 concurrent.futures？**

1. 简洁的 API

2. 自动管理线程/进程池

3. Future 对象统一异步结果

4. 易于错误处理

---

#### **核心概念速查表**

| 类/方法               | 作用               | 使用场景       |
| --------------------- | ------------------ | -------------- |
| `ThreadPoolExecutor`  | 线程池             | I/O 密集型任务 |
| `ProcessPoolExecutor` | 进程池             | CPU 密集型任务 |
| `submit(fn, *args)`   | 提交单个任务       | 返回 Future    |
| `map(fn, *iterables)` | 批量提交任务       | 返回迭代器     |
| `as_completed()`      | 按完成顺序获取结果 | 实时处理       |
| `wait()`              | 等待 Future 完成   | 超时控制       |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：ThreadPoolExecutor 管理 Graph 执行**
>
> ```python
> # backend/executor/manager.py
> from concurrent.futures import ThreadPoolExecutor
> 
> class ExecutionManager:
>     @property
>     def executor(self) -> ThreadPoolExecutor:
>         """创建线程池执行器"""
>         if self._executor is None:
>             self._executor = ThreadPoolExecutor(
>                 max_workers=self.pool_size,
>                 #           ^^^^^^^^^^^^^^ 工作线程数
>                 initializer=init_worker,
>                 #           ^^^^^^^^^^^ 每个线程初始化时调用
>             )
>         return self._executor
>     
>     def execute_graph_run(self, graph_exec_entry):
>         """提交 Graph 执行任务到线程池"""
>         cancel_event = threading.Event()
>         
>         # 提交任务，返回 Future 对象
>         future = self.executor.submit(
>             #             ^^^^^^ 提交任务
>             execute_graph, 
>             graph_exec_entry, 
>             cancel_event, 
>             cluster_lock
>         )
>         
>         # 保存 Future 和取消事件
>         self.active_graph_runs[graph_exec_id] = (future, cancel_event)
>         
>         # 添加完成回调
>         future.add_done_callback(_on_run_done)
>         #      ^^^^^^^^^^^^^^^^^ 任务完成时调用
> 
> # 优势：
> # 1. 自动管理线程池
> # 2. Future 对象跟踪任务状态
> # 3. 回调机制处理完成/错误
> ```
>
> ---
>
> #### **案例 2：Future 对象的生命周期管理**
>
> ```python
> # backend/executor/manager.py
> from concurrent.futures import Future
> 
> def _on_run_done(f: Future):
>     """任务完成时的回调函数"""
>     logger.info(f"Run completed for {graph_exec_id}")
>     
>     try:
>         # 检查是否有异常
>         if exec_error := f.exception():
>             #              ^^^^^^^^^^^ 获取异常（如果有）
>             logger.error(f"Execution failed: {exec_error}")
>             _ack_message(reject=True, requeue=True)
>         else:
>             # 成功完成
>             _ack_message(reject=False, requeue=False)
>     finally:
>         # 清理资源
>         if graph_exec_id in self._execution_locks:
>             self._execution_locks[graph_exec_id].release()
>         self._cleanup_completed_runs()
> 
> # 注册回调
> future.add_done_callback(_on_run_done)
> 
> # Future 的状态检查
> def _cleanup_completed_runs(self):
>     """清理已完成的任务"""
>     completed_runs = []
>     for graph_exec_id, (future, _) in self.active_graph_runs.items():
>         if future.done():
>             #     ^^^^^^ 检查是否完成
>             completed_runs.append(graph_exec_id)
>     
>     for geid in completed_runs:
>         self.active_graph_runs.pop(geid, None)
> ```
>
> ---
>
> #### **案例 3：NodeExecutionProgress 管理并发任务**
>
> ```python
> # backend/executor/utils.py
> from concurrent.futures import Future
> import threading
> 
> class NodeExecutionProgress:
>     def __init__(self):
>         self.output: dict[str, list] = defaultdict(list)
>         self.tasks: dict[str, Future] = {}
>         #                      ^^^^^^ 存储 Future 对象
>         self._lock = threading.Lock()
>     
>     def add_task(self, node_exec_id: str, task: Future):
>         """添加任务"""
>         self.tasks[node_exec_id] = task
>     
>     def is_done(self, wait_time: float = 0.0) -> bool:
>         """检查所有任务是否完成"""
>         exec_id = self._next_exec()
>         if not exec_id:
>             return True
>         
>         if wait_time > 0:
>             try:
>                 # 等待任务完成（带超时）
>                 self.tasks[exec_id].result(wait_time)
>                 #                   ^^^^^^ 获取结果（阻塞）
>             except TimeoutError:
>                 pass
>             except Exception as e:
>                 logger.error(f"Task failed: {e}")
>         
>         return self.is_done(0)
>     
>     def stop(self) -> list[str]:
>         """取消所有任务"""
>         cancelled_ids = []
>         for task_id, task in self.tasks.items():
>             if not task.done():
>                 task.cancel()
>                 #    ^^^^^^ 取消任务
>                 cancelled_ids.append(task_id)
>         return cancelled_ids
> ```
>

#### **详细功能讲解**

**1. Thread PoolExecutor 基础**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def task(n):
    """任务函数"""
    print(f"Task {n} 开始")
    time.sleep(1)
    return f"Task {n} 结果"

# 方式 1：with 语句（推荐）
with ThreadPoolExecutor(max_workers=3) as executor:
    #                     ^^^^^^^^^^^ 最多3个工作线程
    # 提交任务
    future1 = executor.submit(task, 1)
    future2 = executor.submit(task, 2)
    future3 = executor.submit(task, 3)
    
    # 获取结果
    print(future1.result())  # 阻塞直到完成
    print(future2.result())
    print(future3.result())

# with 自动 shutdown()，等待所有任务完成

# 方式 2：手动管理
executor = ThreadPoolExecutor(max_workers=3)
future = executor.submit(task, 1)
result = future.result()
executor.shutdown(wait=True)  # 等待所有任务完成
```

---

**2. Future 对象详解**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def slow_task(n):
    time.sleep(n)
    if n == 3:
        raise ValueError("出错了！")
    return f"结果-{n}"

with ThreadPoolExecutor() as executor:
    future = executor.submit(slow_task, 2)
    
    # 状态检查
    print(future.running())    # 是否正在运行
    print(future.done())       # 是否已完成
    print(future.cancelled())  # 是否已取消
    
    # 获取结果（阻塞）
    result = future.result()
    #               ^^^^^^ 阻塞直到完成
    print(result)  # "结果-2"
    
    # 带超时
    future2 = executor.submit(slow_task, 10)
    try:
        result = future2.result(timeout=2)
        #                       ^^^^^^^^^ 最多等2秒
    except TimeoutError:
        print("超时了！")
    
    # 获取异常
    future3 = executor.submit(slow_task, 3)
    try:
        result = future3.result()
    except ValueError as e:
        print(f"捕获异常: {e}")
    
    # 或者
    if future3.exception():
        #     ^^^^^^^^^ 获取异常对象（不会抛出）
        print(f"任务出错: {future3.exception()}")
```

---

**3. map() 方法（批量提交）**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def process(n):
    time.sleep(0.5)
    return n * 2

# 批量处理
with ThreadPoolExecutor(max_workers=4) as executor:
    numbers = range(10)
    
    # map 返回结果的迭代器（按提交顺序）
    results = executor.map(process, numbers)
    #                ^^^ 类似内置 map，但并发执行
    
    # 获取所有结果
    print(list(results))  # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
    
    # 带超时
    results = executor.map(process, numbers, timeout=5)
    #                                        ^^^^^^^^^ 每个任务的超时

# 等价于
futures = [executor.submit(process, n) for n in numbers]
results = [f.result() for f in futures]
```

---

**4. as_completed() - 按完成顺序获取结果**

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import random

def task(n):
    sleep_time = random.uniform(0.1, 2)
    time.sleep(sleep_time)
    return f"Task {n} (slept {sleep_time:.2f}s)"

with ThreadPoolExecutor(max_workers=5) as executor:
    # 提交多个任务
    futures = {executor.submit(task, i): i for i in range(5)}
    
    # 按完成顺序处理结果
    for future in as_completed(futures):
        #            ^^^^^^^^^^^^ 按完成顺序返回
        task_id = futures[future]
        try:
            result = future.result()
            print(f"✅ {result}")
        except Exception as e:
            print(f"❌ Task {task_id} 失败: {e}")

# 输出示例（顺序不固定）：
# ✅ Task 3 (slept 0.23s)
# ✅ Task 1 (slept 0.45s)
# ✅ Task 4 (slept 0.67s)
# ✅ Task 0 (slept 1.12s)
# ✅ Task 2 (slept 1.89s)
```

---

**5. 回调函数**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def task(n):
    time.sleep(1)
    return n * 2

def on_complete(future):
    """任务完成时的回调"""
    try:
        result = future.result()
        print(f"✅ 任务完成，结果: {result}")
    except Exception as e:
        print(f"❌ 任务失败: {e}")

with ThreadPoolExecutor() as executor:
    future = executor.submit(task, 5)
    
    # 添加回调（任务完成后自动调用）
    future.add_done_callback(on_complete)
    #      ^^^^^^^^^^^^^^^^^
    
    # 主线程可以继续做其他事情
    print("等待任务完成...")
    future.result()  # 确保完成

# 输出：
# 等待任务完成...
# ✅ 任务完成，结果: 10
```

---

**6. ProcessPoolExecutor（CPU 密集型）**

```python
from concurrent.futures import ProcessPoolExecutor
import time

def cpu_intensive(n):
    """CPU 密集型任务"""
    result = sum(i**2 for i in range(n))
    return result

# ThreadPoolExecutor（受 GIL 限制）
with ThreadPoolExecutor(max_workers=4) as executor:
    start = time.time()
    results = list(executor.map(cpu_intensive, [10_000_000] * 4))
    print(f"线程池: {time.time() - start:.2f}s")
    # 约 8 秒（几乎串行）

# ProcessPoolExecutor（真正并行）
with ProcessPoolExecutor(max_workers=4) as executor:
    start = time.time()
    results = list(executor.map(cpu_intensive, [10_000_000] * 4))
    print(f"进程池: {time.time() - start:.2f}s")
    # 约 2 秒（4核并行）

# 选择规则：
# - I/O 密集型 → ThreadPoolExecutor
# - CPU 密集型 → ProcessPoolExecutor
```

---

#### **实际应用场景**

**场景 1：并发 HTTP 请求**

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests

def fetch_url(url):
    """获取 URL"""
    response = requests.get(url, timeout=5)
    return url, len(response.content)

urls = [
    "https://example.com",
    "https://github.com",
    "https://python.org",
    # ... 更多 URL
]

# 并发请求
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = {executor.submit(fetch_url, url): url for url in urls}
    
    for future in as_completed(futures):
        url = futures[future]
        try:
            url, size = future.result()
            print(f"✅ {url}: {size} bytes")
        except Exception as e:
            print(f"❌ {url}: {e}")
```

---

**场景 2：批量数据处理**

```python
from concurrent.futures import ThreadPoolExecutor
import time

def process_record(record):
    """处理单条记录"""
    # 模拟 I/O 操作（数据库写入）
    time.sleep(0.1)
    return {"id": record["id"], "processed": True}

records = [{"id": i, "data": f"data{i}"} for i in range(100)]

# 并发处理
with ThreadPoolExecutor(max_workers=20) as executor:
    results = list(executor.map(process_record, records))

print(f"处理了 {len(results)} 条记录")
# 100 条记录，20 个线程，约 0.5 秒
# 串行需要 10 秒
```

---

**场景 3：超时控制**

```python
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import time

def slow_operation(n):
    time.sleep(n)
    return f"完成-{n}"

with ThreadPoolExecutor() as executor:
    futures = [
        executor.submit(slow_operation, 1),
        executor.submit(slow_operation, 5),  # 这个会超时
        executor.submit(slow_operation, 2),
    ]
    
    for i, future in enumerate(futures):
        try:
            result = future.result(timeout=3)
            #                      ^^^^^^^^^ 3秒超时
            print(f"任务 {i}: {result}")
        except TimeoutError:
            print(f"任务 {i}: 超时！")
            future.cancel()  # 尝试取消

# 输出：
# 任务 0: 完成-1
# 任务 1: 超时！
# 任务 2: 完成-2
```

---

**常见陷阱**

**陷阱 1：忘记调用 result() 或 wait()**

```python
from concurrent.futures import ThreadPoolExecutor

def task():
    print("执行任务")
    return "结果"

# ❌ 错误：没有等待任务完成
with ThreadPoolExecutor() as executor:
    future = executor.submit(task)
    # 立即退出 with，可能任务还没执行完

# ✅ 正确：等待结果
with ThreadPoolExecutor() as executor:
    future = executor.submit(task)
    result = future.result()  # 等待完成
```

---

**陷阱 2：异常被吞掉**

```python
from concurrent.futures import ThreadPoolExecutor

def task():
    raise ValueError("出错了！")

# ❌ 异常不会立即抛出
with ThreadPoolExecutor() as executor:
    future = executor.submit(task)
    # 没有调用 result()，异常被忽略

# ✅ 正确：检查异常
with ThreadPoolExecutor() as executor:
    future = executor.submit(task)
    try:
        future.result()
    except ValueError as e:
        print(f"捕获: {e}")
```

---

**陷阱 3：CPU 密集型用错执行器**

```python
# ❌ CPU 密集型用 ThreadPoolExecutor（慢）
def cpu_task(n):
    return sum(i**2 for i in range(n))

with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(cpu_task, [10_000_000] * 4))
    # 受 GIL 限制，几乎串行

# ✅ 使用 ProcessPoolExecutor
from concurrent.futures import ProcessPoolExecutor

with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(cpu_task, [10_000_000] * 4))
    # 真正并行，快 4 倍
```

---

**陷阱 4：提交太多任务导致内存溢出**

```python
from concurrent.futures import ThreadPoolExecutor

def task(n):
    return n * 2

# ❌ 一次提交 100 万个任务
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(task, i) for i in range(1_000_000)]
    # 所有 Future 对象占用大量内存

# ✅ 分批提交
def batch_submit(items, batch_size=1000):
    with ThreadPoolExecutor(max_workers=10) as executor:
        for i in range(0, len(items), batch_size):
            batch = items[i:i+batch_size]
            futures = [executor.submit(task, n) for n in batch]
            results = [f.result() for f in futures]
            yield from results

results = list(batch_submit(range(1_000_000)))
```

---

#### **总结：concurrent.futures模块核心要点**

**核心类和方法**

| 类/方法               | 作用       | 适用场景   |
| --------------------- | ---------- | ---------- |
| `ThreadPoolExecutor`  | 线程池     | I/O 密集型 |
| `ProcessPoolExecutor` | 进程池     | CPU 密集型 |
| `submit(fn, *args)`   | 提交任务   | 灵活控制   |
| `map(fn, *iterables)` | 批量提交   | 简单并行   |
| `as_completed()`      | 按完成顺序 | 实时处理   |
| `result()`            | 获取结果   | 阻塞等待   |
| `add_done_callback()` | 添加回调   | 异步通知   |

**ThreadPoolExecutor vs ProcessPoolExecutor**

| 特性         | ThreadPoolExecutor | ProcessPoolExecutor |
| ------------ | ------------------ | ------------------- |
| **并发模型** | 多线程             | 多进程              |
| **GIL影响**  | 受限               | 不受限              |
| **内存**     | 共享               | 独立                |
| **启动开销** | 小                 | 大                  |
| **适用场景** | I/O密集型          | CPU密集型           |

**最佳实践**

1. **I/O 密集型用 ThreadPoolExecutor** - 网络、文件
2. **CPU 密集型用 ProcessPoolExecutor** - 计算
3. **用 with 语句** - 自动清理
4. **总是处理异常** - 调用 result() 或 exception()
5. **合理设置 max_workers** - 通常 CPU核心数 * 2-4
6. **大任务分批提交** - 避免内存溢出

### 19.`contextlib` - 上下文管理

**什么是 contextlib？**

- Python 标准库，用于**创建和管理上下文管理器**
- 上下文管理器 = `with` 语句的核心
- 确保资源正确获取和释放（文件、锁、连接等）
- 标准库，无需安装

> **上下文管理**就是 Python 提供的一种优雅的、自动化的机制，来保证这个“获取资源 -> 使用资源 -> 释放资源”的完整流程。

---

#### **核心功能速查表**

| 装饰器/工具            | 作用                     | 使用场景     |
| ---------------------- | ------------------------ | ------------ |
| `@contextmanager`      | 将生成器转为上下文管理器 | 简化资源管理 |
| `@asynccontextmanager` | 异步上下文管理器         | 异步资源管理 |
| `closing()`            | 确保对象关闭             | 调用 close() |
| `suppress()`           | 抑制特定异常             | 忽略某些错误 |
| `redirect_stdout()`    | 重定向标准输出           | 捕获输出     |
| `ExitStack`            | 动态管理多个上下文       | 可变数量资源 |

---

> ## **AutoGPT Platform 中的实际使用**
>
> ### **案例 1：异步数据库事务**
>
> ```python
> # backend/data/db.py
> from contextlib import asynccontextmanager
> 
> @asynccontextmanager
> async def transaction(timeout: int = 30000):
>     """创建数据库事务上下文管理器"""
>     async with prisma.tx(timeout=timeout) as tx:
>         yield tx
> 
> # 使用
> async def save_user(user_data):
>     async with transaction() as tx:
>         user = await tx.user.create(data=user_data)
>         profile = await tx.profile.create(data={"user_id": user.id})
>         # 如果出错，自动回滚
>         # 如果成功，自动提交
>         return user
> ```
>
> ---
>
> ### **案例 2：带锁的数据库事务**
>
> ```python
> # backend/data/db.py
> @asynccontextmanager
> async def locked_transaction(key: str, timeout: int = 30000):
>     """创建带锁的事务（防止并发冲突）"""
>     async with transaction(timeout=timeout) as tx:
>         # 设置超时
>         await tx.execute_raw(f"SET LOCAL lock_timeout = '{timeout}ms'")
>         
>         # 获取 PostgreSQL 咨询锁
>         await tx.execute_raw(
>             "SELECT pg_advisory_xact_lock(hashtextextended($1, 0))",
>             key,
>         )
>         
>         yield tx
>         # 事务结束时自动释放锁
> 
> # 使用
> async def update_balance(user_id: str, amount: int):
>     async with locked_transaction(f"balance_{user_id}") as tx:
>         # 只有一个事务能同时修改此用户余额
>         user = await tx.user.find_unique(where={"id": user_id})
>         await tx.user.update(
>             where={"id": user_id},
>             data={"balance": user.balance + amount}
>         )
> ```
>
> ---
>
> ### **案例 3：Redis 分布式锁**
>
> ```python
> # backend/executor/manager.py
> from contextlib import asynccontextmanager
> 
> @asynccontextmanager
> async def synchronized(key: str, timeout: int = 30):
>     """Redis 分布式锁上下文管理器"""
>     r = await redis.get_redis_async()
>     lock = r.lock(f"lock:{key}", timeout=timeout)
>     
>     try:
>         await lock.acquire()  # 获取锁
>         yield  # 执行临界区代码
>     finally:
>         # 确保释放锁（即使出错）
>         if await lock.locked() and await lock.owned():
>             try:
>                 await lock.release()
>             except Exception as e:
>                 logger.warning(f"Failed to release lock: {e}")
> 
> # 使用
> async def process_unique_task(task_id: str):
>     async with synchronized(f"task:{task_id}"):
>         # 只有一个实例能执行此任务
>         result = await perform_task(task_id)
>         return result
> ```
>
> ---
>
> ### **案例 4：凭证锁管理**
>
> ```python
> # backend/integrations/creds_manager.py
> class IntegrationCredentialsManager:
>     @asynccontextmanager
>     async def _locked(self, user_id: str, credentials_id: str):
>         """获取和释放凭证锁"""
>         lock = await self._acquire_lock(user_id, credentials_id)
>         
>         try:
>             yield
>         finally:
>             if await lock.locked() and await lock.owned():
>                 try:
>                     await lock.release()
>                 except Exception as e:
>                     logger.warning(f"Failed to release lock: {e}")
> 
>     # 使用
>     async def get_credentials(self, user_id: str, creds_id: str):
>         async with self._locked(user_id, creds_id):
>             # 获取凭证时加锁
>             return await self.store.get_credentials(user_id, creds_id)
> ```
>

#### **核心概念详解**

1. @contextmanager - 同步版本

```python
from contextlib import contextmanager

@contextmanager
def file_manager(filename, mode):
    """文件管理器"""
    print(f"打开文件: {filename}")
    f = open(filename, mode)
    
    try:
        yield f  # 传递给 as 变量
    finally:
        # 无论如何都会执行
        print(f"关闭文件: {filename}")
        f.close()

# 使用
with file_manager("test.txt", "w") as f:
    f.write("Hello")
    # 如果这里出错，文件仍会关闭

# 输出：
# 打开文件: test.txt
# 关闭文件: test.txt
```

**工作原理：**
```python
@contextmanager
def my_context():
    # 1. with 语句开始时执行
    print("进入")
    resource = "资源"
    
    try:
        # 2. yield 将控制权交给 with 语句体
        yield resource
        # 5. with 语句体正常结束后继续
    finally:
        # 6. 无论如何都会执行（清理）
        print("退出")

# 使用
with my_context() as res:
    # 3. 执行这里的代码
    print(f"使用 {res}")
    # 4. 执行完毕
```

---

**2. @asynccontextmanager - 异步版本**

```python
from contextlib import asynccontextmanager
import asyncio

@asynccontextmanager
async def async_database_connection():
    """异步数据库连接"""
    print("连接数据库...")
    conn = await asyncio.sleep(0.1)  # 模拟异步连接
    
    try:
        yield conn
    finally:
        print("断开数据库...")
        await asyncio.sleep(0.1)  # 模拟异步断开

# 使用
async def main():
    async with async_database_connection() as conn:
        print("执行查询")
        # 使用连接

asyncio.run(main())
```

---

**3. 嵌套上下文管理器**

```python
from contextlib import asynccontextmanager

# AutoGPT 中的实际例子
@asynccontextmanager
async def locked_transaction(key: str):
    # 嵌套使用另一个上下文管理器
    async with transaction() as tx:
        # 在事务内获取锁
        await acquire_lock(tx, key)
        yield tx
        # 自动释放锁和提交事务

# 等价于手动嵌套
async with transaction() as tx:
    await acquire_lock(tx, key)
    try:
        # 使用
        pass
    finally:
        await release_lock(tx, key)
```

---

**4. ExitStack - 动态管理多个上下文**

```python
from contextlib import ExitStack

def process_files(filenames):
    """动态打开多个文件"""
    with ExitStack() as stack:
        # 动态添加上下文管理器
        files = [
            stack.enter_context(open(fname))
            for fname in filenames
        ]
        
        # 所有文件自动关闭
        return [f.read() for f in files]

# 使用
files = ["file1.txt", "file2.txt", "file3.txt"]
contents = process_files(files)

# 异步版本
from contextlib import AsyncExitStack

async def process_async_resources(resource_ids):
    async with AsyncExitStack() as stack:
        resources = [
            await stack.enter_async_context(get_resource(rid))
            for rid in resource_ids
        ]
        return await process(resources)
```

---

**5. suppress - 抑制异常**

```python
from contextlib import suppress
import os

# 忽略特定异常
with suppress(FileNotFoundError):
    os.remove("non_existent_file.txt")
    # 文件不存在也不会报错

# 等价于
try:
    os.remove("non_existent_file.txt")
except FileNotFoundError:
    pass

# 忽略多个异常
with suppress(FileNotFoundError, PermissionError):
    os.remove("file.txt")
```

---

**6. redirect_stdout/redirect_stderr**

```python
from contextlib import redirect_stdout, redirect_stderr
import io

# 捕获标准输出
f = io.StringIO()
with redirect_stdout(f):
    print("这会被捕获")
    print("不会显示在控制台")

output = f.getvalue()
print(f"捕获的输出: {output}")

# 实际应用：测试
def test_print_function():
    output = io.StringIO()
    with redirect_stdout(output):
        my_function()
    
    assert "expected" in output.getvalue()
```

---

**7. closing - 确保调用 close()**

```python
from contextlib import closing
import urllib.request

# 自动调用 close()
with closing(urllib.request.urlopen("http://example.com")) as page:
    content = page.read()
    # 自动调用 page.close()

# 等价于
page = urllib.request.urlopen("http://example.com")
try:
    content = page.read()
finally:
    page.close()
```

---

#### **实际应用场景**

**场景 1：临时修改配置**

```python
from contextlib import contextmanager

@contextmanager
def temporary_setting(key, value):
    """临时修改配置"""
    old_value = config.get(key)
    config[key] = value
    try:
        yield
    finally:
        config[key] = old_value

# 使用
print(config["debug"])  # False

with temporary_setting("debug", True):
    print(config["debug"])  # True
    run_tests()

print(config["debug"])  # False (自动恢复)
```

---

**场景 2：计时器**

```python
from contextlib import contextmanager
import time

@contextmanager
def timer(name):
    """测量代码执行时间"""
    start = time.time()
    yield
    elapsed = time.time() - start
    print(f"{name} 耗时: {elapsed:.2f}s")

# 使用
with timer("数据处理"):
    process_large_dataset()
# 自动打印: 数据处理 耗时: 3.45s
```

---

**场景 3：临时切换目录**

```python
from contextlib import contextmanager
import os

@contextmanager
def cd(path):
    """临时切换工作目录"""
    old_dir = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(old_dir)

# 使用
print(os.getcwd())  # /home/user

with cd("/tmp"):
    print(os.getcwd())  # /tmp
    # 在这里操作

print(os.getcwd())  # /home/user (自动恢复)
```

---

**场景 4：数据库连接池**

```python
from contextlib import asynccontextmanager

class DatabasePool:
    @asynccontextmanager
    async def acquire(self):
        """从连接池获取连接"""
        conn = await self._get_connection()
        try:
            yield conn
        finally:
            await self._return_connection(conn)

# 使用
pool = DatabasePool()

async def query_database():
    async with pool.acquire() as conn:
        result = await conn.execute("SELECT * FROM users")
        return result
    # 连接自动归还到池
```

---

**常见陷阱**

**陷阱 1：忘记 finally**

```python
from contextlib import contextmanager

# ❌ 错误：没有 finally，出错时不会清理
@contextmanager
def bad_context():
    resource = acquire_resource()
    yield resource
    release_resource(resource)  # 出错时不会执行

# ✅ 正确：使用 try-finally
@contextmanager
def good_context():
    resource = acquire_resource()
    try:
        yield resource
    finally:
        release_resource(resource)  # 总是执行
```

---

**陷阱 2：yield 多次**

```python
from contextlib import contextmanager

# ❌ 错误：只能 yield 一次
@contextmanager
def bad_context():
    yield 1
    yield 2  # RuntimeError!

# ✅ 正确：只 yield 一次
@contextmanager
def good_context():
    yield [1, 2]  # 返回多个值用容器
```

---

**陷阱 3：异步混用**

```python
# ❌ 错误：异步函数用同步装饰器
@contextmanager  # 错误！
async def async_context():
    yield

# ✅ 正确：用异步装饰器
@asynccontextmanager
async def async_context():
    yield
```

---

#### **总结：`contextlib`模块核心要点**

**核心工具**

| 工具                   | 用途             | 典型场景              |
| ---------------------- | ---------------- | --------------------- |
| `@contextmanager`      | 简化上下文管理器 | 文件、锁、临时状态    |
| `@asynccontextmanager` | 异步版本         | 异步连接、事务        |
| `ExitStack`            | 动态管理多个资源 | 数量不固定            |
| `suppress`             | 忽略异常         | 简化错误处理          |
| `closing`              | 确保关闭         | 任何有 close() 的对象 |

**最佳实践**

1. **资源管理用上下文管理器** - 自动清理
2. **finally 确保清理** - 即使出错
3. **异步资源用 asynccontextmanager** - 配合 async/await
4. **嵌套使用** - 可以组合多个上下文管理器
5. **测试时用 suppress/redirect** - 简化测试代码

### 20.`inspect` - 对象检查

**什么是 inspect？**

- Python 标准库，用于**运行时检查对象**
- 获取函数、类、模块的详细信息
- 支持**反射**和**元编程**
- 标准库，无需安装

#### **核心功能速查表**

| 函数                       | 作用             | 示例           |
| -------------------------- | ---------------- | -------------- |
| `signature(obj)`           | 获取函数签名     | 参数、类型注解 |
| `getmembers(obj)`          | 获取对象所有成员 | 属性、方法     |
| `getsource(obj)`           | 获取源代码       | 查看实现       |
| `isfunction(obj)`          | 检查是否是函数   | 类型判断       |
| `iscoroutinefunction(obj)` | 检查是否是协程   | async def      |
| `getfile(obj)`             | 获取定义文件路径 | 定位代码       |

---

> ## **AutoGPT Platform 中的实际使用**
>
> #### **案例 1：动态生成 FastAPI 端点**
>
> ```python
> # backend/util/service.py
> import inspect
> from pydantic import create_model
> 
> def _gen_endpoint(self, func):
>     """从函数签名自动生成 FastAPI 端点"""
>     # 获取函数签名
>     sig = inspect.signature(func)
>     #      ^^^^^^^^^^^^^^^^ 获取函数的完整签名
>     fields = {}
>     
>     # 遍历所有参数
>     for name, param in sig.parameters.items():
>         if name in ("self", "cls"):
>             continue
>         
>         # 获取类型注解（如果没有默认用 str）
>         annotation = (
>             param.annotation 
>             if param.annotation != inspect.Parameter.empty 
>             else str
>         )
>         
>         # 获取默认值（如果没有则为必填）
>         default = (
>             param.default 
>             if param.default != inspect.Parameter.empty 
>             else ...
>         )
>         
>         fields[name] = (annotation, default)
>     
>     # 动态创建 Pydantic 模型
>     RequestBodyModel = create_model("RequestBodyModel", **fields)
>     
>     # 根据函数类型创建端点
>     if asyncio.iscoroutinefunction(func):
>         async def async_endpoint(body: RequestBodyModel):
>             return await func(**body.dict())
>         return async_endpoint
> 
> # 应用：自动将普通函数转为 API 端点
> # 无需手动定义 Pydantic 模型
> ```
>
> ---
>
> #### **案例 2：检查函数是否异步**
>
> ```python
> # backend/util/test.py
> import inspect
> 
> async def execute_block_test(block: Block):
>     """执行 Block 测试，自动检测函数类型"""
>     
>     for mock_name, mock_obj in block.test_mock.items():
>         fun = getattr(block, mock_name)
>         
>         # 检查是否是异步函数或异步生成器
>         is_async = (
>             inspect.iscoroutinefunction(fun) 
>             #      ^^^^^^^^^^^^^^^^^^^^ 是否是 async def
>             or inspect.isasyncgenfunction(fun)
>             #          ^^^^^^^^^^^^^^^^^^^ 是否是 async def ... yield
>         )
>         
>         if is_async:
>             # 创建异步 mock
>             async def async_mock(*args, **kwargs):
>                 return mock_obj(*args, **kwargs)
>             setattr(block, mock_name, async_mock)
>         else:
>             # 直接替换同步 mock
>             setattr(block, mock_name, mock_obj)
> 
> # 优势：
> # 1. 自动适配同步/异步函数
> # 2. 统一测试接口
> ```
>
> ---
>
> #### **案例 3：检查类型注解**
>
> ```python
> # backend/data/block.py
> import inspect
> 
> class BlockSchema:
>     @classmethod
>     def get_credentials_fields(cls):
>         """获取所有凭证字段"""
>         return {
>             field_name: info.annotation
>             for field_name, info in cls.model_fields.items()
>             if (
>                 inspect.isclass(info.annotation)
>                 #      ^^^^^^^ 检查是否是类
>                 and issubclass(
>                     get_origin(info.annotation) or info.annotation,
>                     CredentialsMetaInput,
>                 )
>             )
>         }
> 
> # 使用：自动识别需要凭证的字段
> # 无需手动标记
> ```
>

#### **核心功能详解**

**1. signature() - 获取函数签名**

```python
import inspect

def example(a: int, b: str = "default", *args, **kwargs) -> str:
    """示例函数"""
    return f"{a}: {b}"

# 获取签名
sig = inspect.signature(example)
print(sig)  # (a: int, b: str = 'default', *args, **kwargs) -> str

# 遍历参数
for name, param in sig.parameters.items():
    print(f"参数名: {name}")
    print(f"  类型注解: {param.annotation}")
    print(f"  默认值: {param.default}")
    print(f"  种类: {param.kind}")
    print()

# 输出：
# 参数名: a
#   类型注解: <class 'int'>
#   默认值: <class 'inspect._empty'>
#   种类: POSITIONAL_OR_KEYWORD
# 
# 参数名: b
#   类型注解: <class 'str'>
#   默认值: default
#   种类: POSITIONAL_OR_KEYWORD

# 获取返回类型
print(sig.return_annotation)  # <class 'str'>
```

---

**2. 参数种类**

```python
import inspect

def demo(pos_only, /, pos_or_kw, *, kw_only, **kwargs):
    pass

sig = inspect.signature(demo)

for name, param in sig.parameters.items():
    print(f"{name}: {param.kind}")

# 输出：
# pos_only: POSITIONAL_ONLY
# pos_or_kw: POSITIONAL_OR_KEYWORD
# kw_only: KEYWORD_ONLY
# kwargs: VAR_KEYWORD

# 参数种类：
# - POSITIONAL_ONLY: 只能位置传参（Python 3.8+）
# - POSITIONAL_OR_KEYWORD: 位置或关键字
# - VAR_POSITIONAL: *args
# - KEYWORD_ONLY: 只能关键字传参
# - VAR_KEYWORD: **kwargs
```

---

**3. 类型检查函数**

```python
import inspect

# 函数类型检查
def sync_func():
    pass

async def async_func():
    pass

print(inspect.isfunction(sync_func))           # True
print(inspect.iscoroutinefunction(async_func)) # True
print(inspect.isgeneratorfunction(range))      # False

# 类检查
class MyClass:
    pass

print(inspect.isclass(MyClass))    # True
print(inspect.ismethod(MyClass.mro)) # True

# 模块检查
import os
print(inspect.ismodule(os))  # True
```

---

**4. getmembers() - 获取对象成员**

```python
import inspect

class Example:
    class_var = "类变量"
    
    def __init__(self):
        self.instance_var = "实例变量"
    
    def method(self):
        pass
    
    @staticmethod
    def static_method():
        pass
    
    @classmethod
    def class_method(cls):
        pass

# 获取所有成员
members = inspect.getmembers(Example)
for name, value in members:
    print(f"{name}: {type(value)}")

# 只获取方法
methods = inspect.getmembers(Example, predicate=inspect.ismethod)
print([name for name, _ in methods])

# 只获取函数
functions = inspect.getmembers(Example, predicate=inspect.isfunction)
print([name for name, _ in functions])
```

---

**5. getsource() - 获取源代码**

```python
import inspect

def my_function():
    """示例函数"""
    x = 1
    y = 2
    return x + y

# 获取源代码
source = inspect.getsource(my_function)
print(source)
# 输出：
# def my_function():
#     """示例函数"""
#     x = 1
#     y = 2
#     return x + y

# 获取源文件
file = inspect.getfile(my_function)
print(file)  # /path/to/file.py

# 获取源代码行号
lines, start_line = inspect.getsourcelines(my_function)
print(f"从第 {start_line} 行开始")
```

---

**6. getcallargs() - 绑定参数**

```python
import inspect

def func(a, b=2, *args, **kwargs):
    pass

# 绑定参数（模拟函数调用）
sig = inspect.signature(func)
bound = sig.bind(1, 2, 3, x=4, y=5)
#           ^^^^ 绑定实际参数

print(bound.arguments)
# OrderedDict([('a', 1), ('b', 2), ('args', (3,)), ('kwargs', {'x': 4, 'y': 5})])

# 应用默认值
bound.apply_defaults()

# 部分绑定
partial_bound = sig.bind_partial(a=1)
print(partial_bound.arguments)  # {'a': 1}
```

---

#### **实际应用场景**

**场景 1：参数验证装饰器**

```python
import inspect
from functools import wraps

def validate_types(func):
    """验证函数参数类型"""
    sig = inspect.signature(func)
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        # 绑定参数
        bound = sig.bind(*args, **kwargs)
        bound.apply_defaults()
        
        # 验证类型
        for name, value in bound.arguments.items():
            param = sig.parameters[name]
            if param.annotation != inspect.Parameter.empty:
                expected_type = param.annotation
                if not isinstance(value, expected_type):
                    raise TypeError(
                        f"{name} 应该是 {expected_type}, 得到 {type(value)}"
                    )
        
        return func(*args, **kwargs)
    
    return wrapper

# 使用
@validate_types
def add(a: int, b: int) -> int:
    return a + b

add(1, 2)      # ✅ OK
# add(1, "2")  # ❌ TypeError
```

---

**场景 2：依赖注入**

```python
import inspect

class Container:
    def __init__(self):
        self.services = {}
    
    def register(self, name, instance):
        self.services[name] = instance
    
    def inject(self, func):
        """自动注入依赖"""
        sig = inspect.signature(func)
        
        def wrapper(*args, **kwargs):
            # 自动提供未传递的参数
            for name, param in sig.parameters.items():
                if name not in kwargs and name in self.services:
                    kwargs[name] = self.services[name]
            
            return func(*args, **kwargs)
        
        return wrapper

# 使用
container = Container()
container.register("db", DatabaseConnection())
container.register("cache", RedisCache())

@container.inject
def process_data(data, db, cache):
    # db 和 cache 自动注入
    pass

process_data("data")  # 自动提供 db 和 cache
```

---

**场景 3：动态调用路由**

```python
import inspect

class Router:
    def __init__(self):
        self.routes = {}
    
    def route(self, path):
        def decorator(func):
            self.routes[path] = func
            return func
        return decorator
    
    def call(self, path, **params):
        """智能调用路由函数"""
        func = self.routes[path]
        sig = inspect.signature(func)
        
        # 只传递函数需要的参数
        func_params = {}
        for name in sig.parameters:
            if name in params:
                func_params[name] = params[name]
        
        return func(**func_params)

# 使用
router = Router()

@router.route("/user")
def get_user(user_id, include_posts=False):
    return {"id": user_id, "posts": include_posts}

# 调用时可以传递额外参数，不会报错
result = router.call(
    "/user", 
    user_id=123, 
    include_posts=True, 
    extra_param="ignored"  # 自动忽略
)
```

---

**常见陷阱**

**陷阱 1：修改过的函数签名**

```python
import inspect
from functools import wraps

def decorator(func):
    @wraps(func)  # ⚠️ 即使用了 wraps
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

@decorator
def my_func(a: int, b: str) -> str:
    return f"{a}: {b}"

# ❌ 签名被破坏
sig = inspect.signature(my_func)
print(sig)  # (*args, **kwargs)

# ✅ 使用 functools.wraps 至少保留元数据
print(my_func.__name__)  # "my_func"
```

---

**陷阱 2：动态生成的函数**

```python
import inspect

# 动态创建函数
def create_func():
    def inner():
        pass
    return inner

func = create_func()

# ❌ 无法获取源代码
try:
    inspect.getsource(func)
except OSError:
    print("无法获取源代码（函数是动态创建的）")
```

---

#### **总结：`inspect`模块核心要点**

**核心函数**

| 函数                    | 用途         | 常见场景           |
| ----------------------- | ------------ | ------------------ |
| `signature()`           | 获取函数签名 | 参数验证、自动文档 |
| `iscoroutinefunction()` | 检查异步函数 | 统一同步/异步处理  |
| `isclass()`             | 检查类型     | 类型判断           |
| `getmembers()`          | 获取成员     | 反射、动态调用     |
| `getsource()`           | 获取源代码   | 调试、文档生成     |

**最佳实践**

1. **自动生成 API** - 从函数签名生成端点
2. **参数验证** - 检查类型注解
3. **依赖注入** - 自动提供参数
4. **测试框架** - 区分同步/异步
5. **元编程** - 动态调用和修改
